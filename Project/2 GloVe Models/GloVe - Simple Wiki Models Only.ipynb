{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\User\\\\Google Drive\\\\University\\\\Dissertation\\\\Code'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = 'C:/Users/'+os.getlogin()+'/Google Drive/University/Dissertation'\n",
    "datapath = 'E:/Dissertation Data'\n",
    "\n",
    "os.chdir(path+'/Code')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We collect lexical co-occurrence statistics on all words in\n",
    "the English Wikipedia, using the WikiExtractor tool2 to retrieve\n",
    "plain text from the April 2015 dump (ca. 2.8B words),\n",
    "and using simple regular expressions to segment sentences\n",
    "and words, and remove URLs and punctuation. We perform\n",
    "no POS tagging, lemmatisation, case normalisation,\n",
    "or removal of numbers or symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import MWETokenizer\n",
    "\n",
    "from glove import Corpus, Glove\n",
    "\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "April is the fourth month of the year, and comes between March and May. \n",
      "\n",
      " It is one of four months to have 30 days. \n",
      "\n",
      " April always begins on the same day of week as July, and additionally, January in leap years. \n",
      "\n",
      " April always ends on the same day of the week as December. \n",
      "\n",
      " April's flowers are the Sweet Pea and Daisy. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# On Simple English wiki\n",
    "\n",
    "sf = open(datapath+'/Corpora/wiki/simple_20200601/simple_20200601_v2.txt', 'r', encoding='utf-8')\n",
    "\n",
    "for lines in range(5):\n",
    "    print(sf.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus.reader.plaintext import PlaintextCorpusReader\n",
    "\n",
    "from nltk.tokenize import WhitespaceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "simp = PlaintextCorpusReader(datapath+'/Corpora/wiki/simple_20200601/','simple_20200601_v2.txt',\n",
    "                            word_tokenizer = WhitespaceTokenizer()\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import word and sentence generators\n",
    "\n",
    "from generators import sent_gen, word_gen, Sent_Seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We collect word frequency information with the\n",
    "SRILM language modelling toolkit (Stolcke, 2002), counting\n",
    "n-grams (n <= 3), treating MWEs as contiguous bigrams\n",
    "and trigrams), and identify MWE candidates by computing\n",
    "the Poisson collocation measure (Quasthoff and Wolff,\n",
    "2002) for all bigrams and trigrams (ca. 23M n-grams).\n",
    "This method should be readily extensible to include longer\n",
    "n-grams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collate n-grams\n",
    "\n",
    "from nltk.collocations import BigramCollocationFinder, TrigramCollocationFinder\n",
    "\n",
    "from nltk.metrics import (\n",
    "    BigramAssocMeasures,\n",
    "    TrigramAssocMeasures,\n",
    "    NgramAssocMeasures,\n",
    ")\n",
    "\n",
    "from nltk.metrics.spearman import (\n",
    "    spearman_correlation,\n",
    "    ranks_from_scores,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load n-gram dataframe produced in word2vec iteration\n",
    "\n",
    "ngram_df = pd.read_pickle(datapath+'/Corpora/wiki/simple_20200601/ngram_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>freq</th>\n",
       "      <th>poisson</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>($-125,050, $17,122,936)</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.595935e+01</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(voleyu, spayana)</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.595935e+01</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(vote3, Jeff5/10)</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.595935e+01</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(vote11, Colby3/5)</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.595935e+01</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(vorskane, Lalvar)</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.595935e+01</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23342685</th>\n",
       "      <td>(and, the)</td>\n",
       "      <td>50287</td>\n",
       "      <td>-2.520684e+06</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23342686</th>\n",
       "      <td>(to, the)</td>\n",
       "      <td>62517</td>\n",
       "      <td>-3.073387e+06</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23342687</th>\n",
       "      <td>(is, a)</td>\n",
       "      <td>83617</td>\n",
       "      <td>-3.944892e+06</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23342688</th>\n",
       "      <td>(in, the)</td>\n",
       "      <td>157322</td>\n",
       "      <td>-7.610418e+06</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23342689</th>\n",
       "      <td>(of, the)</td>\n",
       "      <td>249437</td>\n",
       "      <td>-1.203139e+07</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23342690 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             ngram    freq       poisson  len\n",
       "0         ($-125,050, $17,122,936)       1 -2.595935e+01    2\n",
       "1                (voleyu, spayana)       1 -2.595935e+01    2\n",
       "2                (vote3, Jeff5/10)       1 -2.595935e+01    2\n",
       "3               (vote11, Colby3/5)       1 -2.595935e+01    2\n",
       "4               (vorskane, Lalvar)       1 -2.595935e+01    2\n",
       "...                            ...     ...           ...  ...\n",
       "23342685                (and, the)   50287 -2.520684e+06    2\n",
       "23342686                 (to, the)   62517 -3.073387e+06    2\n",
       "23342687                   (is, a)   83617 -3.944892e+06    2\n",
       "23342688                 (in, the)  157322 -7.610418e+06    2\n",
       "23342689                 (of, the)  249437 -1.203139e+07    2\n",
       "\n",
       "[23342690 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then automatically score the million most strongly associated\n",
    "n-grams (i.e., roughly the top 5% of the Poisson-ranked\n",
    "list) for compositionality.\n",
    "\n",
    "Using word2vec (Mikolov et al., 2013) with the parameters\n",
    "found to be most effective by Baroni et al. (2014), we\n",
    "build a word embedding vector for every simplex word in\n",
    "the vocabulary (ca. 1M types), as well as for each MWE candidate.\n",
    "\n",
    "* Continuous bag of words model with 400-dimensional vectors, window size 5, subsampling with t = 10^-5, negative sampling with 10 samples. We build vectors only for tokens observed 20 times or more in the corpus.\n",
    "\n",
    "We then compute the cosine similarity of the vector\n",
    "representation for a MWE candidate with the vectors of its\n",
    "constituent words, and take the arithmetic mean. \n",
    "In scoring\n",
    "the compositionality of a candidate, we do not measure the\n",
    "cosine similarity of the MWE with any stop words it may\n",
    "contain, as stop words may be assumed to be semantically\n",
    "uninformative.\n",
    "* Stop words are taken here to be the 50 most frequent words in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopwords from corpus - 50 most frequent\n",
    "from nltk import FreqDist\n",
    "\n",
    "fdist = FreqDist(word_gen(simp, sent_mark=''))\n",
    "\n",
    "stop = set( word for word, f in fdist.most_common(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " 'A',\n",
       " 'American',\n",
       " 'He',\n",
       " 'In',\n",
       " 'It',\n",
       " 'References',\n",
       " 'The',\n",
       " 'This',\n",
       " 'a',\n",
       " 'also',\n",
       " 'an',\n",
       " 'and',\n",
       " 'are',\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'born',\n",
       " 'by',\n",
       " 'can',\n",
       " 'first',\n",
       " 'for',\n",
       " 'from',\n",
       " 'had',\n",
       " 'has',\n",
       " 'have',\n",
       " 'he',\n",
       " 'his',\n",
       " 'in',\n",
       " 'is',\n",
       " 'it',\n",
       " 'not',\n",
       " 'of',\n",
       " 'on',\n",
       " 'one',\n",
       " 'or',\n",
       " 'people',\n",
       " 'that',\n",
       " 'the',\n",
       " 'their',\n",
       " 'they',\n",
       " 'to',\n",
       " 'was',\n",
       " 'were',\n",
       " 'which',\n",
       " 'with'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from batcher import batcher  # Custom module with logic for assigning n-grams to batches, avoiding overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_freq = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>freq</th>\n",
       "      <th>poisson</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Ving, Rhames)</td>\n",
       "      <td>20</td>\n",
       "      <td>-6.056256e+02</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Grădina, Zoologică)</td>\n",
       "      <td>20</td>\n",
       "      <td>-6.056256e+02</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Gharb-Chrarda-Beni, Hssen)</td>\n",
       "      <td>20</td>\n",
       "      <td>-6.056256e+02</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Karlovy, Vary)</td>\n",
       "      <td>20</td>\n",
       "      <td>-6.070334e+02</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(waystations, shuku-eki)</td>\n",
       "      <td>20</td>\n",
       "      <td>-6.070334e+02</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215905</th>\n",
       "      <td>(and, the)</td>\n",
       "      <td>50287</td>\n",
       "      <td>-2.520684e+06</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215906</th>\n",
       "      <td>(to, the)</td>\n",
       "      <td>62517</td>\n",
       "      <td>-3.073387e+06</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215907</th>\n",
       "      <td>(is, a)</td>\n",
       "      <td>83617</td>\n",
       "      <td>-3.944892e+06</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215908</th>\n",
       "      <td>(in, the)</td>\n",
       "      <td>157322</td>\n",
       "      <td>-7.610418e+06</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215909</th>\n",
       "      <td>(of, the)</td>\n",
       "      <td>249437</td>\n",
       "      <td>-1.203139e+07</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>215910 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              ngram    freq       poisson  len\n",
       "0                    (Ving, Rhames)      20 -6.056256e+02    2\n",
       "1              (Grădina, Zoologică)      20 -6.056256e+02    2\n",
       "2       (Gharb-Chrarda-Beni, Hssen)      20 -6.056256e+02    2\n",
       "3                   (Karlovy, Vary)      20 -6.070334e+02    2\n",
       "4          (waystations, shuku-eki)      20 -6.070334e+02    2\n",
       "...                             ...     ...           ...  ...\n",
       "215905                   (and, the)   50287 -2.520684e+06    2\n",
       "215906                    (to, the)   62517 -3.073387e+06    2\n",
       "215907                      (is, a)   83617 -3.944892e+06    2\n",
       "215908                    (in, the)  157322 -7.610418e+06    2\n",
       "215909                    (of, the)  249437 -1.203139e+07    2\n",
       "\n",
       "[215910 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Duplicate entries appearing for some reason. Removing here\n",
    "ngram_df2 = ngram_df[ngram_df.freq >= min_freq].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "ngram_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>freq</th>\n",
       "      <th>poisson</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Ving, Rhames)</td>\n",
       "      <td>20</td>\n",
       "      <td>-605.625590</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Grădina, Zoologică)</td>\n",
       "      <td>20</td>\n",
       "      <td>-605.625590</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Gharb-Chrarda-Beni, Hssen)</td>\n",
       "      <td>20</td>\n",
       "      <td>-605.625590</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Karlovy, Vary)</td>\n",
       "      <td>20</td>\n",
       "      <td>-607.033377</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(waystations, shuku-eki)</td>\n",
       "      <td>20</td>\n",
       "      <td>-607.033377</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149995</th>\n",
       "      <td>(first, country, to)</td>\n",
       "      <td>45</td>\n",
       "      <td>-3071.582792</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149996</th>\n",
       "      <td>(from, A)</td>\n",
       "      <td>58</td>\n",
       "      <td>-3071.612088</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149997</th>\n",
       "      <td>(1998, 8)</td>\n",
       "      <td>64</td>\n",
       "      <td>-3071.704678</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149998</th>\n",
       "      <td>(had, tested, positive)</td>\n",
       "      <td>55</td>\n",
       "      <td>-3071.728206</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149999</th>\n",
       "      <td>(23, 12)</td>\n",
       "      <td>64</td>\n",
       "      <td>-3071.731328</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              ngram  freq      poisson  len\n",
       "0                    (Ving, Rhames)    20  -605.625590    2\n",
       "1              (Grădina, Zoologică)    20  -605.625590    2\n",
       "2       (Gharb-Chrarda-Beni, Hssen)    20  -605.625590    2\n",
       "3                   (Karlovy, Vary)    20  -607.033377    2\n",
       "4          (waystations, shuku-eki)    20  -607.033377    2\n",
       "...                             ...   ...          ...  ...\n",
       "149995         (first, country, to)    45 -3071.582792    3\n",
       "149996                    (from, A)    58 -3071.612088    2\n",
       "149997                    (1998, 8)    64 -3071.704678    2\n",
       "149998      (had, tested, positive)    55 -3071.728206    3\n",
       "149999                     (23, 12)    64 -3071.731328    2\n",
       "\n",
       "[150000 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_count = 150000\n",
    "\n",
    "ngram_eval = ngram_df2[0:eval_count]\n",
    "\n",
    "ngram_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up\n",
    "del ngram_df, ngram_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('Ving', 'Rhames'): 1,\n",
       " ('Grădina', 'Zoologică'): 1,\n",
       " ('Gharb-Chrarda-Beni', 'Hssen'): 1,\n",
       " ('Karlovy', 'Vary'): 1,\n",
       " ('waystations', 'shuku-eki'): 1,\n",
       " ('Edinson', 'Cavani'): 1,\n",
       " ('Jule', 'Styne'): 1,\n",
       " ('Flèche', 'Wallonne'): 1,\n",
       " ('maillot', 'jaune'): 1,\n",
       " ('Puffy', 'AmiYumi'): 1,\n",
       " ('Aspleniaceae', 'Asplenium'): 1,\n",
       " ('Sheela', 'Shrinivas'): 1,\n",
       " ('Caid', 'Essebsi'): 1,\n",
       " ('Bellas', 'Artes'): 1,\n",
       " ('Sonu', 'Nigam'): 1,\n",
       " ('Päijänne', 'Tavastia'): 1,\n",
       " ('Lemony', 'Snicket'): 1,\n",
       " ('Trisha', 'Yearwood'): 1,\n",
       " ('Pim', 'Fortuyn'): 1,\n",
       " ('Dany', 'Heatley'): 1,\n",
       " ('BNP', 'Paribas'): 1,\n",
       " ('Jomo', 'Kenyatta'): 1,\n",
       " ('Liev', 'Schreiber'): 1,\n",
       " ('Bertolt', 'Brecht'): 1,\n",
       " ('bel', 'canto'): 1,\n",
       " ('Dukla', 'Jihlava'): 1,\n",
       " ('Lieke', 'Martens'): 1,\n",
       " ('Primorje-Gorski', 'Kotar'): 1,\n",
       " ('Luchino', 'Visconti'): 1,\n",
       " ('mutually', 'intelligible'): 1,\n",
       " ('conventionally', 'delimit'): 1,\n",
       " (\"Giant's\", 'Causeway'): 1,\n",
       " ('Ruhollah', 'Khomeini'): 1,\n",
       " ('Jair', 'Bolsonaro'): 1,\n",
       " ('Tomáš', 'Berdych'): 1,\n",
       " ('Hawaiian–Emperor', 'seamount'): 1,\n",
       " ('Tseung', 'Kwan'): 1,\n",
       " ('Sagrada', 'Familia'): 1,\n",
       " ('Geraniaceae', 'Geranium'): 1,\n",
       " ('Frida', 'Kahlo'): 1,\n",
       " ('Antonov', 'An-24'): 1,\n",
       " ('Gavrilo', 'Princip'): 1,\n",
       " ('SSE4.2', 'AVX'): 1,\n",
       " ('Goof', 'Troop'): 1,\n",
       " ('Mesut', 'Özil'): 1,\n",
       " ('Abdus', 'Salam'): 1,\n",
       " ('Zinedine', 'Zidane'): 1,\n",
       " ('Gabba', 'Gabba'): 1,\n",
       " ('Nanga', 'Parbat'): 1,\n",
       " ('Jallianwala', 'Bagh'): 1,\n",
       " ('Nute', 'Gunray'): 1,\n",
       " ('Nakhon', 'Nayok'): 1,\n",
       " ('Scrophulariaceae', 'Verbascum'): 1,\n",
       " ('Novaya', 'Zemlya'): 1,\n",
       " ('Sèvre', 'Nantaise'): 1,\n",
       " ('Futebol', 'Clube'): 1,\n",
       " ('Bilbo', 'Baggins'): 1,\n",
       " ('Paya', 'Lebar'): 1,\n",
       " ('white-headed', 'capuchin'): 1,\n",
       " ('Rikken', 'Seiyūkai'): 1,\n",
       " ('Pranab', 'Mukherjee'): 1,\n",
       " ('Rin', 'Kaiho'): 1,\n",
       " ('Dora', 'Baltea'): 1,\n",
       " ('Dumas', 'père'): 1,\n",
       " ('Bharat', 'Ratna'): 1,\n",
       " (\"D'Oyly\", 'Carte'): 1,\n",
       " (\"Pooh's\", 'Heffalump'): 1,\n",
       " ('Futurama', \"Bender's\"): 1,\n",
       " ('Gohar', 'Shahi'): 1,\n",
       " ('Elon', 'Musk'): 1,\n",
       " ('Pervez', 'Musharraf'): 1,\n",
       " ('Padraic', 'Colum'): 1,\n",
       " ('Priyanka', 'Chopra'): 1,\n",
       " ('hawk', 'Buteo'): 1,\n",
       " ('Ninoy', 'Aquino'): 1,\n",
       " ('Dominik', 'Hašek'): 1,\n",
       " ('Elmer', 'Gantry'): 1,\n",
       " ('Mila', 'Kunis'): 1,\n",
       " ('OUT', 'PASS'): 1,\n",
       " ('Rosemarie', 'DeWitt'): 1,\n",
       " ('Redbergslids', 'IK'): 1,\n",
       " ('Sagrada', 'Família'): 1,\n",
       " ('Chok', 'Tong'): 1,\n",
       " ('Orissa', 'N.A.C'): 1,\n",
       " ('Licinius', 'Crassus'): 1,\n",
       " ('Nathia', 'Gali'): 1,\n",
       " ('Vacheron', 'Constantin'): 1,\n",
       " ('Hansa', 'Rostock'): 1,\n",
       " ('Albacete', 'Balompié'): 1,\n",
       " ('ukiyo-e', 'woodblock'): 1,\n",
       " ('ZX', 'Spectrum'): 1,\n",
       " ('LUV', 'Graz'): 1,\n",
       " ('slime', 'moulds'): 1,\n",
       " ('CornwallKernow', 'LauncestonRural'): 1,\n",
       " ('CornwallKernow', 'LiskeardRural'): 1,\n",
       " ('Swizz', 'Beatz'): 1,\n",
       " ('Karbi', 'Anglong'): 1,\n",
       " ('Destiny', 'Fulfilled'): 1,\n",
       " ('Thora', 'Birch'): 1,\n",
       " ('Rennae', 'Stubbs'): 1,\n",
       " ('Rodrigo', 'Duterte'): 1,\n",
       " ('Kievan', 'Rus'): 1,\n",
       " ('LibDem', 'ALDE'): 1,\n",
       " ('Principia', 'Mathematica'): 1,\n",
       " ('subfamily', 'Asclepiadoideae'): 1,\n",
       " ('corpora', 'cavernosa'): 1,\n",
       " ('Elmer', 'Lach'): 1,\n",
       " ('Megan', 'Mullally'): 1,\n",
       " ('Jean-Pierre', 'Jabouille'): 1,\n",
       " ('zu', 'Guttenberg'): 1,\n",
       " ('Ústí', 'nad'): 1,\n",
       " ('Krazy', 'Kat'): 1,\n",
       " ('Vira', 'Gambarogno'): 1,\n",
       " ('Talladega', 'Superspeedway'): 1,\n",
       " ('Sant', 'Julià'): 1,\n",
       " ('Yul', 'Brynner'): 1,\n",
       " ('Kuch', 'Hota'): 1,\n",
       " ('Jürgen', 'Melzer'): 1,\n",
       " ('sprint', 'canoeist'): 1,\n",
       " ('Tsarevich', 'Alexei'): 1,\n",
       " ('ofthe', 'Senateacting'): 1,\n",
       " ('Angkor', 'Wat'): 1,\n",
       " ('Joachim', 'Löw'): 1,\n",
       " ('Sébastien', 'Buemi'): 1,\n",
       " ('Helicobacter', 'pylori'): 1,\n",
       " ('Herb', 'Alpert'): 1,\n",
       " ('Vyankatesh', 'Madgulkar'): 1,\n",
       " ('Vera', 'Zvonareva'): 1,\n",
       " ('Joo', 'Koon'): 1,\n",
       " ('Gus', 'Grissom'): 1,\n",
       " ('cognitive', 'neuropsychology'): 1,\n",
       " ('Schweizer', 'Hitparade'): 1,\n",
       " ('Dera', 'Ismail'): 1,\n",
       " ('Seongnam', 'Ilhwa'): 1,\n",
       " ('Tycho', 'Brahe'): 1,\n",
       " ('Eio', 'Sakata'): 1,\n",
       " ('Teemu', 'Selanne'): 1,\n",
       " ('FSV', 'Mainz'): 1,\n",
       " ('Wedding', 'Crashers'): 1,\n",
       " ('BELFAST', 'Belfast'): 1,\n",
       " ('Cosworth', 'CA2010'): 1,\n",
       " ('Dit', 'Clapper'): 1,\n",
       " ('CornwallKernow', 'Wadebridge'): 1,\n",
       " ('Milli', 'Vanilli'): 1,\n",
       " ('Swami', 'Vivekananda'): 1,\n",
       " ('Yuva', 'Puraskar'): 1,\n",
       " ('Wacker', 'Mödling'): 1,\n",
       " ('Tilda', 'Swinton'): 1,\n",
       " ('Coeur', \"d'Alene\"): 1,\n",
       " ('Mabillard', 'Operating'): 1,\n",
       " ('Nikolai', 'Volkoff'): 1,\n",
       " ('Eli', 'Wallach'): 1,\n",
       " ('Panjang', 'LRT'): 1,\n",
       " ('Salma', 'Hayek'): 1,\n",
       " ('Olivier', 'Panis'): 1,\n",
       " ('Hush', 'Hush'): 1,\n",
       " ('genital', 'mutilation'): 1,\n",
       " ('Steaua', 'București'): 1,\n",
       " ('chili', 'peppers'): 1,\n",
       " ('d’Art', 'Moderne'): 1,\n",
       " (\"Scribner's\", 'Sons'): 1,\n",
       " ('Jenny', 'Beavan'): 1,\n",
       " ('peremptory', 'challenges'): 1,\n",
       " ('retroflex', 'hook'): 1,\n",
       " ('Miloš', 'Forman'): 1,\n",
       " ('Mats', 'Sundin'): 1,\n",
       " ('PDF', 'eBook'): 1,\n",
       " ('Émile', 'Zola'): 1,\n",
       " ('Extreme', 'Makeover'): 1,\n",
       " ('Das', 'Rheingold'): 1,\n",
       " ('Stefan', 'Elmgren'): 1,\n",
       " ('Tau', 'Ceti'): 1,\n",
       " ('Communauté', 'urbaine'): 1,\n",
       " ('Yun', 'Chi-ho'): 1,\n",
       " ('Aviation', 'Factfile'): 1,\n",
       " ('Dianne', 'Feinstein'): 1,\n",
       " ('Raheem', 'Sterling'): 1,\n",
       " ('im', 'Mühlkreis'): 1,\n",
       " ('Grazer', 'AK'): 1,\n",
       " ('Franco', 'Zeffirelli'): 1,\n",
       " ('Drowning', 'Pool'): 1,\n",
       " ('Cartesian', 'coordinate'): 1,\n",
       " ('Goldie', 'Hawn'): 1,\n",
       " ('Rod', 'Laver'): 1,\n",
       " ('Wears', 'Prada'): 1,\n",
       " ('Amanda', 'Seyfried'): 1,\n",
       " ('voir', 'dire'): 1,\n",
       " ('Grignard', 'reagents'): 1,\n",
       " ('Denholm', 'Elliott'): 1,\n",
       " ('Hannibal', 'Lecter'): 1,\n",
       " ('Aardman', 'Animations'): 1,\n",
       " ('Towering', 'Inferno'): 1,\n",
       " ('Liza', 'Minnelli'): 1,\n",
       " ('Bibliographic', 'Resources'): 1,\n",
       " ('Tet', 'Offensive'): 1,\n",
       " ('Joey', 'Logano'): 1,\n",
       " ('Coup', \"d'état\"): 1,\n",
       " ('nausea', 'vomiting'): 1,\n",
       " ('Bonnie', 'Raitt'): 1,\n",
       " ('Zach', 'Galifianakis'): 1,\n",
       " ('8:00', '8:30'): 1,\n",
       " ('palatal', 'hook'): 1,\n",
       " ('Alexandra', 'Fyodorovna'): 1,\n",
       " ('Campanulaceae', 'Campanula'): 1,\n",
       " ('Genesis', 'Evangelion'): 1,\n",
       " ('Modest', 'Mussorgsky'): 1,\n",
       " ('Dawn', 'Treader'): 1,\n",
       " ('EPT', 'Intel'): 1,\n",
       " ('Fatehpur', 'Sikri'): 1,\n",
       " ('Boraginaceae', 'Miosotis'): 1,\n",
       " ('Loch', 'Lomond'): 1,\n",
       " ('Gisela', 'Dulko'): 1,\n",
       " ('im', 'Breisgau'): 1,\n",
       " ('Whatever', 'Happened'): 1,\n",
       " ('microwave', 'oven'): 1,\n",
       " ('Roberta', 'Flack'): 1,\n",
       " ('grenade', 'launcher'): 1,\n",
       " ('Espírito', 'Santo'): 1,\n",
       " ('Pierre-Simon', 'Laplace'): 1,\n",
       " ('WrestleMania', 'X-Seven'): 1,\n",
       " ('Snorri', 'Sturluson'): 1,\n",
       " ('tardive', 'dyskinesia'): 1,\n",
       " ('Zac', 'Efron'): 1,\n",
       " ('Lu', 'Xun'): 1,\n",
       " ('AM', '11:25'): 1,\n",
       " ('Yio', 'Chu'): 1,\n",
       " ('Cal', 'Ripken'): 1,\n",
       " ('Amon', 'Amarth'): 1,\n",
       " ('Denis', 'Potvin'): 1,\n",
       " ('Val', 'Kilmer'): 1,\n",
       " ('ISO', '3166-2:PY'): 1,\n",
       " ('Titus', \"O'Neil\"): 1,\n",
       " ('Solnhofen', 'limestone'): 1,\n",
       " ('Petticoat', 'Junction'): 1,\n",
       " ('Simchat', 'Torah'): 1,\n",
       " ('Roberto', 'Luongo'): 1,\n",
       " ('Stefan', 'Zweig'): 1,\n",
       " ('Frederik', 'Pohl'): 1,\n",
       " ('Eslamabad', 'Eslamabad'): 1,\n",
       " ('Barton', 'Fink'): 1,\n",
       " ('Sami', 'Zayn'): 1,\n",
       " ('Jugend', 'musiziert'): 1,\n",
       " ('jack', 'swing'): 1,\n",
       " ('Influences', 'link=Flag'): 1,\n",
       " ('Saillagouse', 'Prades'): 1,\n",
       " ('Lou', 'Gehrig'): 1,\n",
       " ('Tenzing', 'Norgay'): 1,\n",
       " ('North-West', 'Frontier'): 1,\n",
       " ('Chum', 'Bucket'): 1,\n",
       " ('toad', 'Ansonia'): 1,\n",
       " ('Columbian', 'Exposition'): 1,\n",
       " ('Ante', 'Pavelić'): 1,\n",
       " ('HDIs', 'Rank'): 1,\n",
       " ('Hurt', 'Locker'): 1,\n",
       " ('Yerba', 'Buena'): 1,\n",
       " ('Palos', 'Verdes'): 1,\n",
       " ('Quảng', 'Trị'): 1,\n",
       " ('Dordoi', 'Bishkek'): 1,\n",
       " ('increment:5', 'start:0'): 1,\n",
       " ('Târgu', 'Jiu'): 1,\n",
       " ('Soviet-Russian', 'cosmonaut'): 1,\n",
       " ('Elisabeth', 'Shue'): 1,\n",
       " ('Gou', 'Bu'): 1,\n",
       " ('Bodmin', 'Moor'): 1,\n",
       " ('Portrait', 'Born-Died'): 1,\n",
       " (\"Monster's\", 'Ball'): 1,\n",
       " ('Nielsen', 'SoundScan'): 1,\n",
       " ('Wang', 'Mang'): 1,\n",
       " ('Interior', 'Seaway'): 1,\n",
       " ('Aliabad', 'Aliabad'): 1,\n",
       " ('pelvic', 'fins'): 1,\n",
       " ('habeas', 'corpus'): 1,\n",
       " ('sigma', 'bond'): 1,\n",
       " ('Grosse', 'Pointe'): 1,\n",
       " ('Pierre-Auguste', 'Renoir'): 1,\n",
       " ('Ziggy', 'Stardust'): 1,\n",
       " ('Triple', \"H's\"): 1,\n",
       " ('Rita', 'Ora'): 1,\n",
       " ('Lou', 'Albano'): 1,\n",
       " ('Mauro', 'Vigliano'): 1,\n",
       " ('ottava', 'rima'): 1,\n",
       " ('Federally', 'Administered'): 1,\n",
       " ('Mumtaz', 'Mahal'): 1,\n",
       " ('AM', '12:30'): 1,\n",
       " ('Deutsche', 'Welle'): 1,\n",
       " ('Fawlty', 'Towers'): 1,\n",
       " ('Mickey', 'Rourke'): 1,\n",
       " ('Riemann', 'zeta'): 1,\n",
       " ('Cedars-Sinai', 'Medical'): 1,\n",
       " ('Crimean', 'Tatar'): 1,\n",
       " ('Adrian', 'Boult'): 1,\n",
       " ('Christiaan', 'Huygens'): 1,\n",
       " ('Scheduled', 'Tribes'): 1,\n",
       " ('Leading', 'goaltenders'): 1,\n",
       " ('Heather', 'Heyer'): 1,\n",
       " ('Palmyra', 'Atoll'): 1,\n",
       " ('BATE', 'Borisov'): 1,\n",
       " ('WrestleMania', 'XXVIII'): 1,\n",
       " ('Trois', 'Rivières'): 1,\n",
       " ('Eartha', 'Kitt'): 1,\n",
       " ('Aksai', 'Chin'): 1,\n",
       " ('Reggio', 'Calabria'): 1,\n",
       " ('Callicebus', 'Callicebus'): 1,\n",
       " ('mako', 'shark'): 1,\n",
       " ('Midway', 'Atoll'): 1,\n",
       " ('Wanda', 'Sykes'): 1,\n",
       " ('optic', 'nerve'): 1,\n",
       " ('Vittorio', 'Emanuele'): 1,\n",
       " ('Antonin', 'Scalia'): 1,\n",
       " ('Abi', 'Talib'): 1,\n",
       " ('Cowardly', 'Dog'): 1,\n",
       " ('attested', 'Poetic'): 1,\n",
       " ('Santiago', 'Bernabéu'): 1,\n",
       " ('Viet', 'Minh'): 1,\n",
       " ('barcelona.svg25x25px', 'rect'): 1,\n",
       " ('SPAD', 'XIII'): 1,\n",
       " ('polar', 'vortex'): 1,\n",
       " ('Raspberry', 'Pi'): 1,\n",
       " ('sodium', 'bicarbonate'): 1,\n",
       " ('Andre', 'Agassi'): 1,\n",
       " ('Irwin', 'Winkler'): 1,\n",
       " ('Petermann', 'Ranges'): 1,\n",
       " ('cellular', 'respiration'): 1,\n",
       " ('Butler', 'Yeats'): 1,\n",
       " ('Springer', 'C.H'): 1,\n",
       " ('Keynes', 'Dons'): 1,\n",
       " ('diamondback', 'rattlesnake'): 1,\n",
       " ('Roy', 'Salvadori'): 1,\n",
       " ('Otto', 'Preminger'): 1,\n",
       " ('Edd', 'n'): 1,\n",
       " ('Django', 'Unchained'): 1,\n",
       " ('Stills', 'Nash'): 1,\n",
       " ('Hiro', 'Yamamoto'): 1,\n",
       " ('Democracy', 'VVD'): 1,\n",
       " ('exclamation', 'mark'): 1,\n",
       " ('magnifying', 'glass'): 1,\n",
       " ('Ponta', 'Delgada'): 1,\n",
       " ('9:00', '9:30'): 1,\n",
       " ('Homeward', 'Bound'): 1,\n",
       " ('Zack', \"Snyder's\"): 1,\n",
       " ('Spike', 'Stent'): 1,\n",
       " ('Freddie', 'Prinze'): 1,\n",
       " ('Nico', 'Hülkenberg'): 1,\n",
       " ('Teutoburg', 'Forest'): 1,\n",
       " ('Grisons', 'Incorporated'): 1,\n",
       " ('Spécialisés', 'MS'): 1,\n",
       " ('extrasolar', 'planets'): 1,\n",
       " ('10:00', '10:30'): 1,\n",
       " ('Rosa', 'Luxemburg'): 1,\n",
       " ('Zatch', 'Bell'): 1,\n",
       " ('Kow', 'Swamp'): 1,\n",
       " ('dart', 'frogs'): 1,\n",
       " ('Taza-Al', 'Hoceima-Taounate'): 1,\n",
       " ('Ivor', 'Novello'): 1,\n",
       " ('Bedtime', 'Stories'): 1,\n",
       " ('Milkweed', 'Asclepias'): 1,\n",
       " ('LOW', 'IN'): 1,\n",
       " ('Prodigal', 'Son'): 1,\n",
       " ('Waheed', 'Murad'): 1,\n",
       " ('sparsely', 'populated'): 1,\n",
       " ('Elmer', 'Bernstein'): 1,\n",
       " ('Der', 'Rosenkavalier'): 1,\n",
       " ('sympathetic', 'nervous'): 1,\n",
       " ('Ian', 'Paice'): 1,\n",
       " ('Margot', 'Fonteyn'): 1,\n",
       " ('synthetic', 'polymer'): 1,\n",
       " ('Jake', 'Gyllenhaal'): 1,\n",
       " ('Things', 'Considered'): 1,\n",
       " ('militaires', \"d'aujourd'hui\"): 1,\n",
       " ('Sciences', 'AMPAS'): 1,\n",
       " ('Blurred', 'Lines'): 1,\n",
       " ('anal', 'fin'): 1,\n",
       " ('fluorescent', 'lamps'): 1,\n",
       " ('Reykjavík', 'Reykjavík'): 1,\n",
       " ('Eugene', 'Onegin'): 1,\n",
       " ('Fairy', 'Godmother'): 1,\n",
       " ('Hermit', 'Phaethornis'): 1,\n",
       " ('Syracuse', 'Crunch'): 1,\n",
       " ('Dave', 'Filoni'): 1,\n",
       " ('Mstislav', 'Rostropovich'): 1,\n",
       " ('Lex', 'Luger'): 1,\n",
       " ('Andretti', 'Lotus-Ford'): 1,\n",
       " ('der', 'Weyden'): 1,\n",
       " ('Nador', 'Oriental'): 1,\n",
       " ('Allison', 'Janney'): 1,\n",
       " ('Gary', 'Busey'): 1,\n",
       " ('Plessy', 'v'): 1,\n",
       " ('Sergei', 'Diaghilev'): 1,\n",
       " ('Jason', 'Statham'): 1,\n",
       " ('Thoroughly', 'Modern'): 1,\n",
       " ('Padma', 'Vibhushan'): 1,\n",
       " ('Lafcadio', 'Hearn'): 1,\n",
       " ('Suez', 'Crisis'): 1,\n",
       " ('Tenure', 'Elected'): 1,\n",
       " ('Wu-Tang', 'Clan'): 1,\n",
       " ('Damn', 'Thing'): 1,\n",
       " (\"B'Day\", 'Deluxe'): 1,\n",
       " ('Kim', 'Il-sung'): 1,\n",
       " ('Jean', 'Behra'): 1,\n",
       " ('Ko', 'Bop'): 1,\n",
       " ('Discovery', 'Discovered'): 1,\n",
       " ('Camera', 'Obscura'): 1,\n",
       " ('Depeche', 'Mode'): 1,\n",
       " ('Logan', 'Lerman'): 1,\n",
       " ('Dave', 'Grohl'): 1,\n",
       " ('Arkhangelsk', 'Oblast'): 1,\n",
       " ('sebaceous', 'glands'): 1,\n",
       " ('Modest', 'Mouse'): 1,\n",
       " ('Judging', 'Amy'): 1,\n",
       " ('Franz', 'Boas'): 1,\n",
       " ('saturated', 'fat'): 1,\n",
       " ('Zika', 'fever'): 1,\n",
       " ('Otto', 'Klemperer'): 1,\n",
       " ('Abdur', 'Rahman'): 1,\n",
       " ('Shah', 'Suri'): 1,\n",
       " ('Terre', 'Haute'): 1,\n",
       " ('Bastian', 'Dankert'): 1,\n",
       " ('CornwallKernow', 'KerrierRural'): 1,\n",
       " ('discus', 'throw'): 1,\n",
       " ('Fact', 'Sheet'): 1,\n",
       " ('Ivanovo', 'Oblast'): 1,\n",
       " ('512', 'MB'): 1,\n",
       " ('Da', 'Nang'): 1,\n",
       " ('Parti', 'Québécois'): 1,\n",
       " ('Kazi', 'Hayat'): 1,\n",
       " ('Werner', 'Herzog'): 1,\n",
       " ('Hidden', 'Leaf'): 1,\n",
       " ('spiny', 'dogfish'): 1,\n",
       " ('Angela', 'Bassett'): 1,\n",
       " ('1-2', '0-0'): 1,\n",
       " ('Anatoly', 'Karpov'): 1,\n",
       " ('Alan', 'Tudyk'): 1,\n",
       " ('Greater', 'Noida'): 1,\n",
       " ('barium', 'sulfate'): 1,\n",
       " ('ballistic', 'missile'): 1,\n",
       " ('Thoroughbred', 'racehorse'): 1,\n",
       " ('NCAA', 'Div'): 1,\n",
       " ('wheat', 'barley'): 1,\n",
       " ('Upton', 'Sinclair'): 1,\n",
       " ('Jarome', 'Iginla'): 1,\n",
       " ('Data', 'Encryption'): 1,\n",
       " ('Luc', 'Besson'): 1,\n",
       " ('serial', 'killers'): 1,\n",
       " ('De', 'Bruyne'): 1,\n",
       " ('mutual', 'funds'): 1,\n",
       " ('mood', 'swings'): 1,\n",
       " ('Pritzker', 'Architecture'): 1,\n",
       " ('Mad', 'Hatter'): 1,\n",
       " ('Donde', 'Quiera'): 1,\n",
       " ('Damien', 'Sandow'): 1,\n",
       " ('Pierre', 'Pilote'): 1,\n",
       " ('Worlds', 'Collide'): 1,\n",
       " ('Ababa', 'Ethiopia'): 1,\n",
       " ('Slovan', 'Bratislava'): 1,\n",
       " ('Drug', 'Enforcement'): 1,\n",
       " ('Iggy', 'Azalea'): 1,\n",
       " ('Pavel', 'Datsyuk'): 1,\n",
       " ('Gene', 'Roddenberry'): 1,\n",
       " ('Turbine', 'Potsdam'): 1,\n",
       " ('Dead', 'Kennedys'): 1,\n",
       " ('van', 'Leeuwenhoek'): 1,\n",
       " ('Offenbach', 'Rural'): 1,\n",
       " ('Lorenzo', 'Bandini'): 1,\n",
       " ('Pictures', 'Imageworks'): 1,\n",
       " ('Nationality', 'Passengers'): 1,\n",
       " ('IFPI', 'DEN'): 1,\n",
       " ('Simon', 'Pegg'): 1,\n",
       " ('low-cost', 'airline'): 1,\n",
       " ('Ub', 'Iwerks'): 1,\n",
       " ('Challengers', 'Bangalore'): 1,\n",
       " ('Henrik', \"Ibsen's\"): 1,\n",
       " ('OT', 'Decision'): 1,\n",
       " ('Joshua', 'Lederberg'): 1,\n",
       " ('Marisa', 'Tomei'): 1,\n",
       " ('Kid', 'Icarus'): 1,\n",
       " ('Jacinda', 'Ardern'): 1,\n",
       " ('mécanique', 'et'): 1,\n",
       " ('PWI', 'Feud'): 1,\n",
       " ('Male', 'Playback'): 1,\n",
       " ('Wins', 'Constructor'): 1,\n",
       " ('Toney', 'Douglas'): 1,\n",
       " ('Compact', '1620'): 1,\n",
       " ('pointed', 'arches'): 1,\n",
       " ('Allama', 'Iqbal'): 1,\n",
       " ('Lorin', 'Maazel'): 1,\n",
       " ('Agusan', 'del'): 1,\n",
       " ('Unix-like', 'operating'): 1,\n",
       " ('Charlotte', 'Bobcats'): 1,\n",
       " ('SN2', 'reaction'): 1,\n",
       " ('selective', 'breeding'): 1,\n",
       " ('Bob', 'Mittenthal'): 1,\n",
       " (\"Winter's\", 'Tale'): 1,\n",
       " ('von', 'Stauffenberg'): 1,\n",
       " ('Milan', 'Image:Francesco'): 1,\n",
       " ('Secretary', 'Lionizes'): 1,\n",
       " ('Bambi', 'Bambi'): 1,\n",
       " ('HMS', 'Sirius'): 1,\n",
       " ('action', 'Notes/Reference'): 1,\n",
       " ('ECHL', 'affiliate'): 1,\n",
       " ('Auguste', 'Comte'): 1,\n",
       " ('Rick', 'Rude'): 1,\n",
       " ('Truman', 'Capote'): 1,\n",
       " ('Demilitarized', 'Zone'): 1,\n",
       " ('Z', 'bosons'): 1,\n",
       " ('Mohs', 'scale'): 1,\n",
       " ('Gene', 'Autry'): 1,\n",
       " ('Highness', 'Mademoiselle'): 1,\n",
       " ('Chernin', 'Entertainment'): 1,\n",
       " ('Grande', 'Comore'): 1,\n",
       " ('Terry', 'Gilliam'): 1,\n",
       " ('OppositionScore', 'OppositionScore'): 1,\n",
       " ('Ordnance', 'Survey'): 1,\n",
       " ('Lone', 'Pine'): 1,\n",
       " ('extrasolar', 'planet'): 1,\n",
       " ('Hiroshige', '1853'): 1,\n",
       " ('Consejo', 'Mundial'): 1,\n",
       " ('Ginny', 'Weasley'): 1,\n",
       " ('Christina', 'Milian'): 1,\n",
       " ('Nürburgring', 'Nordschleife'): 1,\n",
       " ('cracked', 'nipples'): 1,\n",
       " ('Leaning', 'Tower'): 1,\n",
       " ('Wrestling', 'Entertainment/WWE'): 1,\n",
       " ('stationary', 'phase'): 1,\n",
       " ('Knocked', 'Up'): 1,\n",
       " ('Bryan', 'Cranston'): 1,\n",
       " ('Khalid', 'bin'): 1,\n",
       " ('OT', 'Khabibulin'): 1,\n",
       " ('HC', 'Lugano'): 1,\n",
       " ('Cultural:(ii', 'iv'): 1,\n",
       " ('Impressionist', 'painters'): 1,\n",
       " ('Joan', 'Cusack'): 1,\n",
       " ('Shi', 'Huang'): 1,\n",
       " ('Busher', 'Jackson'): 1,\n",
       " ('Ben', 'Chifley'): 1,\n",
       " ('oriole', 'Oriolus'): 1,\n",
       " ('Anton', 'Rubinstein'): 1,\n",
       " ('Nominee', 'Result'): 1,\n",
       " ('Taarak', 'Mehta'): 1,\n",
       " ('Gustav', 'Klimt'): 1,\n",
       " ('Reader', 'Uncle'): 1,\n",
       " ('Eric', 'Idle'): 1,\n",
       " ('feeding', 'habits'): 1,\n",
       " ('Josh', 'Hutcherson'): 1,\n",
       " ('Pinetop', 'Perkins'): 1,\n",
       " ('Date', 'ofqualification'): 1,\n",
       " ('Theoretical', 'Physics'): 1,\n",
       " ('prima', 'ballerina'): 1,\n",
       " ('Lucky', 'Strike'): 1,\n",
       " ('Wave', 'Kitakyushu'): 1,\n",
       " ('Nawaz', 'Sharif'): 1,\n",
       " ('mental', 'retardation'): 1,\n",
       " ('Ivan', 'Lendl'): 1,\n",
       " ('Ordre', 'des'): 1,\n",
       " ('radiocarbon', 'dating'): 1,\n",
       " ('Jim', 'Sturgess'): 1,\n",
       " ('Anton', 'Chekhov'): 1,\n",
       " ('Blast', 'Off'): 1,\n",
       " ('Chiltern', 'Railways'): 1,\n",
       " ('Matt', 'Striker'): 1,\n",
       " ('Veterinary', 'Medicine'): 1,\n",
       " ('Ernest', 'Borgnine'): 1,\n",
       " ('70', 'Virginis'): 1,\n",
       " ('Zebulon', 'Pike'): 1,\n",
       " ('bombs', 'explode'): 1,\n",
       " ('Belle', 'Plaine'): 1,\n",
       " ('Giovanni', 'Boccaccio'): 1,\n",
       " ('Magnus', 'Rosén'): 1,\n",
       " ('facial', 'expressions'): 1,\n",
       " ('Flinders', 'Ranges'): 1,\n",
       " ('Mama', 'Thornton'): 1,\n",
       " ('0600', 'UTC'): 1,\n",
       " ('Mortal', 'Engines'): 1,\n",
       " ('breakfast', 'cereal'): 1,\n",
       " ('Starship', 'Troopers'): 1,\n",
       " ('Bela', 'Lugosi'): 1,\n",
       " ('Emma', 'Lazarus'): 1,\n",
       " ('Campeonato', 'Paulista'): 1,\n",
       " ('Ferris', \"Bueller's\"): 1,\n",
       " ('Jason', 'Isaacs'): 1,\n",
       " ('Shayne', 'Topp'): 1,\n",
       " ('Serbs', 'Croats'): 1,\n",
       " ('smallmouth', 'bass'): 1,\n",
       " ('venomous', 'snake'): 1,\n",
       " ('Glory', 'glory'): 1,\n",
       " ('Usos', 'Jimmy'): 1,\n",
       " ('Neo', 'Geo'): 1,\n",
       " ('Arthurian', 'legend'): 1,\n",
       " ('hemorrhagic', 'fever'): 1,\n",
       " ('Relay', 'Chat'): 1,\n",
       " ('Short', 'Cuts'): 1,\n",
       " ('conjoined', 'twins'): 1,\n",
       " ('Eddie', 'Izzard'): 1,\n",
       " ('Judd', 'Apatow'): 1,\n",
       " ('Nashville', 'Tenn'): 1,\n",
       " ('venomous', 'snakes'): 1,\n",
       " ('Pink', \"Floyd's\"): 1,\n",
       " ('Melanie', 'Griffith'): 1,\n",
       " (\"Planck's\", 'constant'): 1,\n",
       " ('Any', 'Given'): 1,\n",
       " ('gut', 'flora'): 1,\n",
       " ('Roger', 'Crozier'): 1,\n",
       " ('Mark', 'Recchi'): 1,\n",
       " ('von', 'Trips'): 1,\n",
       " ('Internet', 'Off-Broadway'): 1,\n",
       " ('la', 'Maguana'): 1,\n",
       " ('high-level', 'programming'): 1,\n",
       " ('Solid', 'Snake'): 1,\n",
       " ('Lily', 'Tomlin'): 1,\n",
       " ('Vauxhall', 'Gardens'): 1,\n",
       " ('Pro', 'Patria'): 1,\n",
       " ('Miami', 'Marlins'): 1,\n",
       " ('Hill', 'Tracts'): 1,\n",
       " ('Las', 'Casas'): 1,\n",
       " ('Ava', 'Gardner'): 1,\n",
       " ('Jeffrey', 'Epstein'): 1,\n",
       " ('aus', 'dem'): 1,\n",
       " ('epithelial', 'cells'): 1,\n",
       " ('dendritic', 'cells'): 1,\n",
       " ('Add', 'Water'): 1,\n",
       " ('Decade-end', 'charts'): 1,\n",
       " ('Patrick', 'Stump'): 1,\n",
       " ('conspicuous', 'gallantry'): 1,\n",
       " ('Sima', 'Qian'): 1,\n",
       " (\"driver's\", 'license'): 1,\n",
       " ('Political', 'Cesspool'): 1,\n",
       " ('Aaron', 'Klug'): 1,\n",
       " ('Rudolph', 'Valentino'): 1,\n",
       " ('Syriac', 'Orthodox'): 1,\n",
       " ('Faye', 'Dunaway'): 1,\n",
       " ('Kharosthi', 'transliteration'): 1,\n",
       " ('Space', 'Needle'): 1,\n",
       " ('hammer', 'thrower'): 1,\n",
       " ('climate', 'Csa'): 1,\n",
       " ('Navajo', 'Nation'): 1,\n",
       " ('Sankt', 'Georgen'): 1,\n",
       " ('Ryan', 'Gosling'): 1,\n",
       " ('Keke', 'Palmer'): 1,\n",
       " ('Metal', 'Jacket'): 1,\n",
       " ('Mark', 'Ruffalo'): 1,\n",
       " ('Rubén', 'Darío'): 1,\n",
       " ('Lana', 'Turner'): 1,\n",
       " ('unmarked', 'grave'): 1,\n",
       " ('EUR', 'SMR'): 1,\n",
       " ('Colts', 'Quarterback'): 1,\n",
       " ('Quiero', 'Saber'): 1,\n",
       " ('Kingsley', 'Amis'): 1,\n",
       " ('Bhagavad', 'Gita'): 1,\n",
       " ('Tropical', 'Cyclones'): 1,\n",
       " ('Dharma', 'Greg'): 1,\n",
       " ('Ursae', 'Majoris'): 1,\n",
       " ('Eureka', 'Stockade'): 1,\n",
       " ('Venue', 'Opponent'): 1,\n",
       " ('Pop.2009', 'Capital'): 1,\n",
       " ('Kiefer', 'Sutherland'): 1,\n",
       " ('Markup', 'Language'): 1,\n",
       " ('Punggol', 'LRT'): 1,\n",
       " ('Henri', 'Matisse'): 1,\n",
       " ('Communist', 'Manifesto'): 1,\n",
       " ('Promotional', 'singles'): 1,\n",
       " ('Sustainable', 'Development'): 1,\n",
       " ('Oscar', 'Niemeyer'): 1,\n",
       " ('Frank', 'Darabont'): 1,\n",
       " ('Idi', 'Amin'): 1,\n",
       " ('Daniel', 'Ricciardo'): 1,\n",
       " ('Manuel', 'Neuer'): 1,\n",
       " ('deck', 'Ikarus'): 1,\n",
       " ('Visiting', 'Professor'): 1,\n",
       " ('Paolo', 'Valeri'): 1,\n",
       " ('Arminia', 'Bielefeld'): 1,\n",
       " ('Domestic', 'Product'): 1,\n",
       " ('Katarina', 'Srebotnik'): 1,\n",
       " ('JYP', 'Entertainment'): 1,\n",
       " ('Bergen-Belsen', 'concentration'): 1,\n",
       " ('draft', 'picks'): 1,\n",
       " ('Mount', 'Elbrus'): 1,\n",
       " ('deck', 'Leyland'): 1,\n",
       " ('Emigrant', 'Aid'): 1,\n",
       " ('Linux', 'Mint'): 1,\n",
       " ('Crispus', 'Attucks'): 1,\n",
       " ('Global', 'Warming'): 1,\n",
       " ('OTL', 'Pts'): 1,\n",
       " ('depressive', 'disorder'): 1,\n",
       " (\"Queen's\", 'Birthday'): 1,\n",
       " ('scarlet', 'fever'): 1,\n",
       " ('Květa', 'Peschke'): 1,\n",
       " ('Memphis', 'Grizzlies'): 1,\n",
       " ('Copley', 'Medal'): 1,\n",
       " ('Airbus', 'A310'): 1,\n",
       " ('Hugo', 'Weaving'): 1,\n",
       " ('Cardenal', 'Caro'): 1,\n",
       " ('Strange', 'Case'): 1,\n",
       " ('Martín', 'Fierro'): 1,\n",
       " (\"Fermat's\", 'Last'): 1,\n",
       " ('Aldeburgh', 'Festival'): 1,\n",
       " ('Accademia', 'di'): 1,\n",
       " ('Nate', 'Dogg'): 1,\n",
       " ('pound', 'sterling'): 1,\n",
       " ('continental', 'shelves'): 1,\n",
       " ('Smoky', 'Hills'): 1,\n",
       " ('Alec', 'Schwimmer'): 1,\n",
       " ('webbed', 'feet'): 1,\n",
       " ('Big', 'Lebowski'): 1,\n",
       " ('Akira', 'Taue'): 1,\n",
       " ('RNA', 'interference'): 1,\n",
       " ('Carbon', 'monoxide'): 1,\n",
       " ('mm', 'howitzer'): 1,\n",
       " ('falling', 'asleep'): 1,\n",
       " ('Upper', 'Carniola'): 1,\n",
       " ('fantasy', 'role-playing'): 1,\n",
       " (\"Hatteberg's\", 'People'): 1,\n",
       " ('3–1', '2–0'): 1,\n",
       " ('Balls', 'Mahoney'): 1,\n",
       " ('air', 'conditioner'): 1,\n",
       " ('shopping', 'centres'): 1,\n",
       " ('Giravanz', 'Kitakyushu'): 1,\n",
       " ('Zyklon', 'B'): 1,\n",
       " ('Eva', 'Perón'): 1,\n",
       " ('Who', 'Knew'): 1,\n",
       " ('mud', 'volcanoes'): 1,\n",
       " ('Hapoel', 'Tel'): 1,\n",
       " ('Papunya', 'Tula'): 1,\n",
       " ('Low', 'Saxon'): 1,\n",
       " ('anxiety', 'disorders'): 1,\n",
       " ('Emperor', 'Go-Daigo'): 1,\n",
       " ('Morphin', 'Power'): 1,\n",
       " ('GB', 'discontinued'): 1,\n",
       " ('Shōnen', 'Jump'): 1,\n",
       " ('Ramsay', 'MacDonald'): 1,\n",
       " (\"women's\", 'lacrosse'): 1,\n",
       " ('Project', 'Syndicate'): 1,\n",
       " ('Tenth', 'row'): 1,\n",
       " ('penalty', 'shootout'): 1,\n",
       " ('NASL', 'Quarterfinal'): 1,\n",
       " ('Bloomfield', 'Hills'): 1,\n",
       " ('Governing', 'Board'): 1,\n",
       " ('Tao', 'Te'): 1,\n",
       " ('airplay', 'spins'): 1,\n",
       " ('Fifty-three', 'Stations'): 1,\n",
       " ('Princess', 'Leia'): 1,\n",
       " ('Bangor', 'Maine'): 1,\n",
       " ('black', 'mamba'): 1,\n",
       " ('Landry', 'Fields'): 1,\n",
       " ('blood', 'clots'): 1,\n",
       " ('Dr', 'Eggman'): 1,\n",
       " ('Spirit', 'Stallion'): 1,\n",
       " ('igneous', 'rocks'): 1,\n",
       " ('Stevie', 'Richards'): 1,\n",
       " ('Nath', 'Kovind'): 1,\n",
       " ('meter', 'breaststroke'): 1,\n",
       " ('Heian', 'Period'): 1,\n",
       " ('steam', 'turbine'): 1,\n",
       " ('PadstowRural', 'District'): 1,\n",
       " ('Minami-Katsushika', 'District'): 1,\n",
       " ('Kita-Toshima', 'District'): 1,\n",
       " ('direct-to-video', 'sequel'): 1,\n",
       " ('Pall', 'Mall'): 1,\n",
       " ('Gallant', 'conduct'): 1,\n",
       " ('m', 'T11'): 1,\n",
       " ('KAKE', 'TV'): 1,\n",
       " ('allergic', 'reaction'): 1,\n",
       " ('Edgar', 'Degas'): 1,\n",
       " ('Municipality(code', 'Municipal'): 1,\n",
       " ('Spoken', 'Word'): 1,\n",
       " ('P', 'Worrell'): 1,\n",
       " ('Distrito', 'Federal'): 1,\n",
       " ('Matt', 'Vogel'): 1,\n",
       " ('Monts', 'du'): 1,\n",
       " ('leaf', 'litter'): 1,\n",
       " ('Wiley', 'Sons'): 1,\n",
       " ('Christoph', 'Waltz'): 1,\n",
       " ('Rancho', 'Mirage'): 1,\n",
       " ('Sam', 'Peckinpah'): 1,\n",
       " ('Luke', 'Gallows'): 1,\n",
       " ('Mark', 'Ronson'): 1,\n",
       " ('presiding', 'officer'): 1,\n",
       " ('2011–12', '2012–13'): 1,\n",
       " ('Thalia', 'Grace'): 1,\n",
       " ('Jürgen', 'Klinsmann'): 1,\n",
       " ('Tenzin', 'Gyatso'): 1,\n",
       " ('Cable', 'Car'): 1,\n",
       " ('3-car', 'sets'): 1,\n",
       " ('Grand', 'Coulee'): 1,\n",
       " ('Sirimavo', 'Bandaranaike'): 1,\n",
       " ('Sixtus', 'IV'): 1,\n",
       " ('coconut', 'milk'): 1,\n",
       " ('injuries', 'sustained'): 1,\n",
       " ('upper-level', 'low'): 1,\n",
       " ('Dead', 'Redemption'): 1,\n",
       " ('SUI', 'ITA'): 1,\n",
       " ('Darkwing', 'Duck'): 1,\n",
       " ('Nationalteam', 'Goalkeeper'): 1,\n",
       " ('mourning', 'dove'): 1,\n",
       " ('El', 'Tigre'): 1,\n",
       " ('Nicole', 'Scherzinger'): 1,\n",
       " ('Mildred', 'Pierce'): 1,\n",
       " ('Tony', 'Kanal'): 1,\n",
       " ('Lachlan', 'Macquarie'): 1,\n",
       " ('Stranger', 'Tides'): 1,\n",
       " ('Las', 'Cruces'): 1,\n",
       " ('Team', 'Milram'): 1,\n",
       " ('Nintendo', 'eShop'): 1,\n",
       " ('Liga', 'Honra'): 1,\n",
       " ('Getty', 'Conservation'): 1,\n",
       " ('Sahrawi', 'Arab'): 1,\n",
       " ('Timothy', 'McVeigh'): 1,\n",
       " ('Charlotte', 'Hornets'): 1,\n",
       " ('see', 'camo'): 1,\n",
       " ('Tim', 'Hedrick'): 1,\n",
       " ('ski', 'racer'): 1,\n",
       " ('Jeff', 'Hanneman'): 1,\n",
       " ('compact', 'discs'): 1,\n",
       " ('Magnus', 'Carlsen'): 1,\n",
       " ('x', '4-car'): 1,\n",
       " ('Paul', 'Pogba'): 1,\n",
       " (\"Bob's\", 'Burgers'): 1,\n",
       " ('Ernest', 'Giles'): 1,\n",
       " ('Boeing', '717'): 1,\n",
       " ('Astronomer', 'Royal'): 1,\n",
       " ('Otto', 'Hahn'): 1,\n",
       " ('Principal', 'photography'): 1,\n",
       " ('Gold', 'Glove'): 1,\n",
       " ('bald', 'eagles'): 1,\n",
       " ('Reading', 'Berkshire'): 1,\n",
       " ('UCLA', 'Medical'): 1,\n",
       " ('hind', 'wings'): 1,\n",
       " ('Overall', 'Vuelta'): 1,\n",
       " ('barometric', 'pressure'): 1,\n",
       " ('dengue', 'virus'): 1,\n",
       " ('dressing', 'room'): 1,\n",
       " (\"James's\", 'Palace'): 1,\n",
       " ('Ebara', 'District'): 1,\n",
       " ('Gene', 'Wilder'): 1,\n",
       " ('Pour', 'le'): 1,\n",
       " ('R', \"Tolkien's\"): 1,\n",
       " ('Vassar', 'College'): 1,\n",
       " ('Venice', 'Biennale'): 1,\n",
       " ('neural', 'network'): 1,\n",
       " ('Ninth', 'row'): 1,\n",
       " ('honorary', 'doctorates'): 1,\n",
       " ('autonomic', 'nervous'): 1,\n",
       " ('Khan', 'Jahangir'): 1,\n",
       " ('legislative', 'assembly'): 1,\n",
       " ('Voice', 'roleEpisode'): 1,\n",
       " ('bar:g', 'from:0'): 1,\n",
       " ('Honorary', 'Doctorate'): 1,\n",
       " ('EHC', 'Biel'): 1,\n",
       " ('B-2', 'B-2'): 1,\n",
       " ('Naomi', 'Watts'): 1,\n",
       " ('Goodison', 'Park'): 1,\n",
       " ('glam', 'rock'): 1,\n",
       " ('Gaon', 'Digital'): 1,\n",
       " ('Finding', 'Neverland'): 1,\n",
       " ('vegetable', 'oils'): 1,\n",
       " ('Very', 'Merry'): 1,\n",
       " ('Sierra', 'Leonean'): 1,\n",
       " ('supernatural', 'horror'): 1,\n",
       " ('Vegas', 'Strip'): 1,\n",
       " ('Van', 'Doren'): 1,\n",
       " ('Laraine', 'Newman'): 1,\n",
       " ('Caine', 'Mutiny'): 1,\n",
       " ('Louise', \"d'Orléans\"): 1,\n",
       " ('chewing', 'gum'): 1,\n",
       " ('Stood', 'Still'): 1,\n",
       " ('Cautín', 'Flag'): 1,\n",
       " ('treble', 'clef'): 1,\n",
       " ('Most', 'Hated'): 1,\n",
       " ('Brian', 'Dennehy'): 1,\n",
       " ('environmentally', 'friendly'): 1,\n",
       " ('Down', 'Syndrome'): 1,\n",
       " ('Fiona', 'Apple'): 1,\n",
       " ('Matchbox', 'Twenty'): 1,\n",
       " ('Jiminy', 'Cricket'): 1,\n",
       " ('estimate', 'Surface'): 1,\n",
       " ('classic', 'qualification'): 1,\n",
       " ('antimony', 'trioxide'): 1,\n",
       " ('Federalist', 'Papers'): 1,\n",
       " ('rukus', 'Madinan'): 1,\n",
       " ('Legend', 'Continues'): 1,\n",
       " ('Kelsey', 'Grammer'): 1,\n",
       " ('Bardsey', 'Island'): 1,\n",
       " ('pencils', 'Hex'): 1,\n",
       " ('Bill', 'Withers'): 1,\n",
       " ('WCW', 'Cruiserweight'): 1,\n",
       " ('aluminium', 'oxide'): 1,\n",
       " ('Kitty', 'Hawk'): 1,\n",
       " ('Eighth', 'Avenue'): 1,\n",
       " ('Stringybark', 'Creek'): 1,\n",
       " ('David', 'Thewlis'): 1,\n",
       " ('Collision', 'Course'): 1,\n",
       " ('p.m', 'CDT'): 1,\n",
       " ('laryngeal', 'cancer'): 1,\n",
       " ('Eighth', 'row'): 1,\n",
       " ('Harold', 'Arlen'): 1,\n",
       " ('gamma', 'ray'): 1,\n",
       " ('bombing', 'raid'): 1,\n",
       " ('Axl', 'Rotten'): 1,\n",
       " ('Marc', 'Ceccarelli'): 1,\n",
       " ('Ullman', 'Show'): 1,\n",
       " ('Azerbaijani', 'Armed'): 1,\n",
       " ('Coastal', 'Plain'): 1,\n",
       " ('Junkers', 'Ju'): 1,\n",
       " ('$1.5', 'billion'): 1,\n",
       " ('Jesse', 'Owens'): 1,\n",
       " ('Austin', 'Ally'): 1,\n",
       " ('Justin', 'Credible'): 1,\n",
       " ('Nanny', 'McPhee'): 1,\n",
       " ('HC', 'Kladno'): 1,\n",
       " ('Loretta', 'Lynn'): 1,\n",
       " ('Saints', 'Row'): 1,\n",
       " ('Counter', 'Culture'): 1,\n",
       " ('Colombo', 'Sri'): 1,\n",
       " ('Verbandsgemeinde', '2town'): 1,\n",
       " ('George', 'Peppard'): 1,\n",
       " ('Magnum', 'P.I'): 1,\n",
       " ('Airbus', 'A340'): 1,\n",
       " ('Barbadian', 'recording'): 1,\n",
       " ('Team', 'CSC'): 1,\n",
       " ('Tank', 'Engine'): 1,\n",
       " ('Of', 'Mice'): 1,\n",
       " ('Bruce', 'Cabot'): 1,\n",
       " ('Kirov', 'Oblast'): 1,\n",
       " ('Bruno', 'Sammartino'): 1,\n",
       " ('Donald', 'Rumsfeld'): 1,\n",
       " ('Point', 'Pleasant'): 1,\n",
       " ('Alessandro', 'Nannini'): 1,\n",
       " ('Rip', 'Torn'): 1,\n",
       " ('Minneapolis', 'Millers'): 1,\n",
       " ('gravitational', 'potential'): 1,\n",
       " ('Morioka', 'Regional'): 1,\n",
       " ('$250,000', 'Court'): 1,\n",
       " ('Rif', 'Dimashq'): 1,\n",
       " ('venture', 'capitalist'): 1,\n",
       " ('Poaceae', 'Poa'): 1,\n",
       " ('Idaho', 'Tourtellotte'): 1,\n",
       " ('Triassic', 'herbivore'): 1,\n",
       " ('Mitch', 'McConnell'): 1,\n",
       " ('investigative', 'journalist'): 1,\n",
       " ('Psychiatric', 'Association'): 1,\n",
       " ('Trek', 'Enterprise'): 1,\n",
       " ('Golf', 'Course'): 1,\n",
       " ('floppy', 'disks'): 1,\n",
       " ('Mary-Louise', 'Parker'): 1,\n",
       " ('Lansing', 'Michigan'): 1,\n",
       " ('Nuclear', 'fusion'): 1,\n",
       " ('ABS-CBN', 'CorporationCurrently'): 1,\n",
       " ('fig', 'tree'): 1,\n",
       " ('Navassa', 'Island'): 1,\n",
       " ('Mount', 'Kisco'): 1,\n",
       " ('Mladá', 'Boleslav'): 1,\n",
       " ('Blazing', 'Saddles'): 1,\n",
       " ('Munnetra', 'Kazhagam'): 1,\n",
       " ('SWI', 'Platinum'): 1,\n",
       " ('Leicester', 'Tigers'): 1,\n",
       " ('sponsorship', 'reasons'): 1,\n",
       " ('multicellular', 'organisms'): 1,\n",
       " ('Stanley', 'Steamer'): 1,\n",
       " ('borderline', 'personality'): 1,\n",
       " ('warm-blooded', 'animals'): 1,\n",
       " ('1–1', '5–1'): 1,\n",
       " ('Field', 'Recap'): 1,\n",
       " ('Botev', 'Plovdiv'): 1,\n",
       " ('Barclays', 'Center'): 1,\n",
       " ('rule', 'Radu'): 1,\n",
       " ('confidence', 'interval'): 1,\n",
       " ('Scrolls', 'IV'): 1,\n",
       " ('Playboy', 'Playmate'): 1,\n",
       " ('Richard', 'Dreyfuss'): 1,\n",
       " ('belly', 'button'): 1,\n",
       " ('Sakhalin', 'Oblast'): 1,\n",
       " ('Tottori', 'Prefecture'): 1,\n",
       " ('Pope', 'Anastasius'): 1,\n",
       " ('Mike', 'Modano'): 1,\n",
       " ('Tigger', 'Movie'): 1,\n",
       " ('Happy', 'Endings'): 1,\n",
       " ('Bobby', 'Darin'): 1,\n",
       " ('separate', 'subscription'): 1,\n",
       " ('internal', 'bleeding'): 1,\n",
       " ('Jason', 'Voorhees'): 1,\n",
       " ('161', 'laps'): 1,\n",
       " ('Album', 'Writer(s'): 1,\n",
       " ('deciduous', 'trees'): 1,\n",
       " ('Locomotive', 'Chase'): 1,\n",
       " ('Junius', 'Brutus'): 1,\n",
       " ('Goofy', 'Pluto'): 1,\n",
       " ('Port', 'Vila'): 1,\n",
       " ('Somewhere', 'Only'): 1,\n",
       " ('Richter', 'Scale'): 1,\n",
       " ('Bad', 'Doberan'): 1,\n",
       " ('Non', 'Stop'): 1,\n",
       " ('Gifu', 'Prefecture'): 1,\n",
       " ('Grand', 'Bahama'): 1,\n",
       " ('Wendell', 'Holmes'): 1,\n",
       " ('gridcolor:lightgrey', 'increment:50000'): 1,\n",
       " ('flood', 'basalt'): 1,\n",
       " ('Poison', 'Ivy'): 1,\n",
       " ('Concentration', 'Camp'): 1,\n",
       " ('Grange', 'Books'): 1,\n",
       " ('File', 'VIAF'): 1,\n",
       " ('Gospel', 'Oak'): 1,\n",
       " ('modernized', 'variant'): 1,\n",
       " ...}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches, batch_count = batcher(ngram_eval.ngram, stopwords=stop, max_batches = 15)\n",
    "\n",
    "batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>batch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Ving, Rhames)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Grădina, Zoologică)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Gharb-Chrarda-Beni, Hssen)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Karlovy, Vary)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(waystations, shuku-eki)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149995</th>\n",
       "      <td>(first, country, to)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149996</th>\n",
       "      <td>(from, A)</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149997</th>\n",
       "      <td>(1998, 8)</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149998</th>\n",
       "      <td>(had, tested, positive)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149999</th>\n",
       "      <td>(23, 12)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              ngram  batch\n",
       "0                    (Ving, Rhames)      1\n",
       "1              (Grădina, Zoologică)      1\n",
       "2       (Gharb-Chrarda-Beni, Hssen)      1\n",
       "3                   (Karlovy, Vary)      1\n",
       "4          (waystations, shuku-eki)      1\n",
       "...                             ...    ...\n",
       "149995         (first, country, to)      2\n",
       "149996                    (from, A)     -2\n",
       "149997                    (1998, 8)      6\n",
       "149998      (had, tested, positive)      4\n",
       "149999                     (23, 12)      3\n",
       "\n",
       "[150000 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Should be able to add batch information using df.map() but am encountering errors apparently relating\n",
    "#  to indexing - workaround (though slower).\n",
    "\n",
    "ngb_cols = [\"ngram\", \"batch\"]\n",
    "rows = []\n",
    "\n",
    "for ng in ngram_eval['ngram']:\n",
    "    rows.append({\"ngram\" : ng,\n",
    "                \"batch\" : batches[ng]})\n",
    "    \n",
    "ng_batch = pd.DataFrame(rows, columns = ngb_cols)\n",
    "\n",
    "ng_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>freq</th>\n",
       "      <th>poisson</th>\n",
       "      <th>len</th>\n",
       "      <th>batch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Ving, Rhames)</td>\n",
       "      <td>20</td>\n",
       "      <td>-605.625590</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Grădina, Zoologică)</td>\n",
       "      <td>20</td>\n",
       "      <td>-605.625590</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Gharb-Chrarda-Beni, Hssen)</td>\n",
       "      <td>20</td>\n",
       "      <td>-605.625590</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Karlovy, Vary)</td>\n",
       "      <td>20</td>\n",
       "      <td>-607.033377</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(waystations, shuku-eki)</td>\n",
       "      <td>20</td>\n",
       "      <td>-607.033377</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149995</th>\n",
       "      <td>(first, country, to)</td>\n",
       "      <td>45</td>\n",
       "      <td>-3071.582792</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149996</th>\n",
       "      <td>(from, A)</td>\n",
       "      <td>58</td>\n",
       "      <td>-3071.612088</td>\n",
       "      <td>2</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149997</th>\n",
       "      <td>(1998, 8)</td>\n",
       "      <td>64</td>\n",
       "      <td>-3071.704678</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149998</th>\n",
       "      <td>(had, tested, positive)</td>\n",
       "      <td>55</td>\n",
       "      <td>-3071.728206</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149999</th>\n",
       "      <td>(23, 12)</td>\n",
       "      <td>64</td>\n",
       "      <td>-3071.731328</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              ngram  freq      poisson  len  batch\n",
       "0                    (Ving, Rhames)    20  -605.625590    2      1\n",
       "1              (Grădina, Zoologică)    20  -605.625590    2      1\n",
       "2       (Gharb-Chrarda-Beni, Hssen)    20  -605.625590    2      1\n",
       "3                   (Karlovy, Vary)    20  -607.033377    2      1\n",
       "4          (waystations, shuku-eki)    20  -607.033377    2      1\n",
       "...                             ...   ...          ...  ...    ...\n",
       "149995         (first, country, to)    45 -3071.582792    3      2\n",
       "149996                    (from, A)    58 -3071.612088    2     -2\n",
       "149997                    (1998, 8)    64 -3071.704678    2      6\n",
       "149998      (had, tested, positive)    55 -3071.728206    3      4\n",
       "149999                     (23, 12)    64 -3071.731328    2      3\n",
       "\n",
       "[150000 rows x 5 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_eval = ngram_eval.merge(ng_batch, on='ngram')\n",
    "\n",
    "ngram_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ng_batch, batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle evaluation frame (with batch numbers!) for later\n",
    "ngram_eval.to_pickle(datapath+'/Corpora/wiki/simple_20200601/ngram_eval.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If skipping creating ngram_eval\n",
    "\n",
    "#ngram_eval = pd.read_pickle(datapath+'/Corpora/wiki/simple_20200601/ngram_eval.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1     45301\n",
       " 2     33312\n",
       " 3     24686\n",
       " 4     16668\n",
       " 5     10517\n",
       " 6      7502\n",
       " 7      4240\n",
       " 8      2702\n",
       " 9      1905\n",
       " 10     1051\n",
       "-2       832\n",
       " 11      450\n",
       "-1       300\n",
       " 12      247\n",
       " 13      123\n",
       " 14      107\n",
       " 15       57\n",
       "Name: batch, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_eval.batch.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import MWETokenizer\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Flatten down to a single number\n",
    "def cosim(x,y):\n",
    "    return cosine_similarity(x.reshape(1,-1), y.reshape(1,-1))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mwe_score(exp, model, stats_frame):\n",
    "    # Combined token for MWE\n",
    "    mwetoken = '+'.join(exp)\n",
    "\n",
    "    # Stopwords - 1 if component is a stopword, 0 if present, -1 if simplex word missing from vocab, -2 if MWE missing\n",
    "    sws = []\n",
    "    # Component vectors\n",
    "    cvs = []\n",
    "\n",
    "    #  Neighbours in original & MWE-aware space\n",
    "    oldn = []\n",
    "    newn = []\n",
    "\n",
    "    # List of individual word similarities (where present in the vocab)\n",
    "    css = []\n",
    "\n",
    "    # Empty array\n",
    "    earr = np.empty(1000)\n",
    "    earr[:] = np.nan\n",
    "\n",
    "    # Check that combined token exists in the vocab. This protects against inflation of n-gram counts caused by repeats\n",
    "    #  of the same token (e.g. in lists like https://simple.wikipedia.org/wiki/List_of_cities,_towns_and_villages_in_Fars_Province)\n",
    "    if mwetoken in model.dictionary:\n",
    "\n",
    "        mwv = model.word_vectors[model.dictionary[mwetoken]]\n",
    "\n",
    "        for w in exp:\n",
    "            if w in model.dictionary:\n",
    "                cvs.append(model.word_vectors[model.dictionary[w]])\n",
    "\n",
    "                oldn.append(model.most_similar(w, number=5))\n",
    "\n",
    "                if w in stop:\n",
    "                    sws.append(1)\n",
    "                    css.append(np.nan)\n",
    "                else:\n",
    "                    sws.append(0)\n",
    "                    css.append(cosim(model.word_vectors[model.dictionary[w]], mwv ))\n",
    "\n",
    "            # If component is absent from vocab\n",
    "            else:\n",
    "                sws.append(-1)\n",
    "                cvs.append(earr)\n",
    "                css.append(np.nan)\n",
    "\n",
    "                oldn.append([])\n",
    "\n",
    "        #  Mean cosim\n",
    "        if min(sws) >= 0:\n",
    "            cs = np.nanmean(css)\n",
    "        else:\n",
    "            cs = np.nan\n",
    "\n",
    "        newn = model.most_similar(mwetoken, number=5)\n",
    "\n",
    "    # Combined token missing from vocab - mark with defaults\n",
    "    else:\n",
    "        sws = [-2]\n",
    "        mwv = np.empty(400)\n",
    "        mwv[:] = np.nan\n",
    "\n",
    "\n",
    "    # Append to stats df\n",
    "    return stats_frame.append({\n",
    "        'ngram'  : exp,\n",
    "        'stopwords' : sws,\n",
    "        'mwe_vector' : mwv,\n",
    "        'component_vectors' : cvs,\n",
    "        'component_cosims'  : css,\n",
    "        'cosine_sim'  : cs,\n",
    "        'base_nearest': oldn,\n",
    "        'mwe_nearest' : newn,\n",
    "    }, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_count = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1 of 1\n",
      "Building GloVe model\n",
      " Training model\n",
      " Saving model\n",
      "Wall time: 38min 8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0:                              ngram  freq      poisson  len  batch\n",
       " 0                   (Ving, Rhames)    20  -605.625590    2      1\n",
       " 1             (Grădina, Zoologică)    20  -605.625590    2      1\n",
       " 2      (Gharb-Chrarda-Beni, Hssen)    20  -605.625590    2      1\n",
       " 3                  (Karlovy, Vary)    20  -607.033377    2      1\n",
       " 4         (waystations, shuku-eki)    20  -607.033377    2      1\n",
       " ...                            ...   ...          ...  ...    ...\n",
       " 45296             (the, South, of)    41 -3070.727239    3      1\n",
       " 45297                   (no, such)    64 -3070.763377    2      1\n",
       " 45298      (very, important, part)    49 -3070.800963    3      1\n",
       " 45299        (a, children's, book)    49 -3071.464079    3      1\n",
       " 45300              (to, get, them)    46 -3071.464786    3      1\n",
       " \n",
       " [45301 rows x 5 columns]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "batch_dfs = {}\n",
    "\n",
    "for bb in range(batch_count):\n",
    "    print('Processing batch {} of {}'.format(bb+1,batch_count))\n",
    "    \n",
    "    # Subset DataFrame\n",
    "    batch_dfs[bb] = ngram_eval[ngram_eval.batch == bb+1].reset_index(drop=True)\n",
    "    \n",
    "    # Initialise MWETokenizer\n",
    "    batch_token_mwe = MWETokenizer(list(batch_dfs[bb].ngram) , separator='+')\n",
    "    \n",
    "    # Build model\n",
    "    print('Building GloVe model')\n",
    "    simp_corp = Corpus()\n",
    "\n",
    "    sents_mwe = Sent_Seq(simp, batch_token_mwe)\n",
    "    simp_corp.fit( sents_mwe , window = 10)\n",
    "    \n",
    "    batch_model = Glove(no_components = 300, \n",
    "             learning_rate = 0.05)\n",
    "    \n",
    "    print(' Training model')\n",
    "    batch_model.fit(simp_corp.matrix, \n",
    "          epochs=25,\n",
    "          no_threads=8,\n",
    "          verbose=False)\n",
    "\n",
    "    batch_model.add_dictionary(simp_corp.dictionary)\n",
    "\n",
    "    # Save model\n",
    "    print(' Saving model')\n",
    "    batch_model.save(datapath+'/Models/2 GloVe/simple_batch{}_v2.model'.format(bb+1))\n",
    "    # Reload looks like    new_model = Glove.load('glove.model')\n",
    "    \n",
    "    # Just saving models for now\n",
    "    \n",
    "batch_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('relationship', 0.7570696300178639),\n",
       " ('Doctor-patient', 0.7032971906384414),\n",
       " ('rivalry', 0.6864205478742692),\n",
       " ('connections', 0.6742437997045764),\n",
       " ('ties', 0.6734428749018191)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model inspection\n",
    "batch_model.most_similar('relationships', number=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cacao', 0.7070576211561542),\n",
       " ('neuroectodermal', 0.6924046077134078),\n",
       " ('Condy’s', 0.6536899321462041),\n",
       " ('coconut', 0.643141442258816),\n",
       " ('tubers', 0.6293274227757036)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_model.most_similar('banana', number=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1059614x1059614 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 60555488 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simp_corp.matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18307"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_model.dictionary['relationships']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x1059614 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1121 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simp_corp.matrix.asformat('csr')[18307]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "307"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_model.dictionary['American']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2130"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_model.dictionary['man']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simp_corp.matrix.asformat('csr')[2130,307]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removed\n",
    "    #print('Gathering MWE stats')\n",
    "    # For each MWE, evaluate stats. Record vectors (in case we want to calculate different metrics later).\n",
    "    #statsf = pd.DataFrame(columns=['ngram', 'stopwords', 'mwe_vector', 'component_vectors', 'component_cosims', \n",
    "    #                               'cosine_sim', 'base_nearest', 'mwe_nearest'])\n",
    "\n",
    "    #for exp in batch_dfs[bb].ngram:\n",
    "    #    statsf = mwe_score(exp,batch_model,statsf)\n",
    "\n",
    "    #  Join back onto DataFrame\n",
    "    #batch_dfs[bb] = batch_dfs[bb].merge(statsf, on='ngram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge dataframes, sort by compositionality metric, export\n",
    "\n",
    "# Also want the default batches with batch no < 0\n",
    "all_batches = ngram_eval[ngram_eval.batch < 0]\n",
    "\n",
    "for d in range(batch_count):\n",
    "    all_batches = all_batches.append(batch_dfs[d])\n",
    "    \n",
    "all_batches = all_batches.sort_values('cosine_sim')\n",
    "all_batches = all_batches.reset_index(drop=True)\n",
    "\n",
    "all_batches.to_csv(datapath+'/Models/2 GloVe/Results/simple_output_001.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
