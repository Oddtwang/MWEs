{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\User\\\\Google Drive\\\\University\\\\Dissertation\\\\Code'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = 'C:/Users/'+os.getlogin()+'/Google Drive/University/Dissertation'\n",
    "datapath = 'E:/Dissertation Data'\n",
    "\n",
    "os.chdir(path+'/Code')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import MWETokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus.reader.plaintext import PlaintextCorpusReader\n",
    "\n",
    "from nltk.tokenize import WhitespaceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "simp = PlaintextCorpusReader(datapath+'/Corpora/wiki/simple_20200601/','simple_20200601_v2.txt',\n",
    "                            word_tokenizer = WhitespaceTokenizer()\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import word and sentence generators\n",
    "\n",
    "from generators import sent_gen, word_gen, Sent_Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load n-gram dataframe produced in word2vec iteration\n",
    "\n",
    "ngram_eval = pd.read_pickle(datapath+'/Corpora/wiki/simple_20200601/ngram_eval.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>freq</th>\n",
       "      <th>poisson</th>\n",
       "      <th>len</th>\n",
       "      <th>batch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Ving, Rhames)</td>\n",
       "      <td>20</td>\n",
       "      <td>-605.625590</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Grădina, Zoologică)</td>\n",
       "      <td>20</td>\n",
       "      <td>-605.625590</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Gharb-Chrarda-Beni, Hssen)</td>\n",
       "      <td>20</td>\n",
       "      <td>-605.625590</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Karlovy, Vary)</td>\n",
       "      <td>20</td>\n",
       "      <td>-607.033377</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(waystations, shuku-eki)</td>\n",
       "      <td>20</td>\n",
       "      <td>-607.033377</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149995</th>\n",
       "      <td>(first, country, to)</td>\n",
       "      <td>45</td>\n",
       "      <td>-3071.582792</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149996</th>\n",
       "      <td>(from, A)</td>\n",
       "      <td>58</td>\n",
       "      <td>-3071.612088</td>\n",
       "      <td>2</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149997</th>\n",
       "      <td>(1998, 8)</td>\n",
       "      <td>64</td>\n",
       "      <td>-3071.704678</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149998</th>\n",
       "      <td>(had, tested, positive)</td>\n",
       "      <td>55</td>\n",
       "      <td>-3071.728206</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149999</th>\n",
       "      <td>(23, 12)</td>\n",
       "      <td>64</td>\n",
       "      <td>-3071.731328</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              ngram  freq      poisson  len  batch\n",
       "0                    (Ving, Rhames)    20  -605.625590    2      1\n",
       "1              (Grădina, Zoologică)    20  -605.625590    2      1\n",
       "2       (Gharb-Chrarda-Beni, Hssen)    20  -605.625590    2      1\n",
       "3                   (Karlovy, Vary)    20  -607.033377    2      1\n",
       "4          (waystations, shuku-eki)    20  -607.033377    2      1\n",
       "...                             ...   ...          ...  ...    ...\n",
       "149995         (first, country, to)    45 -3071.582792    3      2\n",
       "149996                    (from, A)    58 -3071.612088    2     -2\n",
       "149997                    (1998, 8)    64 -3071.704678    2      6\n",
       "149998      (had, tested, positive)    55 -3071.728206    3      4\n",
       "149999                     (23, 12)    64 -3071.731328    2      3\n",
       "\n",
       "[150000 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_count = 150000\n",
    "min_freq = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1     45301\n",
       " 2     33312\n",
       " 3     24686\n",
       " 4     16668\n",
       " 5     10517\n",
       " 6      7502\n",
       " 7      4240\n",
       " 8      2702\n",
       " 9      1905\n",
       " 10     1051\n",
       "-2       832\n",
       " 11      450\n",
       "-1       300\n",
       " 12      247\n",
       " 13      123\n",
       " 14      107\n",
       " 15       57\n",
       "Name: batch, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_eval.batch.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No. of simplex words to include in vocabulary (plus n-grams for each batch)\n",
    "simplex_vocab_count = 300000\n",
    "\n",
    "batch_count = max(ngram_eval.batch)\n",
    "batch_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from gensim import corpora\n",
    "from scipy import sparse\n",
    "import itertools\n",
    "\n",
    "from dist_cooccurrence import dist_cooccurrence_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_count = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import FreqDist\n",
    "\n",
    "fdist = FreqDist(word_gen(simp, sent_mark=''))\n",
    "\n",
    "#stop = set( word for word, f in fdist.most_common(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30471577"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist.N()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1014614"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fdist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab = [w for w,f in filter(lambda x: x[1]>=20,fdist.items())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simplex_vocab = set( word for word, f in fdist.most_common(simplex_vocab_count))\n",
    "len(simplex_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary for batch 1\n",
      "Dictionary for batch 2\n",
      "Dictionary for batch 3\n",
      "Dictionary for batch 4\n",
      "Dictionary for batch 5\n",
      "Dictionary for batch 6\n",
      "Dictionary for batch 7\n",
      "Dictionary for batch 8\n",
      "Dictionary for batch 9\n",
      "Dictionary for batch 10\n",
      "Dictionary for batch 11\n",
      "Dictionary for batch 12\n",
      "Dictionary for batch 13\n",
      "Dictionary for batch 14\n",
      "Dictionary for batch 15\n"
     ]
    }
   ],
   "source": [
    "# Iterate over batches - save vocabs\n",
    "for bb in range(batch_count):\n",
    "\n",
    "    print('Dictionary for batch {}'.format(bb+1))\n",
    "    \n",
    "    this_batch = ngram_eval[ngram_eval.batch == bb+1].reset_index(drop=True)\n",
    "    #  Append n-grams to simplex_vocab\n",
    "    ng_list = [ '+'.join(ng) for ng in this_batch.ngram ]\n",
    "    \n",
    "    batch_vocab = simplex_vocab.copy()\n",
    "    batch_vocab.update(ng_list)\n",
    "\n",
    "    #  Pickle and save\n",
    "    with open(datapath+'/Corpora/wiki/simple_20200601/simp_b{}vocab.pkl'.format(bb+1), 'wb') as pfile:\n",
    "        pickle.dump(batch_vocab, pfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary for batch 1\n",
      "Dictionary for batch 2\n",
      "Dictionary for batch 3\n",
      "Dictionary for batch 4\n",
      "Dictionary for batch 5\n",
      "Dictionary for batch 6\n",
      "Dictionary for batch 7\n",
      "Dictionary for batch 8\n",
      "Dictionary for batch 9\n",
      "Dictionary for batch 10\n",
      "Dictionary for batch 11\n",
      "Dictionary for batch 12\n",
      "Dictionary for batch 13\n",
      "Dictionary for batch 14\n",
      "Dictionary for batch 15\n"
     ]
    }
   ],
   "source": [
    "# Dictionaries only\n",
    "\n",
    "\n",
    "# Iterate over batches\n",
    "for bb in range(batch_count):\n",
    "\n",
    "    print('Dictionary for batch {}'.format(bb+1))\n",
    "\n",
    "    #  Load pickled vocab set\n",
    "    with open(datapath+'/Corpora/wiki/simple_20200601/simp_b{}vocab.pkl'.format(bb+1), 'rb') as pfile:\n",
    "        batch_vocab = pickle.load(pfile)\n",
    "        \n",
    "    # Dictionary mapping\n",
    "    batch_dict = corpora.Dictionary([['<unk>']])\n",
    "    batch_dict.add_documents([list(batch_vocab)])\n",
    "    \n",
    "    # Pickle and save dictionary\n",
    "    with open(datapath+'/Corpora/wiki/simple_20200601/Pickles/simp_b{}_dict.pkl'.format(bb+1), 'wb') as pfile:\n",
    "        pickle.dump(batch_dict, pfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing for batch 1\n",
      " Processed: 100000\n",
      " Processed: 200000\n",
      "Obtained response from channel <Channel id=1 open>\n",
      "Obtained response from channel <Channel id=1 open>\n",
      "Obtained response from channel <Channel id=1 open>\n",
      "Obtained response from channel <Channel id=1 open>\n",
      " Processed: 300000\n",
      "Obtained response from channel <Channel id=1 open>\n",
      "Obtained response from channel <Channel id=1 open>\n",
      " Processed: 400000\n",
      " Processed: 500000\n",
      "Obtained response from channel <Channel id=1 open>\n",
      "Obtained response from channel <Channel id=1 open>\n",
      "Obtained response from channel <Channel id=1 open>\n",
      "Obtained response from channel <Channel id=1 open>\n",
      "Obtained response from channel <Channel id=1 open>\n",
      " Processed: 600000\n",
      "Obtained response from channel <Channel id=1 open>\n",
      " Processed: 700000\n",
      " Processed: 800000\n",
      "Obtained response from channel <Channel id=1 open>\n",
      "Obtained response from channel <Channel id=1 open>\n",
      " Processed: 900000\n",
      "Obtained response from channel <Channel id=1 open>\n",
      "Obtained response from channel <Channel id=1 open>\n",
      "Obtained response from channel <Channel id=1 open>\n",
      "Obtained response from channel <Channel id=1 open>\n",
      " Processed: 1000000\n",
      " Processed: 1100000\n",
      "Obtained response from channel <Channel id=1 open>\n",
      "Obtained response from channel <Channel id=1 open>\n",
      "Obtained response from channel <Channel id=1 open>\n",
      "Obtained response from channel <Channel id=1 open>\n",
      " Processed: 1200000\n",
      "Obtained response from channel <Channel id=1 open>\n",
      "Obtained response from channel <Channel id=1 open>\n",
      " Processed: 1300000\n",
      " Processed: 1400000\n",
      "Obtained response from channel <Channel id=1 open>\n",
      "Obtained response from channel <Channel id=1 open>\n",
      " Processed: 1500000\n",
      "Obtained response from channel <Channel id=1 open>\n",
      "Obtained response from channel <Channel id=1 open>\n",
      "Obtained response from channel <Channel id=1 open>\n",
      "Obtained response from channel <Channel id=1 open>\n",
      " Processed: 1600000\n",
      " Processed: 1700000\n",
      "Obtained response from channel <Channel id=1 open>\n",
      "Obtained response from channel <Channel id=1 open>\n",
      "Obtained response from channel <Channel id=1 open>\n",
      " Processed: 1800000\n",
      "Obtained response from channel <Channel id=1 open>\n",
      "Obtained response from channel <Channel id=1 open>\n",
      "Obtained response from channel <Channel id=1 open>\n",
      " Processed: 1900000\n",
      " Processed: 2000000\n",
      "Obtained response from channel <Channel id=1 open>\n",
      "Obtained response from channel <Channel id=1 open>\n",
      "Obtained response from channel <Channel id=1 open>\n",
      " Processed: 2100000\n",
      "Obtained response from channel <Channel id=1 open>\n",
      "Obtained response from channel <Channel id=1 open>\n",
      "Obtained response from channel <Channel id=1 open>\n",
      "Out of sentences - requesting returns\n",
      "Out of sentences - requesting returns\n",
      "Out of sentences - requesting returns\n",
      "Out of sentences - requesting returns\n",
      "Out of sentences - requesting returns\n",
      "Out of sentences - requesting returns\n",
      "Obtained response from channel <Channel id=1 open>\n",
      "Obtained response from channel <Channel id=1 open>\n",
      "Obtained response from channel <Channel id=1 open>\n",
      "Obtained response from channel <Channel id=1 open>\n",
      "Obtained response from channel <Channel id=1 open>\n",
      "Obtained response from channel <Channel id=1 open>\n",
      "Channel <Channel id=1 closed> terminated. 1 so far.\n",
      "Channel <Channel id=1 closed> terminated. 2 so far.\n",
      "Channel <Channel id=1 closed> terminated. 3 so far.\n",
      "Channel <Channel id=1 closed> terminated. 4 so far.\n",
      "Channel <Channel id=1 closed> terminated. 5 so far.\n",
      "Channel <Channel id=1 open> terminated. 6 so far.\n",
      "Everything terminated, exiting\n",
      "Pickled\n",
      "**************************** \n",
      "\n",
      "Wall time: 25min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Iterate over batches\n",
    "for bb in range(batch_count):\n",
    "\n",
    "    print('Executing for batch {}'.format(bb+1))\n",
    "    \n",
    "    this_batch = ngram_eval[ngram_eval.batch == bb+1].reset_index(drop=True)\n",
    "\n",
    "    #  Load pickled vocab set\n",
    "    with open(datapath+'/Corpora/wiki/simple_20200601/simp_b{}vocab.pkl'.format(bb+1), 'rb') as pfile:\n",
    "        batch_vocab = pickle.load(pfile)\n",
    "        \n",
    "    # Dictionary mapping\n",
    "    batch_dict = corpora.Dictionary([['<unk>']])\n",
    "    batch_dict.add_documents([list(batch_vocab)])\n",
    "    \n",
    "    # Pickle and save dictionary\n",
    "    with open(datapath+'/Corpora/wiki/simple_20200601/Pickles/simp_b{}_dict.pkl'.format(bb+1), 'wb') as pfile:\n",
    "        pickle.dump(batch_dict, pfile)\n",
    "    \n",
    "    \n",
    "    # Distributed construction of matrix\n",
    "    cooccurrence = dist_cooccurrence_v3(batch_dict, \n",
    "                                     sent_gen(simp, vocab=batch_vocab), \n",
    "                                     window_size = 20,\n",
    "                                        mark=100000,\n",
    "                                        rem_return = 50000,\n",
    "                                    specs=[('popen', 6)])\n",
    "    \n",
    "    # Pickle and save\n",
    "    with open(datapath+'/Corpora/wiki/simple_20200601/Pickles/simp_b{}_coo.pkl'.format(bb+1), 'wb') as pfile:\n",
    "        pickle.dump(cooccurrence, pfile, protocol=4)\n",
    "        \n",
    "    print('Pickled')\n",
    "    print('****************************','\\n')\n",
    "    \n",
    "    del cooccurrence\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Started 11.58\n",
    "\n",
    "Sentences:\n",
    "16500000 - 16600000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
