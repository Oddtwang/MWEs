{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\User\\\\Google Drive\\\\University\\\\Dissertation\\\\Code'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = 'C:/Users/'+os.getlogin()+'/Google Drive/University/Dissertation'\n",
    "datapath = 'E:/Dissertation Data'\n",
    "\n",
    "os.chdir(path+'/Code')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "import nltk\n",
    "from nltk.tokenize import MWETokenizer\n",
    "\n",
    "from glove import Corpus, Glove\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load n-gram list produced earlier\n",
    "\n",
    "ngram_eval = pd.read_pickle(datapath+'/Corpora/wiki/enwiki_20200520/10pc_ngram_eval.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(datapath+'/Corpora/wiki/enwiki_20200520/10pc_stop.pkl', 'rb') as pfile:\n",
    "    stop = pickle.load(pfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " 'A',\n",
       " 'He',\n",
       " 'In',\n",
       " 'It',\n",
       " 'New',\n",
       " 'The',\n",
       " 'a',\n",
       " 'also',\n",
       " 'an',\n",
       " 'and',\n",
       " 'are',\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'been',\n",
       " 'but',\n",
       " 'by',\n",
       " 'first',\n",
       " 'for',\n",
       " 'from',\n",
       " 'had',\n",
       " 'has',\n",
       " 'have',\n",
       " 'he',\n",
       " 'her',\n",
       " 'his',\n",
       " 'in',\n",
       " 'is',\n",
       " 'it',\n",
       " 'its',\n",
       " 'not',\n",
       " 'of',\n",
       " 'on',\n",
       " 'one',\n",
       " 'or',\n",
       " 'that',\n",
       " 'the',\n",
       " 'their',\n",
       " 'this',\n",
       " 'to',\n",
       " 'two',\n",
       " 'was',\n",
       " 'were',\n",
       " 'which',\n",
       " 'who',\n",
       " 'with'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_freq = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>poisson</th>\n",
       "      <th>len</th>\n",
       "      <th>batch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(of, the)</td>\n",
       "      <td>3.874652e+06</td>\n",
       "      <td>2</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(References, External, links)</td>\n",
       "      <td>2.566994e+06</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(External, links)</td>\n",
       "      <td>2.229096e+06</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(in, the)</td>\n",
       "      <td>2.094387e+06</td>\n",
       "      <td>2</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0, 0, 0)</td>\n",
       "      <td>1.798530e+06</td>\n",
       "      <td>3</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499995</th>\n",
       "      <td>(Work, started, on)</td>\n",
       "      <td>3.883693e+02</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499996</th>\n",
       "      <td>(of, these, techniques)</td>\n",
       "      <td>3.883679e+02</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499997</th>\n",
       "      <td>(Stadio, Flaminio)</td>\n",
       "      <td>3.883678e+02</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499998</th>\n",
       "      <td>(IRE, 3, C)</td>\n",
       "      <td>3.883678e+02</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499999</th>\n",
       "      <td>(The, Official, Encyclopedia)</td>\n",
       "      <td>3.883646e+02</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                ngram       poisson  len  batch\n",
       "0                           (of, the)  3.874652e+06    2     -2\n",
       "1       (References, External, links)  2.566994e+06    3      1\n",
       "2                   (External, links)  2.229096e+06    2      2\n",
       "3                           (in, the)  2.094387e+06    2     -2\n",
       "4                           (0, 0, 0)  1.798530e+06    3     -2\n",
       "...                               ...           ...  ...    ...\n",
       "499995            (Work, started, on)  3.883693e+02    3      8\n",
       "499996        (of, these, techniques)  3.883679e+02    3      8\n",
       "499997             (Stadio, Flaminio)  3.883678e+02    2      1\n",
       "499998                    (IRE, 3, C)  3.883678e+02    3      1\n",
       "499999  (The, Official, Encyclopedia)  3.883646e+02    3      2\n",
       "\n",
       "[500000 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_count = max(ngram_eval.batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1     94011\n",
       " 2     79538\n",
       " 3     69221\n",
       " 4     56154\n",
       " 5     48934\n",
       " 6     38288\n",
       " 7     30374\n",
       "-1     29076\n",
       " 8     22495\n",
       " 9     19272\n",
       " 10    11300\n",
       "-2      1337\n",
       "Name: batch, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_eval.batch.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import MWETokenizer\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Flatten down to a single number\n",
    "def cosim(x,y):\n",
    "    return cosine_similarity(x.reshape(1,-1), y.reshape(1,-1))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mwe_score(exp, model, stats_frame):\n",
    "    # Combined token for MWE\n",
    "    mwetoken = '+'.join(exp)\n",
    "\n",
    "    # Stopwords - 1 if component is a stopword, 0 if present, -1 if simplex word missing from vocab, -2 if MWE missing\n",
    "    sws = []\n",
    "    # Component vectors\n",
    "    cvs = []\n",
    "\n",
    "    #  Neighbours in original & MWE-aware space\n",
    "    oldn = []\n",
    "    newn = []\n",
    "\n",
    "    # List of individual word similarities (where present in the vocab)\n",
    "    css = []\n",
    "\n",
    "    # Empty array\n",
    "    earr = np.empty(1000)\n",
    "    earr[:] = np.nan\n",
    "\n",
    "    # Check that combined token exists in the vocab. This protects against inflation of n-gram counts caused by repeats\n",
    "    #  of the same token (e.g. in lists like https://simple.wikipedia.org/wiki/List_of_cities,_towns_and_villages_in_Fars_Province)\n",
    "    if mwetoken in model.dictionary:\n",
    "\n",
    "        mwv = model.word_vectors[model.dictionary[mwetoken]]\n",
    "\n",
    "        for w in exp:\n",
    "            if w in model.dictionary:\n",
    "                cvs.append(model.word_vectors[model.dictionary[w]])\n",
    "\n",
    "                #oldn.append(model.most_similar(w, number=5))\n",
    "\n",
    "                if w in stop:\n",
    "                    sws.append(1)\n",
    "                    css.append(np.nan)\n",
    "                else:\n",
    "                    sws.append(0)\n",
    "                    css.append(cosim(model.word_vectors[model.dictionary[w]], mwv ))\n",
    "\n",
    "            # If component is absent from vocab\n",
    "            else:\n",
    "                sws.append(-1)\n",
    "                cvs.append(earr)\n",
    "                css.append(np.nan)\n",
    "\n",
    "                #oldn.append([])\n",
    "\n",
    "        #  Mean cosim\n",
    "        if min(sws) >= 0:\n",
    "            cs = np.nanmean(css)\n",
    "        else:\n",
    "            cs = np.nan\n",
    "\n",
    "        #newn = model.most_similar(mwetoken, number=5)\n",
    "\n",
    "    # Combined token missing from vocab - mark with defaults\n",
    "    else:\n",
    "        sws = [-2]\n",
    "        mwv = np.empty(400)\n",
    "        mwv[:] = np.nan\n",
    "\n",
    "\n",
    "    # Append to stats df\n",
    "    return stats_frame.append({\n",
    "        'ngram'  : exp,\n",
    "        'stopwords' : sws,\n",
    "        'mwe_vector' : mwv,\n",
    "        'component_vectors' : cvs,\n",
    "        'component_cosims'  : css,\n",
    "        'cosine_sim'  : cs,\n",
    "        #'base_nearest': oldn,\n",
    "        #'mwe_nearest' : newn,\n",
    "    }, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invert_dict(dic):\n",
    "    return {value:key for (key, value) in dic.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1 of 10\n",
      "Loading GloVe model\n",
      "Gathering MWE stats\n",
      " MWE 0/94011: References+External+links\n",
      " MWE 2500/94011: noted+for\n",
      " MWE 5000/94011: 2016â€“17+season\n",
      " MWE 7500/94011: D'Oyly+Carte\n",
      " MWE 10000/94011: said+she\n",
      " MWE 12500/94011: Buddy+Holly\n",
      " MWE 15000/94011: Nuevo+Laredo\n",
      " MWE 17500/94011: an+organic+compound\n",
      " MWE 20000/94011: Campeonato+de+Portugal\n",
      " MWE 22500/94011: joined+together\n",
      " MWE 25000/94011: going+down\n",
      " MWE 27500/94011: describes+it\n",
      " MWE 30000/94011: was+convicted+in\n",
      " MWE 32500/94011: 2nd+Runner-up\n",
      " MWE 35000/94011: begin+work+on\n",
      " MWE 37500/94011: Bryce+Canyon\n",
      " MWE 40000/94011: Julien+Duvivier\n",
      " MWE 42500/94011: 23%+below+basic\n",
      " MWE 45000/94011: municipal+unit+has\n",
      " MWE 47500/94011: is+released+on\n",
      " MWE 50000/94011: Bobby+Hutcherson\n",
      " MWE 52500/94011: Boeing+777-300ER\n",
      " MWE 55000/94011: Little+Feat\n",
      " MWE 57500/94011: Oficial+911\n",
      " MWE 60000/94011: Multiple+Launch+Rocket\n",
      " MWE 62500/94011: and+in+spite\n",
      " MWE 65000/94011: Institutional+Investor\n",
      " MWE 67500/94011: A+Catalogue+of\n",
      " MWE 70000/94011: Guillermo+Coria\n",
      " MWE 72500/94011: co-directed+with\n",
      " MWE 75000/94011: Delta+Connection\n",
      " MWE 77500/94011: Sharpe's+Enemy\n",
      " MWE 80000/94011: reduce+energy+consumption\n",
      " MWE 82500/94011: Tristan+and+Isolde\n",
      " MWE 85000/94011: consist+primarily+of\n",
      " MWE 87500/94011: Dutch+cyclist\n",
      " MWE 90000/94011: would+entail\n",
      " MWE 92500/94011: Firenze+galleria\n",
      "Processing batch 2 of 10\n",
      "Loading GloVe model\n",
      "Gathering MWE stats\n",
      " MWE 0/79538: External+links\n",
      " MWE 2500/79538: was+a+prominent\n",
      " MWE 5000/79538: Liberal+Democratic+Party\n",
      " MWE 7500/79538: rose+to+fame\n",
      " MWE 10000/79538: forced+out+of\n",
      " MWE 12500/79538: heavily+armed\n",
      " MWE 15000/79538: electricity+generation\n",
      " MWE 17500/79538: Southwest+Asia\n",
      " MWE 20000/79538: the+wreck\n",
      " MWE 22500/79538: From+Here\n",
      " MWE 25000/79538: and+Merrie+Melodies\n",
      " MWE 27500/79538: 6.1+earthquake\n",
      " MWE 30000/79538: topical+guide+to\n",
      " MWE 32500/79538: Ex+parte\n",
      " MWE 35000/79538: An+overview\n",
      " MWE 37500/79538: persons+who+have\n",
      " MWE 40000/79538: Raitz+von\n",
      " MWE 42500/79538: from+Portland+Oregon\n",
      " MWE 45000/79538: The+current+editor-in-chief\n",
      " MWE 47500/79538: DE+FG\n",
      " MWE 50000/79538: The+front+of\n",
      " MWE 52500/79538: a+property+tax\n",
      " MWE 55000/79538: seize+power\n",
      " MWE 57500/79538: the+BahÃ¡Ê¼Ã­\n",
      " MWE 60000/79538: Peakposition+US+Bubbling\n",
      " MWE 62500/79538: heavyweight+bout+between\n",
      " MWE 65000/79538: the+functionality+of\n",
      " MWE 67500/79538: The+breed+is\n",
      " MWE 70000/79538: Blue+Hens\n",
      " MWE 72500/79538: The+Dunwich+Horror\n",
      " MWE 75000/79538: the+monument+to\n",
      " MWE 77500/79538: Invasion+Attack\n",
      "Processing batch 3 of 10\n",
      "Loading GloVe model\n",
      "Gathering MWE stats\n",
      " MWE 0/69221: References+External\n",
      " MWE 2500/69221: East+Asian\n",
      " MWE 5000/69221: often+seen\n",
      " MWE 7500/69221: the+Mojave+Desert\n",
      " MWE 10000/69221: OTW+OTL+L\n",
      " MWE 12500/69221: were+transported\n",
      " MWE 15000/69221: western+Atlantic+Ocean\n",
      " MWE 17500/69221: 18+17\n",
      " MWE 20000/69221: during+spring+training\n",
      " MWE 22500/69221: Adjunct+Professor+of\n",
      " MWE 25000/69221: your+heart\n",
      " MWE 27500/69221: at+the+southeast\n",
      " MWE 30000/69221: T+R+Sundaram\n",
      " MWE 32500/69221: the+independent+circuit\n",
      " MWE 35000/69221: up+to+50%\n",
      " MWE 37500/69221: Albums+Chart+27\n",
      " MWE 40000/69221: Came+Back\n",
      " MWE 42500/69221: Ennu+Ninte\n",
      " MWE 45000/69221: teen+years\n",
      " MWE 47500/69221: a+foreign+power\n",
      " MWE 50000/69221: for+membership\n",
      " MWE 52500/69221: at+the+Birmingham\n",
      " MWE 55000/69221: sire+of+winners\n",
      " MWE 57500/69221: often+simply\n",
      " MWE 60000/69221: the+train+was\n",
      " MWE 62500/69221: Lava+Men\n",
      " MWE 65000/69221: an+aggregated+score\n",
      " MWE 67500/69221: the+family+Papilionidae\n",
      "Processing batch 4 of 10\n",
      "Loading GloVe model\n",
      "Gathering MWE stats\n",
      " MWE 0/56154: also+known+as\n",
      " MWE 2500/56154: will+have+to\n",
      " MWE 5000/56154: empties+into+the\n",
      " MWE 7500/56154: Shortly+thereafter+the\n",
      " MWE 10000/56154: Commentary+on+the\n",
      " MWE 12500/56154: Thus+the+two\n",
      " MWE 15000/56154: manages+to+convince\n",
      " MWE 17500/56154: narrow+margin\n",
      " MWE 20000/56154: lack+of+transparency\n",
      " MWE 22500/56154: early+eighteenth+century\n",
      " MWE 25000/56154: Railroad+Station\n",
      " MWE 27500/56154: a+Ukrainian\n",
      " MWE 30000/56154: in+the+25th\n",
      " MWE 32500/56154: Pack+Up+Your\n",
      " MWE 35000/56154: 90th+anniversary\n",
      " MWE 37500/56154: Luca+Lanotte\n",
      " MWE 40000/56154: Dutra+da\n",
      " MWE 42500/56154: of+Valois\n",
      " MWE 45000/56154: during+his+long\n",
      " MWE 47500/56154: Unable+to+get\n",
      " MWE 50000/56154: put+the+ball\n",
      " MWE 52500/56154: they+finished+with\n",
      " MWE 55000/56154: of+her+family's\n",
      "Processing batch 5 of 10\n",
      "Loading GloVe model\n",
      "Gathering MWE stats\n",
      " MWE 0/48934: the+end\n",
      " MWE 2500/48934: is+separated+from\n",
      " MWE 5000/48934: Lemmon+Survey+2.2\n",
      " MWE 7500/48934: the+minimum\n",
      " MWE 10000/48934: the+squad+for\n",
      " MWE 12500/48934: to+the+crown\n",
      " MWE 15000/48934: Northern+Arizona+University\n",
      " MWE 17500/48934: self-inflicted+gunshot\n",
      " MWE 20000/48934: BOS+CHI+CLE\n",
      " MWE 22500/48934: the+US+Army's\n",
      " MWE 25000/48934: spaces+are\n",
      " MWE 27500/48934: the+Iraqi+Army\n",
      " MWE 30000/48934: being+investigated+for\n",
      " MWE 32500/48934: Â±0+Animalist\n",
      " MWE 35000/48934: the+following+six\n",
      " MWE 37500/48934: Alfonso+XIII+of\n",
      " MWE 40000/48934: to+the+stadium\n",
      " MWE 42500/48934: metal+band+Metallica\n",
      " MWE 45000/48934: rifles+and+carbines\n",
      " MWE 47500/48934: United+States+Equestrian\n",
      "Processing batch 6 of 10\n",
      "Loading GloVe model\n",
      "Gathering MWE stats\n",
      " MWE 0/38288: is+located+in\n",
      " MWE 2500/38288: League+Third+Division\n",
      " MWE 5000/38288: Minister+of+Interior\n",
      " MWE 7500/38288: distribution+deal+with\n",
      " MWE 10000/38288: fact+it+was\n",
      " MWE 12500/38288: Society+of+India\n",
      " MWE 15000/38288: speed+at+which\n",
      " MWE 17500/38288: Kent+County+Council\n",
      " MWE 20000/38288: Dulles+International\n",
      " MWE 22500/38288: for+the+management\n",
      " MWE 25000/38288: have+benefited\n",
      " MWE 27500/38288: an+action-adventure+video\n",
      " MWE 30000/38288: 3â€“1+loss\n",
      " MWE 32500/38288: team+could+not\n",
      " MWE 35000/38288: perform+oral+sex\n",
      " MWE 37500/38288: Beautiful+Girls\n",
      "Processing batch 7 of 10\n",
      "Loading GloVe model\n",
      "Gathering MWE stats\n",
      " MWE 0/30374: located+in+the\n",
      " MWE 2500/30374: Week+Date\n",
      " MWE 5000/30374: often+used+by\n",
      " MWE 7500/30374: and+a+minimum\n",
      " MWE 10000/30374: Edward+L\n",
      " MWE 12500/30374: runner-ups+Legend+Grand\n",
      " MWE 15000/30374: highest+rates+of\n",
      " MWE 17500/30374: there+that+he\n",
      " MWE 20000/30374: with+my\n",
      " MWE 22500/30374: Handbook+of+Marvel\n",
      " MWE 25000/30374: forum+for+the\n",
      " MWE 27500/30374: on+22+reviews\n",
      " MWE 30000/30374: royal+charter+issued\n",
      "Processing batch 8 of 10\n",
      "Loading GloVe model\n",
      "Gathering MWE stats\n",
      " MWE 0/22495: to+return+to\n",
      " MWE 2500/22495: good+relations\n",
      " MWE 5000/22495: French+film\n",
      " MWE 7500/22495: Player+Team+Position\n",
      " MWE 10000/22495: able+to+locate\n",
      " MWE 12500/22495: William+Boyd+Andy\n",
      " MWE 15000/22495: his+life+story\n",
      " MWE 17500/22495: accepted+an+athletic\n",
      " MWE 20000/22495: point+of+interest\n",
      "Processing batch 9 of 10\n",
      "Loading GloVe model\n",
      "Gathering MWE stats\n",
      " MWE 0/19272: as+opposed+to\n",
      " MWE 2500/19272: Japan+Football+League\n",
      " MWE 5000/19272: German+drama+film\n",
      " MWE 7500/19272: which+was+converted\n",
      " MWE 10000/19272: other+matters\n",
      " MWE 12500/19272: never+before+been\n",
      " MWE 15000/19272: annual+award+ceremony\n",
      " MWE 17500/19272: not+changed+since\n",
      "Processing batch 10 of 10\n",
      "Loading GloVe model\n",
      "Gathering MWE stats\n",
      " MWE 0/11300: to+ensure+that\n",
      " MWE 2500/11300: website+St\n",
      " MWE 5000/11300: died+after+falling\n",
      " MWE 7500/11300: University+Press+and\n",
      " MWE 10000/11300: French+squadron\n",
      "Wall time: 50min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "batch_dfs = {}\n",
    "\n",
    "invert_dict = False\n",
    "\n",
    "for bb in range(batch_count):\n",
    "    print('Processing batch {} of {}'.format(bb+1,batch_count))\n",
    "    \n",
    "    # Subset DataFrame\n",
    "    batch_dfs[bb] = ngram_eval[ngram_eval.batch == bb+1].reset_index(drop=True)\n",
    "    \n",
    "    # Initialise MWETokenizer\n",
    "    batch_token_mwe = MWETokenizer(list(batch_dfs[bb].ngram) , separator='+')\n",
    "    \n",
    "    # Load model\n",
    "    print('Loading GloVe model')\n",
    "    \n",
    "    batch_model = Glove.load(datapath+'/Models/2 GloVe/w10p_glove_vocab_batch{}.model'.format(bb+1))\n",
    "    \n",
    "    # Invert dictionary (due to error in model execution code, now fixed)\n",
    "    if invert_dict:\n",
    "        batch_dict = invert_dict(batch_model.dictionary)\n",
    "        batch_model.add_dictionary(batch_dict)\n",
    "\n",
    "    print('Gathering MWE stats')\n",
    "     # For each MWE, evaluate stats. Record vectors (in case we want to calculate different metrics later).\n",
    "    statsf = pd.DataFrame(columns=['ngram', 'stopwords', 'mwe_vector', 'component_vectors', 'component_cosims', \n",
    "                                   'cosine_sim'])  #, 'base_nearest', 'mwe_nearest'\n",
    "\n",
    "    batch_len = len(batch_dfs[bb].ngram)\n",
    "    if batch_len >= 5000: \n",
    "        printer = 2500\n",
    "    else:\n",
    "        printer = 200\n",
    "        \n",
    "    _i = 0\n",
    "    \n",
    "    for exp in batch_dfs[bb].ngram:\n",
    "        if _i % printer == 0:\n",
    "            print(' MWE '+str(_i)+'/'+str(batch_len)+': '+'+'.join(exp))\n",
    "        _i += 1\n",
    "            \n",
    "        statsf = mwe_score(exp,batch_model,statsf)\n",
    "\n",
    "      #Join back onto DataFrame\n",
    "    batch_dfs[bb] = batch_dfs[bb].merge(statsf, on='ngram')    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removed\n",
    "    #print('Gathering MWE stats')\n",
    "    # For each MWE, evaluate stats. Record vectors (in case we want to calculate different metrics later).\n",
    "    #statsf = pd.DataFrame(columns=['ngram', 'stopwords', 'mwe_vector', 'component_vectors', 'component_cosims', \n",
    "    #                               'cosine_sim', 'base_nearest', 'mwe_nearest'])\n",
    "\n",
    "    #for exp in batch_dfs[bb].ngram:\n",
    "    #    statsf = mwe_score(exp,batch_model,statsf)\n",
    "\n",
    "    #  Join back onto DataFrame\n",
    "    #batch_dfs[bb] = batch_dfs[bb].merge(statsf, on='ngram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge dataframes, sort by compositionality metric, export\n",
    "\n",
    "# Also want the default batches with batch no < 0\n",
    "all_batches = ngram_eval[ngram_eval.batch < 0].reindex(columns = batch_dfs[0].columns.tolist())\n",
    "\n",
    "for d in range(batch_count):\n",
    "    all_batches = all_batches.append(batch_dfs[d])\n",
    "    \n",
    "all_batches = all_batches.sort_values('cosine_sim')\n",
    "all_batches = all_batches.reset_index(drop=True)\n",
    "\n",
    "all_batches.to_csv(datapath+'/Models/2 GloVe/Results/w10p_vocab_output_001.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>poisson</th>\n",
       "      <th>len</th>\n",
       "      <th>batch</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>mwe_vector</th>\n",
       "      <th>component_vectors</th>\n",
       "      <th>component_cosims</th>\n",
       "      <th>cosine_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(at, the, FIL)</td>\n",
       "      <td>389.297974</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>[1, 1, 0]</td>\n",
       "      <td>[-3.304669400496006, 3.2918497977969414, 3.289...</td>\n",
       "      <td>[[0.29045682541149237, -0.08268427520868048, 0...</td>\n",
       "      <td>[nan, nan, -0.9999266969605956]</td>\n",
       "      <td>-0.999927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(brunt, of)</td>\n",
       "      <td>764.399850</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[-6.011641172649969, -5.913132775700688, 5.929...</td>\n",
       "      <td>[[7.2772876167131235, 7.0261345448651396, -7.1...</td>\n",
       "      <td>[-0.9999125564125098, nan]</td>\n",
       "      <td>-0.999913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(New, Zealand-born)</td>\n",
       "      <td>999.388134</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[-5.285540019627866, 5.32779199475822, -5.4064...</td>\n",
       "      <td>[[-0.01064217782706564, 0.01147192576760911, -...</td>\n",
       "      <td>[nan, -0.9998874696606046]</td>\n",
       "      <td>-0.999887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(of, Mecklenburg-Schwerin)</td>\n",
       "      <td>472.114015</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[1.227232183250606, 1.3143013409835398, -1.235...</td>\n",
       "      <td>[[0.16670074192461656, -0.11178727846883854, -...</td>\n",
       "      <td>[nan, -0.999882841396625]</td>\n",
       "      <td>-0.999883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(a, spinoff, of)</td>\n",
       "      <td>403.374558</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 0, 1]</td>\n",
       "      <td>[0.6472155313911789, -0.6442973932991041, 0.62...</td>\n",
       "      <td>[[0.025192777637270344, 0.22246980769008778, -...</td>\n",
       "      <td>[nan, -0.9998615809834557, nan]</td>\n",
       "      <td>-0.999862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499995</th>\n",
       "      <td>(Party, Comments/Suppleant, representatives)</td>\n",
       "      <td>514.988873</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>[0, -1, 0]</td>\n",
       "      <td>[-0.001532781228780539, -0.0013564962182825934...</td>\n",
       "      <td>[[0.14885982741054793, 0.07894516720668883, -0...</td>\n",
       "      <td>[-0.06401353437456728, nan, -0.04209184800298231]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499996</th>\n",
       "      <td>(bottom:50px, top:10px)</td>\n",
       "      <td>454.154168</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>[-1, 0]</td>\n",
       "      <td>[-4.248468422089702e-05, 0.0004327387824826704...</td>\n",
       "      <td>[[nan, nan, nan, nan, nan, nan, nan, nan, nan,...</td>\n",
       "      <td>[nan, -0.14174566466780864]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499997</th>\n",
       "      <td>(color:eocene, text:Eocene)</td>\n",
       "      <td>420.145374</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>[0, -1]</td>\n",
       "      <td>[0.000839802598036845, -0.0002937641294715939,...</td>\n",
       "      <td>[[0.0032681698690965907, -0.001653449966643513...</td>\n",
       "      <td>[0.010569120806779533, nan]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499998</th>\n",
       "      <td>(Nova, Scotia, TUNS)</td>\n",
       "      <td>587.673502</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>[0, 0, -1]</td>\n",
       "      <td>[0.0006182197742030652, -0.000467253574371338,...</td>\n",
       "      <td>[[0.12940666025848813, 0.01258788292999845, -0...</td>\n",
       "      <td>[-0.007134790689687712, -0.02787587841584928, ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499999</th>\n",
       "      <td>(Canada, Toporama, Natural)</td>\n",
       "      <td>507.737679</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>[0, -1, 0]</td>\n",
       "      <td>[0.0013956055642313859, 0.0011425061785436867,...</td>\n",
       "      <td>[[-0.3415841538896306, -0.031145198105149697, ...</td>\n",
       "      <td>[-0.025117911735303488, nan, 0.029490782429853...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500000 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               ngram     poisson  len  batch  \\\n",
       "0                                     (at, the, FIL)  389.297974    3      4   \n",
       "1                                        (brunt, of)  764.399850    2      3   \n",
       "2                                (New, Zealand-born)  999.388134    2      1   \n",
       "3                         (of, Mecklenburg-Schwerin)  472.114015    2      6   \n",
       "4                                   (a, spinoff, of)  403.374558    3      1   \n",
       "...                                              ...         ...  ...    ...   \n",
       "499995  (Party, Comments/Suppleant, representatives)  514.988873    3      5   \n",
       "499996                       (bottom:50px, top:10px)  454.154168    2      5   \n",
       "499997                   (color:eocene, text:Eocene)  420.145374    2      5   \n",
       "499998                          (Nova, Scotia, TUNS)  587.673502    3      6   \n",
       "499999                   (Canada, Toporama, Natural)  507.737679    3      7   \n",
       "\n",
       "         stopwords                                         mwe_vector  \\\n",
       "0        [1, 1, 0]  [-3.304669400496006, 3.2918497977969414, 3.289...   \n",
       "1           [0, 1]  [-6.011641172649969, -5.913132775700688, 5.929...   \n",
       "2           [1, 0]  [-5.285540019627866, 5.32779199475822, -5.4064...   \n",
       "3           [1, 0]  [1.227232183250606, 1.3143013409835398, -1.235...   \n",
       "4        [1, 0, 1]  [0.6472155313911789, -0.6442973932991041, 0.62...   \n",
       "...            ...                                                ...   \n",
       "499995  [0, -1, 0]  [-0.001532781228780539, -0.0013564962182825934...   \n",
       "499996     [-1, 0]  [-4.248468422089702e-05, 0.0004327387824826704...   \n",
       "499997     [0, -1]  [0.000839802598036845, -0.0002937641294715939,...   \n",
       "499998  [0, 0, -1]  [0.0006182197742030652, -0.000467253574371338,...   \n",
       "499999  [0, -1, 0]  [0.0013956055642313859, 0.0011425061785436867,...   \n",
       "\n",
       "                                        component_vectors  \\\n",
       "0       [[0.29045682541149237, -0.08268427520868048, 0...   \n",
       "1       [[7.2772876167131235, 7.0261345448651396, -7.1...   \n",
       "2       [[-0.01064217782706564, 0.01147192576760911, -...   \n",
       "3       [[0.16670074192461656, -0.11178727846883854, -...   \n",
       "4       [[0.025192777637270344, 0.22246980769008778, -...   \n",
       "...                                                   ...   \n",
       "499995  [[0.14885982741054793, 0.07894516720668883, -0...   \n",
       "499996  [[nan, nan, nan, nan, nan, nan, nan, nan, nan,...   \n",
       "499997  [[0.0032681698690965907, -0.001653449966643513...   \n",
       "499998  [[0.12940666025848813, 0.01258788292999845, -0...   \n",
       "499999  [[-0.3415841538896306, -0.031145198105149697, ...   \n",
       "\n",
       "                                         component_cosims  cosine_sim  \n",
       "0                         [nan, nan, -0.9999266969605956]   -0.999927  \n",
       "1                              [-0.9999125564125098, nan]   -0.999913  \n",
       "2                              [nan, -0.9998874696606046]   -0.999887  \n",
       "3                               [nan, -0.999882841396625]   -0.999883  \n",
       "4                         [nan, -0.9998615809834557, nan]   -0.999862  \n",
       "...                                                   ...         ...  \n",
       "499995  [-0.06401353437456728, nan, -0.04209184800298231]         NaN  \n",
       "499996                        [nan, -0.14174566466780864]         NaN  \n",
       "499997                        [0.010569120806779533, nan]         NaN  \n",
       "499998  [-0.007134790689687712, -0.02787587841584928, ...         NaN  \n",
       "499999  [-0.025117911735303488, nan, 0.029490782429853...         NaN  \n",
       "\n",
       "[500000 rows x 9 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_batches_light = all_batches.drop(columns=['mwe_vector', 'component_vectors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_batches_light.to_csv(datapath+'/Models/2 GloVe/Results/w10p_vocab_light_001.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
