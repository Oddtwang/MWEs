{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\tom\\\\Google Drive\\\\University\\\\Dissertation\\\\Code'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = 'C:/Users/'+os.getlogin()+'/Google Drive/University/Dissertation'\n",
    "#datapath = 'E:/Dissertation Data'\n",
    "datapath = 'C:/Users/'+os.getlogin()+'/Dissertation Data'\n",
    "\n",
    "os.chdir(path+'/Code')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We collect lexical co-occurrence statistics on all words in\n",
    "the English Wikipedia, using the WikiExtractor tool2 to retrieve\n",
    "plain text from the April 2015 dump (ca. 2.8B words),\n",
    "and using simple regular expressions to segment sentences\n",
    "and words, and remove URLs and punctuation. We perform\n",
    "no POS tagging, lemmatisation, case normalisation,\n",
    "or removal of numbers or symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import MWETokenizer\n",
    "\n",
    "#from glove import Corpus, Glove\n",
    "\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus.reader.plaintext import PlaintextCorpusReader\n",
    "\n",
    "from nltk.tokenize import WhitespaceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "w10p = PlaintextCorpusReader(datapath+'/Corpora/wiki/enwiki_20200520/','enwiki_20200520_10pc.txt',\n",
    "                            word_tokenizer = WhitespaceTokenizer()\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import word and sentence generators\n",
    "\n",
    "from generators import sent_gen, word_gen, Sent_Seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We collect word frequency information with the\n",
    "SRILM language modelling toolkit (Stolcke, 2002), counting\n",
    "n-grams (n <= 3), treating MWEs as contiguous bigrams\n",
    "and trigrams), and identify MWE candidates by computing\n",
    "the Poisson collocation measure (Quasthoff and Wolff,\n",
    "2002) for all bigrams and trigrams (ca. 23M n-grams).\n",
    "This method should be readily extensible to include longer\n",
    "n-grams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collate n-grams\n",
    "\n",
    "from nltk.collocations import BigramCollocationFinder, TrigramCollocationFinder\n",
    "\n",
    "from nltk.metrics import (\n",
    "    BigramAssocMeasures,\n",
    "    TrigramAssocMeasures,\n",
    "    NgramAssocMeasures,\n",
    ")\n",
    "\n",
    "from nltk.metrics.spearman import (\n",
    "    spearman_correlation,\n",
    "    ranks_from_scores,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then automatically score the million most strongly associated\n",
    "n-grams (i.e., roughly the top 5% of the Poisson-ranked\n",
    "list) for compositionality.\n",
    "\n",
    "Using word2vec (Mikolov et al., 2013) with the parameters\n",
    "found to be most effective by Baroni et al. (2014), we\n",
    "build a word embedding vector for every simplex word in\n",
    "the vocabulary (ca. 1M types), as well as for each MWE candidate.\n",
    "\n",
    "* Continuous bag of words model with 400-dimensional vectors, window size 5, subsampling with t = 10^-5, negative sampling with 10 samples. We build vectors only for tokens observed 20 times or more in the corpus.\n",
    "\n",
    "We then compute the cosine similarity of the vector\n",
    "representation for a MWE candidate with the vectors of its\n",
    "constituent words, and take the arithmetic mean. \n",
    "In scoring\n",
    "the compositionality of a candidate, we do not measure the\n",
    "cosine similarity of the MWE with any stop words it may\n",
    "contain, as stop words may be assumed to be semantically\n",
    "uninformative.\n",
    "* Stop words are taken here to be the 50 most frequent words in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopwords from corpus - 50 most frequent\n",
    "\n",
    "with open(datapath+'/Corpora/wiki/enwiki_20200520/10pc_stop.pkl', 'rb') as pfile:\n",
    "    stop = pickle.load(pfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " 'A',\n",
       " 'He',\n",
       " 'In',\n",
       " 'It',\n",
       " 'New',\n",
       " 'The',\n",
       " 'a',\n",
       " 'also',\n",
       " 'an',\n",
       " 'and',\n",
       " 'are',\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'been',\n",
       " 'but',\n",
       " 'by',\n",
       " 'first',\n",
       " 'for',\n",
       " 'from',\n",
       " 'had',\n",
       " 'has',\n",
       " 'have',\n",
       " 'he',\n",
       " 'her',\n",
       " 'his',\n",
       " 'in',\n",
       " 'is',\n",
       " 'it',\n",
       " 'its',\n",
       " 'not',\n",
       " 'of',\n",
       " 'on',\n",
       " 'one',\n",
       " 'or',\n",
       " 'that',\n",
       " 'the',\n",
       " 'their',\n",
       " 'this',\n",
       " 'to',\n",
       " 'two',\n",
       " 'was',\n",
       " 'were',\n",
       " 'which',\n",
       " 'who',\n",
       " 'with'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>poisson</th>\n",
       "      <th>len</th>\n",
       "      <th>batch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(of, the)</td>\n",
       "      <td>3.874652e+06</td>\n",
       "      <td>2</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(References, External, links)</td>\n",
       "      <td>2.566994e+06</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(External, links)</td>\n",
       "      <td>2.229096e+06</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(in, the)</td>\n",
       "      <td>2.094387e+06</td>\n",
       "      <td>2</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0, 0, 0)</td>\n",
       "      <td>1.798530e+06</td>\n",
       "      <td>3</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499995</th>\n",
       "      <td>(Work, started, on)</td>\n",
       "      <td>3.883693e+02</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499996</th>\n",
       "      <td>(of, these, techniques)</td>\n",
       "      <td>3.883679e+02</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499997</th>\n",
       "      <td>(Stadio, Flaminio)</td>\n",
       "      <td>3.883678e+02</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499998</th>\n",
       "      <td>(IRE, 3, C)</td>\n",
       "      <td>3.883678e+02</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499999</th>\n",
       "      <td>(The, Official, Encyclopedia)</td>\n",
       "      <td>3.883646e+02</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                ngram       poisson  len  batch\n",
       "0                           (of, the)  3.874652e+06    2     -2\n",
       "1       (References, External, links)  2.566994e+06    3      1\n",
       "2                   (External, links)  2.229096e+06    2      2\n",
       "3                           (in, the)  2.094387e+06    2     -2\n",
       "4                           (0, 0, 0)  1.798530e+06    3     -2\n",
       "...                               ...           ...  ...    ...\n",
       "499995            (Work, started, on)  3.883693e+02    3      8\n",
       "499996        (of, these, techniques)  3.883679e+02    3      8\n",
       "499997             (Stadio, Flaminio)  3.883678e+02    2      1\n",
       "499998                    (IRE, 3, C)  3.883678e+02    3      1\n",
       "499999  (The, Official, Encyclopedia)  3.883646e+02    3      2\n",
       "\n",
       "[500000 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_eval = pd.read_pickle(datapath+'/Corpora/wiki/enwiki_20200520/10pc_ngram_eval.pkl')\n",
    "\n",
    "ngram_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_count = max(ngram_eval.batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1     94011\n",
       " 2     79538\n",
       " 3     69221\n",
       " 4     56154\n",
       " 5     48934\n",
       " 6     38288\n",
       " 7     30374\n",
       "-1     29076\n",
       " 8     22495\n",
       " 9     19272\n",
       " 10    11300\n",
       "-2      1337\n",
       "Name: batch, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_eval.batch.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import MWETokenizer\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Flatten down to a single number\n",
    "def cosim(x,y):\n",
    "    return cosine_similarity(x.reshape(1,-1), y.reshape(1,-1))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mwe_score(exp, model, stats_frame):\n",
    "    \n",
    "    # Combined token for MWE\n",
    "    mwetoken = '+'.join(exp)\n",
    "\n",
    "    # Stopwords - 1 if component is a stopword, 0 if present, -1 if simplex word missing from vocab, -2 if MWE missing\n",
    "    sws = []\n",
    "    # Component vectors\n",
    "    cvs = []\n",
    "\n",
    "    #  Neighbours in original & MWE-aware space\n",
    "    #oldn = []\n",
    "    #newn = []\n",
    "\n",
    "    # List of individual word similarities (where present in the vocab)\n",
    "    css = []\n",
    "\n",
    "    # Empty array\n",
    "    earr = np.empty(400)\n",
    "    earr[:] = np.nan\n",
    "\n",
    "    # Check that combined token exists in the vocab. This protects against inflation of n-gram counts caused by repeats\n",
    "    #  of the same token (e.g. in lists like https://simple.wikipedia.org/wiki/List_of_cities,_towns_and_villages_in_Fars_Province)\n",
    "    if mwetoken in batch_model.wv.vocab:\n",
    "\n",
    "        mwv = model.wv[mwetoken]\n",
    "\n",
    "        for w in exp:\n",
    "            if w in model.wv.vocab:\n",
    "                cvs.append(model.wv[w])\n",
    "\n",
    "                #oldn.append(batch_model.wv.most_similar(w, topn=5))\n",
    "\n",
    "                if w in stop:\n",
    "                    sws.append(1)\n",
    "                    css.append(np.nan)\n",
    "                else:\n",
    "                    sws.append(0)\n",
    "                    css.append(cosim(model.wv[w], mwv ))\n",
    "\n",
    "            # If component is absent from vocab\n",
    "            else:\n",
    "                sws.append(-1)\n",
    "                cvs.append(earr)\n",
    "                css.append(np.nan)\n",
    "\n",
    "                #oldn.append([])\n",
    "\n",
    "        #  Mean cosim\n",
    "        if min(sws) >= 0:\n",
    "            cs = np.nanmean(css)\n",
    "        else:\n",
    "            cs = np.nan\n",
    "\n",
    "        #newn = batch_model.wv.most_similar(mwetoken, topn=5)\n",
    "\n",
    "    # Combined token missing from vocab - mark with defaults\n",
    "    else:\n",
    "        sws = [-2]\n",
    "        mwv = np.empty(400)\n",
    "        mwv[:] = np.nan\n",
    "        cs = np.nan\n",
    "\n",
    "\n",
    "    # Append to stats df\n",
    "    return stats_frame.append({\n",
    "        'ngram'  : exp,\n",
    "        'stopwords' : sws,\n",
    "        'mwe_vector' : mwv,\n",
    "        'component_vectors' : cvs,\n",
    "        'component_cosims'  : css,\n",
    "        'cosine_sim'  : cs,\n",
    "        #'base_nearest': oldn,\n",
    "        #'mwe_nearest' : newn,\n",
    "    }, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1 of 10\n",
      "Loading w2v model\n",
      "Gathering MWE stats\n",
      " MWE 0/94011: References+External+links\n",
      " MWE 5000/94011: 2016–17+season\n",
      " MWE 10000/94011: said+she\n",
      " MWE 15000/94011: Nuevo+Laredo\n",
      " MWE 20000/94011: Campeonato+de+Portugal\n",
      " MWE 25000/94011: going+down\n",
      " MWE 30000/94011: was+convicted+in\n",
      " MWE 35000/94011: begin+work+on\n",
      " MWE 40000/94011: Julien+Duvivier\n",
      " MWE 45000/94011: municipal+unit+has\n",
      " MWE 50000/94011: Bobby+Hutcherson\n",
      " MWE 55000/94011: Little+Feat\n",
      " MWE 60000/94011: Multiple+Launch+Rocket\n",
      " MWE 65000/94011: Institutional+Investor\n",
      " MWE 70000/94011: Guillermo+Coria\n",
      " MWE 75000/94011: Delta+Connection\n",
      " MWE 80000/94011: reduce+energy+consumption\n",
      " MWE 85000/94011: consist+primarily+of\n",
      " MWE 90000/94011: would+entail\n",
      "Processing batch 2 of 10\n",
      "Loading w2v model\n",
      "Gathering MWE stats\n",
      " MWE 0/79538: External+links\n",
      " MWE 5000/79538: Liberal+Democratic+Party\n",
      " MWE 10000/79538: forced+out+of\n",
      " MWE 15000/79538: electricity+generation\n",
      " MWE 20000/79538: the+wreck\n",
      " MWE 25000/79538: and+Merrie+Melodies\n",
      " MWE 30000/79538: topical+guide+to\n",
      " MWE 35000/79538: An+overview\n",
      " MWE 40000/79538: Raitz+von\n",
      " MWE 45000/79538: The+current+editor-in-chief\n",
      " MWE 50000/79538: The+front+of\n",
      " MWE 55000/79538: seize+power\n",
      " MWE 60000/79538: Peakposition+US+Bubbling\n",
      " MWE 65000/79538: the+functionality+of\n",
      " MWE 70000/79538: Blue+Hens\n",
      " MWE 75000/79538: the+monument+to\n",
      "Processing batch 3 of 10\n",
      "Loading w2v model\n",
      "Gathering MWE stats\n",
      " MWE 0/69221: References+External\n",
      " MWE 5000/69221: often+seen\n",
      " MWE 10000/69221: OTW+OTL+L\n",
      " MWE 15000/69221: western+Atlantic+Ocean\n",
      " MWE 20000/69221: during+spring+training\n",
      " MWE 25000/69221: your+heart\n",
      " MWE 30000/69221: T+R+Sundaram\n",
      " MWE 35000/69221: up+to+50%\n",
      " MWE 40000/69221: Came+Back\n",
      " MWE 45000/69221: teen+years\n",
      " MWE 50000/69221: for+membership\n",
      " MWE 55000/69221: sire+of+winners\n",
      " MWE 60000/69221: the+train+was\n",
      " MWE 65000/69221: an+aggregated+score\n",
      "Processing batch 4 of 10\n",
      "Loading w2v model\n",
      "Gathering MWE stats\n",
      " MWE 0/56154: also+known+as\n",
      " MWE 5000/56154: empties+into+the\n",
      " MWE 10000/56154: Commentary+on+the\n",
      " MWE 15000/56154: manages+to+convince\n",
      " MWE 20000/56154: lack+of+transparency\n",
      " MWE 25000/56154: Railroad+Station\n",
      " MWE 30000/56154: in+the+25th\n",
      " MWE 35000/56154: 90th+anniversary\n",
      " MWE 40000/56154: Dutra+da\n",
      " MWE 45000/56154: during+his+long\n",
      " MWE 50000/56154: put+the+ball\n",
      " MWE 55000/56154: of+her+family's\n",
      "Processing batch 5 of 10\n",
      "Loading w2v model\n",
      "Gathering MWE stats\n",
      " MWE 0/48934: the+end\n",
      " MWE 5000/48934: Lemmon+Survey+2.2\n",
      " MWE 10000/48934: the+squad+for\n",
      " MWE 15000/48934: Northern+Arizona+University\n",
      " MWE 20000/48934: BOS+CHI+CLE\n",
      " MWE 25000/48934: spaces+are\n",
      " MWE 30000/48934: being+investigated+for\n",
      " MWE 35000/48934: the+following+six\n",
      " MWE 40000/48934: to+the+stadium\n",
      " MWE 45000/48934: rifles+and+carbines\n",
      "Processing batch 6 of 10\n",
      "Loading w2v model\n",
      "Gathering MWE stats\n",
      " MWE 0/38288: is+located+in\n",
      " MWE 5000/38288: Minister+of+Interior\n",
      " MWE 10000/38288: fact+it+was\n",
      " MWE 15000/38288: speed+at+which\n",
      " MWE 20000/38288: Dulles+International\n",
      " MWE 25000/38288: have+benefited\n",
      " MWE 30000/38288: 3–1+loss\n",
      " MWE 35000/38288: perform+oral+sex\n",
      "Processing batch 7 of 10\n",
      "Loading w2v model\n",
      "Gathering MWE stats\n",
      " MWE 0/30374: located+in+the\n",
      " MWE 5000/30374: often+used+by\n",
      " MWE 10000/30374: Edward+L\n",
      " MWE 15000/30374: highest+rates+of\n",
      " MWE 20000/30374: with+my\n",
      " MWE 25000/30374: forum+for+the\n",
      " MWE 30000/30374: royal+charter+issued\n",
      "Processing batch 8 of 10\n",
      "Loading w2v model\n",
      "Gathering MWE stats\n",
      " MWE 0/22495: to+return+to\n",
      " MWE 5000/22495: French+film\n",
      " MWE 10000/22495: able+to+locate\n",
      " MWE 15000/22495: his+life+story\n",
      " MWE 20000/22495: point+of+interest\n",
      "Processing batch 9 of 10\n",
      "Loading w2v model\n",
      "Gathering MWE stats\n",
      " MWE 0/19272: as+opposed+to\n",
      " MWE 1000/19272: Team+Event\n",
      " MWE 2000/19272: southern+boundary+of\n",
      " MWE 3000/19272: team+had\n",
      " MWE 4000/19272: Cup+game+against\n",
      " MWE 5000/19272: German+drama+film\n",
      " MWE 6000/19272: Sussex+County+Delaware\n",
      " MWE 7000/19272: later+due+to\n",
      " MWE 8000/19272: Department+of+Physical\n",
      " MWE 9000/19272: the+lower+divisions\n",
      " MWE 10000/19272: other+matters\n",
      " MWE 11000/19272: 30+January+2014\n",
      " MWE 12000/19272: Result+Date+Tournament\n",
      " MWE 13000/19272: closed+in+1992\n",
      " MWE 14000/19272: August+21+2012\n",
      " MWE 15000/19272: annual+award+ceremony\n",
      " MWE 16000/19272: greatest+success+came\n",
      " MWE 17000/19272: first-class+debut+on\n",
      " MWE 18000/19272: water+power\n",
      " MWE 19000/19272: Buddhist+monks+and\n",
      "Processing batch 10 of 10\n",
      "Loading w2v model\n",
      "Gathering MWE stats\n",
      " MWE 0/11300: to+ensure+that\n",
      " MWE 1000/11300: in+Raleigh+North\n",
      " MWE 2000/11300: Short+History\n",
      " MWE 3000/11300: Back+to+You\n",
      " MWE 4000/11300: to+attract+new\n",
      " MWE 5000/11300: died+after+falling\n",
      " MWE 6000/11300: in+1990+with\n",
      " MWE 7000/11300: period+also+saw\n",
      " MWE 8000/11300: Baltimore+Ravens+On\n",
      " MWE 9000/11300: a+more+suitable\n",
      " MWE 10000/11300: French+squadron\n",
      " MWE 11000/11300: a+more+moderate\n",
      "Wall time: 51min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "batch_dfs = {}\n",
    "\n",
    "for bb in range(batch_count):\n",
    "    print('Processing batch {} of {}'.format(bb+1,batch_count))\n",
    "    \n",
    "    # Subset DataFrame\n",
    "    batch_dfs[bb] = ngram_eval[ngram_eval.batch == bb+1].reset_index(drop=True)\n",
    "    \n",
    "    # Initialise MWETokenizer\n",
    "    batch_token_mwe = MWETokenizer(list(batch_dfs[bb].ngram) , separator='+')\n",
    "    \n",
    "    # Load model\n",
    "    print('Loading w2v model')\n",
    "\n",
    "    batch_model = Word2Vec.load(datapath+'/Models/1 w2v/wiki10pc_batch{}.model'.format(bb+1))\n",
    "    \n",
    "    print('Gathering MWE stats')\n",
    "    \n",
    "    # For each MWE, evaluate stats. Record vectors (in case we want to calculate different metrics later).\n",
    "    statsf = pd.DataFrame(columns=['ngram', 'stopwords', 'mwe_vector', 'component_vectors', 'component_cosims', \n",
    "                                   'cosine_sim']) # , 'base_nearest', 'mwe_nearest'\n",
    "    batch_len = len(batch_dfs[bb].ngram)\n",
    "    if batch_len >= 20000: \n",
    "        printer = 5000\n",
    "    elif batch_len >= 5000: \n",
    "        printer = 1000\n",
    "    else:\n",
    "        printer = 200\n",
    "        \n",
    "    _i = 0\n",
    "    \n",
    "    for exp in batch_dfs[bb].ngram:\n",
    "        if _i % printer == 0:\n",
    "            print(' MWE '+str(_i)+'/'+str(batch_len)+': '+'+'.join(exp))\n",
    "        _i += 1\n",
    "        \n",
    "        statsf = mwe_score(exp, batch_model, statsf)\n",
    "        \n",
    "    #  Join back onto DataFrame\n",
    "    batch_dfs[bb] = batch_dfs[bb].merge(statsf, on='ngram')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending batch 1 of 10\n",
      "Appending batch 2 of 10\n",
      "Appending batch 3 of 10\n",
      "Appending batch 4 of 10\n",
      "Appending batch 5 of 10\n",
      "Appending batch 6 of 10\n",
      "Appending batch 7 of 10\n",
      "Appending batch 8 of 10\n",
      "Appending batch 9 of 10\n",
      "Appending batch 10 of 10\n"
     ]
    }
   ],
   "source": [
    "# Merge dataframes, sort by compositionality metric, export\n",
    "\n",
    "# Also want the default batches with batch no < 0\n",
    "all_batches = ngram_eval[ngram_eval.batch < 0]\n",
    "\n",
    "for d in range(batch_count):\n",
    "    print('Appending batch {} of '.format(d+1)+str(batch_count))\n",
    "    all_batches = all_batches.append(batch_dfs[d])\n",
    "    \n",
    "all_batches = all_batches.sort_values('cosine_sim')\n",
    "all_batches = all_batches.reset_index(drop=True)\n",
    "\n",
    "all_batches.to_csv(datapath+'/Models/1 w2v/Results/wiki10pc_output_001.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>poisson</th>\n",
       "      <th>len</th>\n",
       "      <th>batch</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>mwe_vector</th>\n",
       "      <th>component_vectors</th>\n",
       "      <th>component_cosims</th>\n",
       "      <th>cosine_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(1980s, 1970s, 1960s)</td>\n",
       "      <td>504.762099</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0.13252905, 0.2195085, 0.16913609, 0.18139634...</td>\n",
       "      <td>[[0.8419779, -0.8224145, -1.1535275, -0.101147...</td>\n",
       "      <td>[-0.23996054, -0.23782371, -0.2340202]</td>\n",
       "      <td>-0.237268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(amongst, many, others)</td>\n",
       "      <td>712.565055</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0.014603417, 0.11368454, 0.1424945, 0.1589423...</td>\n",
       "      <td>[[1.1393661, -0.18046533, -0.26049742, 0.29468...</td>\n",
       "      <td>[-0.15940933, -0.21269974, -0.19618905]</td>\n",
       "      <td>-0.189433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(European, register, of)</td>\n",
       "      <td>588.560764</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[0.14991252, 0.15334864, 0.24452145, 0.3467293...</td>\n",
       "      <td>[[0.088441856, -1.0335438, 0.83159375, -2.4368...</td>\n",
       "      <td>[-0.1621425, -0.21278596, nan]</td>\n",
       "      <td>-0.187464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(1950s, 1940s, 1930s)</td>\n",
       "      <td>576.491489</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0.20758897, 0.26073128, 0.2666307, 0.3133268,...</td>\n",
       "      <td>[[-0.43351597, -0.032804497, -0.5531056, -1.58...</td>\n",
       "      <td>[-0.18906975, -0.1606813, -0.19921347]</td>\n",
       "      <td>-0.182988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(As, far, back)</td>\n",
       "      <td>449.645748</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[-0.009685142, 0.012536515, 0.1396035, 0.10224...</td>\n",
       "      <td>[[-0.2582686, 0.022926275, -0.18216193, -0.799...</td>\n",
       "      <td>[-0.09595686, -0.2087354, -0.24125503]</td>\n",
       "      <td>-0.181982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499995</th>\n",
       "      <td>(Billboard, R_B, Albums)</td>\n",
       "      <td>482.775787</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>[-2]</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499996</th>\n",
       "      <td>(eligible, Not, eligible)</td>\n",
       "      <td>459.896112</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>[-2]</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499997</th>\n",
       "      <td>(Change, Seats, Change)</td>\n",
       "      <td>450.553474</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>[-2]</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499998</th>\n",
       "      <td>(A_M, University, System)</td>\n",
       "      <td>425.385206</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>[-2]</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499999</th>\n",
       "      <td>(under, the, LaxmiNarayan)</td>\n",
       "      <td>416.549424</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>[0, 1, -1]</td>\n",
       "      <td>[0.07590307, 0.21432732, 0.07106148, 0.1203041...</td>\n",
       "      <td>[[-0.08687744, -0.13019331, -0.012585309, -0.3...</td>\n",
       "      <td>[-0.10454963, nan, nan]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             ngram     poisson  len  batch   stopwords  \\\n",
       "0            (1980s, 1970s, 1960s)  504.762099    3      8   [0, 0, 0]   \n",
       "1          (amongst, many, others)  712.565055    3      1   [0, 0, 0]   \n",
       "2         (European, register, of)  588.560764    3      1   [0, 0, 1]   \n",
       "3            (1950s, 1940s, 1930s)  576.491489    3     10   [0, 0, 0]   \n",
       "4                  (As, far, back)  449.645748    3      3   [0, 0, 0]   \n",
       "...                            ...         ...  ...    ...         ...   \n",
       "499995    (Billboard, R_B, Albums)  482.775787    3     10        [-2]   \n",
       "499996   (eligible, Not, eligible)  459.896112    3     10        [-2]   \n",
       "499997     (Change, Seats, Change)  450.553474    3     10        [-2]   \n",
       "499998   (A_M, University, System)  425.385206    3     10        [-2]   \n",
       "499999  (under, the, LaxmiNarayan)  416.549424    3     10  [0, 1, -1]   \n",
       "\n",
       "                                               mwe_vector  \\\n",
       "0       [0.13252905, 0.2195085, 0.16913609, 0.18139634...   \n",
       "1       [0.014603417, 0.11368454, 0.1424945, 0.1589423...   \n",
       "2       [0.14991252, 0.15334864, 0.24452145, 0.3467293...   \n",
       "3       [0.20758897, 0.26073128, 0.2666307, 0.3133268,...   \n",
       "4       [-0.009685142, 0.012536515, 0.1396035, 0.10224...   \n",
       "...                                                   ...   \n",
       "499995  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "499996  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "499997  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "499998  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "499999  [0.07590307, 0.21432732, 0.07106148, 0.1203041...   \n",
       "\n",
       "                                        component_vectors  \\\n",
       "0       [[0.8419779, -0.8224145, -1.1535275, -0.101147...   \n",
       "1       [[1.1393661, -0.18046533, -0.26049742, 0.29468...   \n",
       "2       [[0.088441856, -1.0335438, 0.83159375, -2.4368...   \n",
       "3       [[-0.43351597, -0.032804497, -0.5531056, -1.58...   \n",
       "4       [[-0.2582686, 0.022926275, -0.18216193, -0.799...   \n",
       "...                                                   ...   \n",
       "499995                                                 []   \n",
       "499996                                                 []   \n",
       "499997                                                 []   \n",
       "499998                                                 []   \n",
       "499999  [[-0.08687744, -0.13019331, -0.012585309, -0.3...   \n",
       "\n",
       "                               component_cosims  cosine_sim  \n",
       "0        [-0.23996054, -0.23782371, -0.2340202]   -0.237268  \n",
       "1       [-0.15940933, -0.21269974, -0.19618905]   -0.189433  \n",
       "2                [-0.1621425, -0.21278596, nan]   -0.187464  \n",
       "3        [-0.18906975, -0.1606813, -0.19921347]   -0.182988  \n",
       "4        [-0.09595686, -0.2087354, -0.24125503]   -0.181982  \n",
       "...                                         ...         ...  \n",
       "499995                                       []         NaN  \n",
       "499996                                       []         NaN  \n",
       "499997                                       []         NaN  \n",
       "499998                                       []         NaN  \n",
       "499999                  [-0.10454963, nan, nan]         NaN  \n",
       "\n",
       "[500000 rows x 9 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
