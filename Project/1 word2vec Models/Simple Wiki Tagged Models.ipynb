{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\User\\\\Google Drive\\\\University\\\\Dissertation\\\\Code'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = 'C:/Users/'+os.getlogin()+'/Google Drive/University/Dissertation'\n",
    "#datapath = 'C:/Users/'+os.getlogin()+'/Dissertation Data'\n",
    "datapath = 'E:/Dissertation Data'\n",
    "\n",
    "os.chdir(path+'/Code')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import MWETokenizer\n",
    "\n",
    "from glove import Corpus, Glove\n",
    "\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "April|NNP is|VBZ the|DT fourth|JJ month|NN of|IN the|DT year|NN and|CC comes|VBZ between|IN March|NNP and|CC May|NNP \n",
      "\n",
      "It|PRP is|VBZ one|CD of|IN four|CD months|NNS to|TO have|VB 30|CD days|NNS \n",
      "\n",
      "April|NNP always|RB begins|VBZ on|IN the|DT same|JJ day|NN of|IN week|NN as|IN July|NNP and|CC additionally|RB January|NNP in|IN leap|NNP years|NNS \n",
      "\n",
      "April|NNP always|RB ends|VBZ on|IN the|DT same|JJ day|NN of|IN the|DT week|NN as|IN December|NNP \n",
      "\n",
      "April|NNP 's|POS flowers|NNS are|VBP the|DT Sweet|NNP Pea|NN and|CC Daisy|NNP \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# On Simple English wiki, POS tagged\n",
    "\n",
    "sf = open(datapath+'/Corpora/wiki/simple_20200601/Tagged/simple_20200601_tagged.txt', 'r', encoding='utf-8')\n",
    "\n",
    "for lines in range(5):\n",
    "    print(sf.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus.reader.plaintext import PlaintextCorpusReader\n",
    "\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "\n",
    "from nltk.corpus.reader.util import read_line_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "simp_t = PlaintextCorpusReader(datapath+'/Corpora/wiki/simple_20200601/Tagged','simple_20200601_tagged.txt',\n",
    "                            word_tokenizer = WhitespaceTokenizer(),\n",
    "                            para_block_reader=read_line_block\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import word and sentence generators\n",
    "\n",
    "from generators import sent_gen, word_gen, Sent_Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collate n-grams\n",
    "\n",
    "from nltk.collocations import BigramCollocationFinder, TrigramCollocationFinder\n",
    "\n",
    "from nltk.metrics import (\n",
    "    BigramAssocMeasures,\n",
    "    TrigramAssocMeasures,\n",
    "    NgramAssocMeasures,\n",
    ")\n",
    "\n",
    "from nltk.metrics.spearman import (\n",
    "    spearman_correlation,\n",
    "    ranks_from_scores,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopwords from corpus - 50 most frequent\n",
    "\n",
    "with open(datapath+'/Corpora/wiki/simple_20200601/Tagged/stop.pkl', 'rb') as pfile:\n",
    "    stop = pickle.load(pfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0|CD',\n",
       " '1|CD',\n",
       " '2|CD',\n",
       " '3|CD',\n",
       " '4|CD',\n",
       " 'A|DT',\n",
       " 'He|PRP',\n",
       " 'In|IN',\n",
       " 'It|PRP',\n",
       " 'The|DT',\n",
       " 'also|RB',\n",
       " 'and|CC',\n",
       " 'an|DT',\n",
       " 'are|VBP',\n",
       " 'as|IN',\n",
       " 'at|IN',\n",
       " 'a|DT',\n",
       " 'be|VB',\n",
       " 'born|VBN',\n",
       " 'by|IN',\n",
       " 'can|MD',\n",
       " 'first|JJ',\n",
       " 'for|IN',\n",
       " 'from|IN',\n",
       " 'had|VBD',\n",
       " 'has|VBZ',\n",
       " 'he|PRP',\n",
       " 'his|PRP$',\n",
       " 'in|IN',\n",
       " 'is|VBZ',\n",
       " 'it|PRP',\n",
       " 'not|RB',\n",
       " 'of|IN',\n",
       " 'one|CD',\n",
       " 'on|IN',\n",
       " 'or|CC',\n",
       " 'people|NNS',\n",
       " 's|POS',\n",
       " 'that|IN',\n",
       " 'that|WDT',\n",
       " 'they|PRP',\n",
       " 'the|DT',\n",
       " 'to|IN',\n",
       " 'to|TO',\n",
       " 'was|VBD',\n",
       " 'were|VBD',\n",
       " 'which|WDT',\n",
       " 'with|IN',\n",
       " '|HYPH',\n",
       " '–|SYM'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_freq = 20\n",
    "eval_count = 150000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>freq</th>\n",
       "      <th>poisson</th>\n",
       "      <th>len</th>\n",
       "      <th>batch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Grădina|NNP, Zoologică|NNP)</td>\n",
       "      <td>20</td>\n",
       "      <td>-606.668931</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Karlovy|NNP, Vary|NNP)</td>\n",
       "      <td>20</td>\n",
       "      <td>-606.668931</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Ving|NNP, Rhames|NNP)</td>\n",
       "      <td>20</td>\n",
       "      <td>-606.668931</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(waystations|NNS, shuku|NN)</td>\n",
       "      <td>20</td>\n",
       "      <td>-608.076717</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Aer|NNP, Lingus|NNP)</td>\n",
       "      <td>20</td>\n",
       "      <td>-609.419001</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149995</th>\n",
       "      <td>(Cena|NNP, and|CC)</td>\n",
       "      <td>56</td>\n",
       "      <td>-2732.579707</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149996</th>\n",
       "      <td>(and|CC, keeping|VBG)</td>\n",
       "      <td>56</td>\n",
       "      <td>-2732.579707</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149997</th>\n",
       "      <td>(province|NN, has|VBZ, a|DT)</td>\n",
       "      <td>40</td>\n",
       "      <td>-2732.586816</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149998</th>\n",
       "      <td>(speak|VBP, a|DT)</td>\n",
       "      <td>56</td>\n",
       "      <td>-2732.604570</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149999</th>\n",
       "      <td>(DC|NNP, 3|CD)</td>\n",
       "      <td>59</td>\n",
       "      <td>-2732.631310</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               ngram  freq      poisson  len  batch\n",
       "0       (Grădina|NNP, Zoologică|NNP)    20  -606.668931    2      1\n",
       "1            (Karlovy|NNP, Vary|NNP)    20  -606.668931    2      1\n",
       "2             (Ving|NNP, Rhames|NNP)    20  -606.668931    2      1\n",
       "3        (waystations|NNS, shuku|NN)    20  -608.076717    2      1\n",
       "4              (Aer|NNP, Lingus|NNP)    20  -609.419001    2      1\n",
       "...                              ...   ...          ...  ...    ...\n",
       "149995            (Cena|NNP, and|CC)    56 -2732.579707    2      5\n",
       "149996         (and|CC, keeping|VBG)    56 -2732.579707    2      1\n",
       "149997  (province|NN, has|VBZ, a|DT)    40 -2732.586816    3      6\n",
       "149998             (speak|VBP, a|DT)    56 -2732.604570    2      2\n",
       "149999                (DC|NNP, 3|CD)    59 -2732.631310    2      2\n",
       "\n",
       "[150000 rows x 5 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_eval = pd.read_pickle(datapath+'/Corpora/wiki/simple_20200601/Tagged/ngram_eval.pkl')\n",
    "\n",
    "ngram_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_count = max(ngram_eval.batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1     47772\n",
       " 2     33213\n",
       " 3     25419\n",
       " 4     15895\n",
       " 5     10517\n",
       " 6      6533\n",
       " 7      3782\n",
       " 8      2398\n",
       " 9      1434\n",
       " 10     1073\n",
       "-2       732\n",
       " 11      317\n",
       "-1       282\n",
       " 14      239\n",
       " 12      227\n",
       " 13       96\n",
       " 15       71\n",
       "Name: batch, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_eval.batch.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import MWETokenizer\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Flatten down to a single number\n",
    "def cosim(x,y):\n",
    "    return cosine_similarity(x.reshape(1,-1), y.reshape(1,-1))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['April|NNP', 'is|VBZ', 'the|DT', 'fourth|JJ', 'month|NN', 'of|IN', 'the|DT', 'year|NN', 'and|CC', 'comes|VBZ', 'between|IN', 'March|NNP', 'and|CC', 'May|NNP']\n"
     ]
    }
   ],
   "source": [
    "for s in Sent_Seq(simp_t, remchars = \"[`¬@^\\\"]\"):\n",
    "    print(s)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1 of 15\n",
      "Building word2vec model\n",
      " Training model\n",
      " Saving model\n",
      "Processing batch 2 of 15\n",
      "Building word2vec model\n",
      " Training model\n",
      " Saving model\n",
      "Processing batch 3 of 15\n",
      "Building word2vec model\n",
      " Training model\n",
      " Saving model\n",
      "Processing batch 4 of 15\n",
      "Building word2vec model\n",
      " Training model\n",
      " Saving model\n",
      "Processing batch 5 of 15\n",
      "Building word2vec model\n",
      " Training model\n",
      " Saving model\n",
      "Processing batch 6 of 15\n",
      "Building word2vec model\n",
      " Training model\n",
      " Saving model\n",
      "Processing batch 7 of 15\n",
      "Building word2vec model\n",
      " Training model\n",
      " Saving model\n",
      "Processing batch 8 of 15\n",
      "Building word2vec model\n",
      " Training model\n",
      " Saving model\n",
      "Processing batch 9 of 15\n",
      "Building word2vec model\n",
      " Training model\n",
      " Saving model\n",
      "Processing batch 10 of 15\n",
      "Building word2vec model\n",
      " Training model\n",
      " Saving model\n",
      "Processing batch 11 of 15\n",
      "Building word2vec model\n",
      " Training model\n",
      " Saving model\n",
      "Processing batch 12 of 15\n",
      "Building word2vec model\n",
      " Training model\n",
      " Saving model\n",
      "Processing batch 13 of 15\n",
      "Building word2vec model\n",
      " Training model\n",
      " Saving model\n",
      "Processing batch 14 of 15\n",
      "Building word2vec model\n",
      " Training model\n",
      " Saving model\n",
      "Processing batch 15 of 15\n",
      "Building word2vec model\n",
      " Training model\n",
      " Saving model\n",
      "Wall time: 9h 58min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "batch_dfs = {}\n",
    "\n",
    "for bb in range(batch_count):\n",
    "    print('Processing batch {} of {}'.format(bb+1,batch_count))\n",
    "    \n",
    "    # Subset DataFrame\n",
    "    batch_dfs[bb] = ngram_eval[ngram_eval.batch == bb+1].reset_index(drop=True)\n",
    "    \n",
    "    # Initialise MWETokenizer\n",
    "    batch_token_mwe = MWETokenizer(list(batch_dfs[bb].ngram) , separator='+')\n",
    "    \n",
    "    # Build model\n",
    "    print('Building word2vec model')\n",
    "    sents_mwe = Sent_Seq(simp_t, tokenizer = batch_token_mwe, remchars = \"[`¬@^\\\"]\")\n",
    "    \n",
    "    print(' Training model')\n",
    "    batch_model = Word2Vec(sents_mwe,\n",
    "                             min_count = 20,  # 20 matches R&E on EN Wiki\n",
    "                             size = 400,\n",
    "                             workers = 8,\n",
    "                             window = 5,\n",
    "                             sg = 0,         # CBOW\n",
    "                             sample = 10e-5, # Subsampling\n",
    "                             negative = 10\n",
    "                            )\n",
    "\n",
    "    # Save model\n",
    "    print(' Saving model')\n",
    "    batch_model.save(datapath+'/Models/1 w2v/Tagged/simp_tagged_batch{}.model'.format(bb+1))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
