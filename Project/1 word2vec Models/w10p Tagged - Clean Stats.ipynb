{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\User\\\\Google Drive\\\\University\\\\Dissertation\\\\Code'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = 'C:/Users/'+os.getlogin()+'/Google Drive/University/Dissertation'\n",
    "datapath = 'E:/Dissertation Data'\n",
    "#datapath = 'C:/Users/'+os.getlogin()+'/Dissertation Data'\n",
    "\n",
    "os.chdir(path+'/Code')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import MWETokenizer\n",
    "\n",
    "#from glove import Corpus, Glove\n",
    "\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.metrics import (\n",
    "    BigramAssocMeasures,\n",
    "    TrigramAssocMeasures,\n",
    "    NgramAssocMeasures,\n",
    ")\n",
    "\n",
    "from nltk.metrics.spearman import (\n",
    "    spearman_correlation,\n",
    "    ranks_from_scores,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then automatically score the million most strongly associated\n",
    "n-grams (i.e., roughly the top 5% of the Poisson-ranked\n",
    "list) for compositionality.\n",
    "\n",
    "Using word2vec (Mikolov et al., 2013) with the parameters\n",
    "found to be most effective by Baroni et al. (2014), we\n",
    "build a word embedding vector for every simplex word in\n",
    "the vocabulary (ca. 1M types), as well as for each MWE candidate.\n",
    "\n",
    "* Continuous bag of words model with 400-dimensional vectors, window size 5, subsampling with t = 10^-5, negative sampling with 10 samples. We build vectors only for tokens observed 20 times or more in the corpus.\n",
    "\n",
    "We then compute the cosine similarity of the vector\n",
    "representation for a MWE candidate with the vectors of its\n",
    "constituent words, and take the arithmetic mean. \n",
    "In scoring\n",
    "the compositionality of a candidate, we do not measure the\n",
    "cosine similarity of the MWE with any stop words it may\n",
    "contain, as stop words may be assumed to be semantically\n",
    "uninformative.\n",
    "* Stop words are taken here to be the 50 most frequent words in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopwords from corpus - 50 most frequent\n",
    "\n",
    "with open(datapath+'/Corpora/wiki/enwiki_20200520/Tagged/stop_clean.pkl', 'rb') as pfile:\n",
    "    stop = pickle.load(pfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0|CD',\n",
       " '1|CD',\n",
       " '2|CD',\n",
       " 'A|DT',\n",
       " 'He|PRP',\n",
       " 'In|IN',\n",
       " 'It|PRP',\n",
       " 'New|NNP',\n",
       " 'The|DT',\n",
       " 'after|IN',\n",
       " 'also|RB',\n",
       " 'and|CC',\n",
       " 'an|DT',\n",
       " 'are|VBP',\n",
       " 'as|IN',\n",
       " 'at|IN',\n",
       " 'a|DT',\n",
       " 'been|VBN',\n",
       " 'be|VB',\n",
       " 'but|CC',\n",
       " 'by|IN',\n",
       " 'first|JJ',\n",
       " 'for|IN',\n",
       " 'from|IN',\n",
       " 'had|VBD',\n",
       " 'has|VBZ',\n",
       " 'he|PRP',\n",
       " 'his|PRP$',\n",
       " 'in|IN',\n",
       " 'is|VBZ',\n",
       " 'its|PRP$',\n",
       " 'it|PRP',\n",
       " 'not|RB',\n",
       " 'of|IN',\n",
       " 'one|CD',\n",
       " 'on|IN',\n",
       " 'or|CC',\n",
       " 'that|IN',\n",
       " 'that|WDT',\n",
       " 'their|PRP$',\n",
       " 'the|DT',\n",
       " 'this|DT',\n",
       " 'to|IN',\n",
       " 'to|TO',\n",
       " 'two|CD',\n",
       " 'was|VBD',\n",
       " 'were|VBD',\n",
       " 'which|WDT',\n",
       " 'who|WP',\n",
       " 'with|IN'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>freq</th>\n",
       "      <th>poisson</th>\n",
       "      <th>len</th>\n",
       "      <th>batch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Dechawat|NNP, Poomjaeng|NNP)</td>\n",
       "      <td>20</td>\n",
       "      <td>-666.206003</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(MSC1|NN, MSC2|NN)</td>\n",
       "      <td>20</td>\n",
       "      <td>-666.206003</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(resting_place_coordinates|NNS, burial_place|VBP)</td>\n",
       "      <td>20</td>\n",
       "      <td>-666.206003</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Neophron|NNP, percnopterus|NNP)</td>\n",
       "      <td>20</td>\n",
       "      <td>-667.613790</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Eugeniya|NNP, Pashkova|NNP)</td>\n",
       "      <td>20</td>\n",
       "      <td>-668.956074</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499995</th>\n",
       "      <td>(Mom|NNP, Deserves|VBZ, a|DT)</td>\n",
       "      <td>28</td>\n",
       "      <td>-1711.315270</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499996</th>\n",
       "      <td>(that|IN, he|PRP, takes|VBZ)</td>\n",
       "      <td>22</td>\n",
       "      <td>-1711.316813</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499997</th>\n",
       "      <td>(got|VBD, the|DT, best|JJS)</td>\n",
       "      <td>22</td>\n",
       "      <td>-1711.316966</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499998</th>\n",
       "      <td>(In|IN, his|PRP$, novel|JJ)</td>\n",
       "      <td>22</td>\n",
       "      <td>-1711.317012</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499999</th>\n",
       "      <td>(Warsaw|NNP, by|IN)</td>\n",
       "      <td>30</td>\n",
       "      <td>-1711.317160</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    ngram  freq      poisson  \\\n",
       "0                           (Dechawat|NNP, Poomjaeng|NNP)    20  -666.206003   \n",
       "1                                      (MSC1|NN, MSC2|NN)    20  -666.206003   \n",
       "2       (resting_place_coordinates|NNS, burial_place|VBP)    20  -666.206003   \n",
       "3                        (Neophron|NNP, percnopterus|NNP)    20  -667.613790   \n",
       "4                            (Eugeniya|NNP, Pashkova|NNP)    20  -668.956074   \n",
       "...                                                   ...   ...          ...   \n",
       "499995                      (Mom|NNP, Deserves|VBZ, a|DT)    28 -1711.315270   \n",
       "499996                       (that|IN, he|PRP, takes|VBZ)    22 -1711.316813   \n",
       "499997                        (got|VBD, the|DT, best|JJS)    22 -1711.316966   \n",
       "499998                        (In|IN, his|PRP$, novel|JJ)    22 -1711.317012   \n",
       "499999                                (Warsaw|NNP, by|IN)    30 -1711.317160   \n",
       "\n",
       "        len  batch  \n",
       "0         2      1  \n",
       "1         2      1  \n",
       "2         2      1  \n",
       "3         2      1  \n",
       "4         2      1  \n",
       "...     ...    ...  \n",
       "499995    3      4  \n",
       "499996    3      2  \n",
       "499997    3      6  \n",
       "499998    3      1  \n",
       "499999    2      8  \n",
       "\n",
       "[500000 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_eval = pd.read_pickle(datapath+'/Corpora/wiki/enwiki_20200520/Tagged/ngram_eval_clean.pkl')\n",
    "\n",
    "ngram_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_freq = 20\n",
    "eval_count = 500000\n",
    "\n",
    "batch_count = max(ngram_eval.batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1     179196\n",
       " 2     122020\n",
       " 3      79022\n",
       " 4      51014\n",
       " 5      29281\n",
       " 6      17771\n",
       " 7       9368\n",
       " 8       5678\n",
       " 9       2898\n",
       "-1       2017\n",
       " 10      1561\n",
       "-2        174\n",
       "Name: batch, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_eval.batch.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import MWETokenizer\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Flatten down to a single number\n",
    "def cosim(x,y):\n",
    "    return cosine_similarity(x.reshape(1,-1), y.reshape(1,-1))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mwe_score(exp, model, stats_frame):\n",
    "    \n",
    "    # Combined token for MWE\n",
    "    mwetoken = '+'.join(exp)\n",
    "\n",
    "    # Stopwords - 1 if component is a stopword, 0 if present, -1 if simplex word missing from vocab, -2 if MWE missing\n",
    "    sws = []\n",
    "    # Component vectors\n",
    "    cvs = []\n",
    "\n",
    "    #  Neighbours in original & MWE-aware space\n",
    "    #oldn = []\n",
    "    #newn = []\n",
    "\n",
    "    # List of individual word similarities (where present in the vocab)\n",
    "    css = []\n",
    "\n",
    "    # Empty array\n",
    "    earr = np.empty(400)\n",
    "    earr[:] = np.nan\n",
    "\n",
    "    # Check that combined token exists in the vocab. This protects against inflation of n-gram counts caused by repeats\n",
    "    #  of the same token (e.g. in lists like https://simple.wikipedia.org/wiki/List_of_cities,_towns_and_villages_in_Fars_Province)\n",
    "    if mwetoken in batch_model.wv.vocab:\n",
    "\n",
    "        mwv = model.wv[mwetoken]\n",
    "\n",
    "        for w in exp:\n",
    "            if w in model.wv.vocab:\n",
    "                cvs.append(model.wv[w])\n",
    "\n",
    "                #oldn.append(batch_model.wv.most_similar(w, topn=5))\n",
    "\n",
    "                if w in stop:\n",
    "                    sws.append(1)\n",
    "                    css.append(np.nan)\n",
    "                else:\n",
    "                    sws.append(0)\n",
    "                    css.append(cosim(model.wv[w], mwv ))\n",
    "\n",
    "            # If component is absent from vocab\n",
    "            else:\n",
    "                sws.append(-1)\n",
    "                cvs.append(earr)\n",
    "                css.append(np.nan)\n",
    "\n",
    "                #oldn.append([])\n",
    "\n",
    "        #  Mean cosim\n",
    "        if min(sws) >= 0:\n",
    "            cs = np.nanmean(css)\n",
    "        else:\n",
    "            cs = np.nan\n",
    "\n",
    "        #newn = batch_model.wv.most_similar(mwetoken, topn=5)\n",
    "\n",
    "    # Combined token missing from vocab - mark with defaults\n",
    "    else:\n",
    "        sws = [-2]\n",
    "        mwv = np.empty(400)\n",
    "        mwv[:] = np.nan\n",
    "        cs = np.nan\n",
    "\n",
    "\n",
    "    # Append to stats df\n",
    "    return stats_frame.append({\n",
    "        'ngram'  : exp,\n",
    "        'stopwords' : sws,\n",
    "        'mwe_vector' : mwv,\n",
    "        'component_vectors' : cvs,\n",
    "        'component_cosims'  : css,\n",
    "        'cosine_sim'  : cs,\n",
    "        #'base_nearest': oldn,\n",
    "        #'mwe_nearest' : newn,\n",
    "    }, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1 of 10\n",
      "Loading w2v model\n",
      "Gathering MWE stats\n",
      " MWE 0/179196: Dechawat|NNP+Poomjaeng|NNP\n",
      " MWE 5000/179196: ta|NNP+Know|NNP\n",
      " MWE 10000/179196: Ub|NNP+Iwerks|NNP\n",
      " MWE 15000/179196: Joseph|NNP+Merrick|NNP\n",
      " MWE 20000/179196: Scouts|NNS'+Association|NNP\n",
      " MWE 25000/179196: newspapers|NNS+ran|VBD\n",
      " MWE 30000/179196: a|DT+crevice|NN\n",
      " MWE 35000/179196: The|DT+GeForce|NNP\n",
      " MWE 40000/179196: Tajik|NNP+Cup|NNP\n",
      " MWE 45000/179196: 2014|CD+Skate|NNP\n",
      " MWE 50000/179196: US|NNP+-24|CD\n",
      " MWE 55000/179196: well|RB+again|RB\n",
      " MWE 60000/179196: to|IN+resolution|NN\n",
      " MWE 65000/179196: Mark|NNP+Casstevens|NNP\n",
      " MWE 70000/179196: attended|VBD+UCLA|NNP\n",
      " MWE 75000/179196: of|IN+disuse|NN\n",
      " MWE 80000/179196: C|NN-sharp|JJ+minor|JJ+Op|NN\n",
      " MWE 85000/179196: inheritance|NN+tax|NN\n",
      " MWE 90000/179196: often|RB+remembered|VBN\n",
      " MWE 95000/179196: multiple|JJ+targets|NNS\n",
      " MWE 100000/179196: intelligence|NN+test|NN\n",
      " MWE 105000/179196: in|IN+1986\n",
      " MWE 110000/179196: great|JJ+houses|NNS\n",
      " MWE 115000/179196: s|POS+Years|NNS\n",
      " MWE 120000/179196: Other|JJ+brands|NNS\n",
      " MWE 125000/179196: B|NNP+Sowerby|NNP+III|NNP\n",
      " MWE 130000/179196: in|IN+Orem|NNP\n",
      " MWE 135000/179196: She|PRP+concludes|VBZ\n",
      " MWE 140000/179196: public|JJ+school|NN+boards|NNS\n",
      " MWE 145000/179196: may|MD+persist|VB+for|IN\n",
      " MWE 150000/179196: began|VBD+work|NN+for|IN\n",
      " MWE 155000/179196: prominent|JJ+players|NNS\n",
      " MWE 160000/179196: was|VBD+clocked|VBN\n",
      " MWE 165000/179196: 1990|CD+Position|NN\n",
      " MWE 170000/179196: the|DT+Old|NNP+Mill|NNP\n",
      " MWE 175000/179196: Premiership|NN+season|NN\n",
      "Processing batch 2 of 10\n",
      "Loading w2v model\n",
      "Gathering MWE stats\n",
      " MWE 0/122020: burial_place|VBP+burial_coordinates|NNS\n",
      " MWE 5000/122020: 7th|JJ+10th|JJ\n",
      " MWE 10000/122020: heavily|RB+reliant|JJ\n",
      " MWE 15000/122020: central|JJ+black|JJ\n",
      " MWE 20000/122020: helicopter|NN+gunships|NNS\n",
      " MWE 25000/122020: RUC|NNP+Special|NNP\n",
      " MWE 30000/122020: pubs|NNS+The|DT\n",
      " MWE 35000/122020: right|NN+out|IN\n",
      " MWE 40000/122020: surface|NN+waves|NNS\n",
      " MWE 45000/122020: 2â€“3|CD+Vancouver|NNP\n",
      " MWE 50000/122020: Variation|NNP+Order|NNP+1992|CD\n",
      " MWE 55000/122020: System|NNP+Engineering|NNP\n",
      " MWE 60000/122020: Jr.|NNP+(|-LRB-\n",
      " MWE 65000/122020: Classics|NNS+1|CD\n",
      " MWE 70000/122020: Board|NNP+NTSB|NNP\n",
      " MWE 75000/122020: from|IN+Confederate|JJ\n",
      " MWE 80000/122020: protests|NNS+took|VBD+place|NN\n",
      " MWE 85000/122020: anonymity|NN+of|IN\n",
      " MWE 90000/122020: 29.6%|CD+had|VBD\n",
      " MWE 95000/122020: Treviranus|NNP+J|NNP\n",
      " MWE 100000/122020: earth|NN+stations|NNS\n",
      " MWE 105000/122020: June|NNP+2017|CD+in|IN\n",
      " MWE 110000/122020: highest|JJS+selling|VBG\n",
      " MWE 115000/122020: end|VBP+their|PRP$\n",
      " MWE 120000/122020: the|DT+Pedro|NNP\n",
      "Processing batch 3 of 10\n",
      "Loading w2v model\n",
      "Gathering MWE stats\n",
      " MWE 0/79022: resting_place_coordinates|NNS+burial_place|VBP+burial_coordinates|NNS\n",
      " MWE 5000/79022: motor|NN+neurone|NN\n",
      " MWE 10000/79022: corporations|NNS+power|NN\n",
      " MWE 15000/79022: de|NNP+Beaujeu|NNP\n",
      " MWE 20000/79022: playing|VBG+days|NNS\n",
      " MWE 25000/79022: traits|NNS+were|VBD\n",
      " MWE 30000/79022: Services|NNP+University|NNP\n",
      " MWE 35000/79022: Youth|NNP+Commission|NNP\n",
      " MWE 40000/79022: with|IN+Biblical|JJ\n",
      " MWE 45000/79022: fourteenth|NN+and|CC+fifteenth|NN\n",
      " MWE 50000/79022: Boy|NN+Wonder|NN\n",
      " MWE 55000/79022: expressed|VBD+strong|JJ\n",
      " MWE 60000/79022: in|IN+bed|NN+together|RB\n",
      " MWE 65000/79022: over|IN+48|CD\n",
      " MWE 70000/79022: Trenton|NNP+Titans|NNPS\n",
      " MWE 75000/79022: immediate|JJ+access|NN\n",
      "Processing batch 4 of 10\n",
      "Loading w2v model\n",
      "Gathering MWE stats\n",
      " MWE 0/51014: resting_place|NN+resting_place_coordinates|NNS+burial_place|VBP\n",
      " MWE 5000/51014: their|PRP$+Greek|JJ\n",
      " MWE 10000/51014: Left|VBD+Behind|IN\n",
      " MWE 15000/51014: controls|NNS+can|MD\n",
      " MWE 20000/51014: from|IN+mostly|RB\n",
      " MWE 25000/51014: foot|NN+a|DT\n",
      " MWE 30000/51014: 19|CD+September|NNP+2017|CD\n",
      " MWE 35000/51014: at|IN+Disneyland|NNP+in|IN\n",
      " MWE 40000/51014: proposed|VBN+route|NN+of|IN\n",
      " MWE 45000/51014: entered|VBD+the|DT+French|JJ\n",
      " MWE 50000/51014: Drake|NNP+to|TO\n",
      "Processing batch 5 of 10\n",
      "Loading w2v model\n",
      "Gathering MWE stats\n",
      " MWE 0/29281: body_discovered|VBN+resting_place|NN+resting_place_coordinates|NNS\n",
      " MWE 5000/29281: life|NN+By|IN\n",
      " MWE 10000/29281: Energy|NNP+Association|NNP\n",
      " MWE 15000/29281: by|IN+northern|JJ\n",
      " MWE 20000/29281: of|IN+Cheshire|NNP+East|NNP\n",
      " MWE 25000/29281: death|NN+duties|NNS\n",
      "Processing batch 6 of 10\n",
      "Loading w2v model\n",
      "Gathering MWE stats\n",
      " MWE 0/17771: Aydar|NNP+Belyaev|NNP+Andrey|NNP\n",
      " MWE 1000/17771: better|JJR+communication|NN\n",
      " MWE 2000/17771: removed|VBN+this|DT\n",
      " MWE 3000/17771: all|DT+county|NN\n",
      " MWE 4000/17771: Roy|NNP+William|NNP\n",
      " MWE 5000/17771: a|DT+debilitating|VBG+stroke|NN\n",
      " MWE 6000/17771: Criminal|JJ+law|NN\n",
      " MWE 7000/17771: Collins|NNP+also|RB\n",
      " MWE 8000/17771: revised|VBN+design|NN\n",
      " MWE 9000/17771: average|NN+while|IN\n",
      " MWE 10000/17771: set|VBN+high|JJ\n",
      " MWE 11000/17771: Curtis|NNP+Young|NNP\n",
      " MWE 12000/17771: is|VBZ+extended|VBN+to|TO\n",
      " MWE 13000/17771: studio|NN+in|IN+Paris|NNP\n",
      " MWE 14000/17771: Combined|JJ+days|NNS\n",
      " MWE 15000/17771: a|DT+Cincinnati|NNP\n",
      " MWE 16000/17771: One|CD+play|NN-off|NN\n",
      " MWE 17000/17771: Puerto|NNP+Rico|NNP+School|NNP\n",
      "Processing batch 7 of 10\n",
      "Loading w2v model\n",
      "Gathering MWE stats\n",
      " MWE 0/9368: dates|NNS+only|RB\n",
      " MWE 1000/9368: March|NNP+March|NNP\n",
      " MWE 2000/9368: Asia|NNP+Command|NNP\n",
      " MWE 3000/9368: BC|NN+A|DT\n",
      " MWE 4000/9368: Film|NNP+music|NN\n",
      " MWE 5000/9368: flew|VBD+more|JJR+than|IN\n",
      " MWE 6000/9368: track|NN+Do|VBP+n't|RB\n",
      " MWE 7000/9368: the|DT+government|NN+may|MD\n",
      " MWE 8000/9368: to|TO+ensure|VB+adequate|JJ\n",
      " MWE 9000/9368: energy|NN+market|NN\n",
      "Processing batch 8 of 10\n",
      "Loading w2v model\n",
      "Gathering MWE stats\n",
      " MWE 0/5678: 2007|CD+Texas|NNP\n",
      " MWE 1000/5678: where|WRB+someone|NN\n",
      " MWE 2000/5678: 1997|CD+song|NN\n",
      " MWE 3000/5678: at|IN+religious|JJ\n",
      " MWE 4000/5678: for|IN+a|DT+response|NN\n",
      " MWE 5000/5678: compensation|NN+is|VBZ+roughly|RB\n",
      "Processing batch 9 of 10\n",
      "Loading w2v model\n",
      "Gathering MWE stats\n",
      " MWE 0/2898: R|NNP+North|NNP\n",
      " MWE 200/2898: team|NN+silver|NN+medal|NN\n",
      " MWE 400/2898: runs|VBZ+an|DT+annual|JJ\n",
      " MWE 600/2898: poverty|NN+chastity|NN+and|CC\n",
      " MWE 800/2898: Open|NNP+Not|RB+Held|VBD\n",
      " MWE 1000/2898: imprisonment|NN+for|IN+life|NN\n",
      " MWE 1200/2898: 74|CD+W|NN+March|NNP\n",
      " MWE 1400/2898: also|RB+included|VBD+his|PRP$\n",
      " MWE 1600/2898: far|RB+northeastern|JJ\n",
      " MWE 1800/2898: the|DT+Olympic|JJ+final|JJ\n",
      " MWE 2000/2898: the|DT+only|JJ+engine|NN\n",
      " MWE 2200/2898: the|DT+first|JJ+Army|NNP\n",
      " MWE 2400/2898: were|VBD+open|JJ+for|IN\n",
      " MWE 2600/2898: different|JJ+from|IN+anything|NN\n",
      " MWE 2800/2898: is|VBZ+rich|JJ+and|CC\n",
      "Processing batch 10 of 10\n",
      "Loading w2v model\n",
      "Gathering MWE stats\n",
      " MWE 0/1561: track|NN+14|CD\n",
      " MWE 200/1561: a|DT+hamlet|NN+within|IN\n",
      " MWE 400/1561: Population|NNP+there|EX+were|VBD\n",
      " MWE 600/1561: was|VBD+indifferent|JJ+to|IN\n",
      " MWE 800/1561: on|IN+Central|NNP+Park|NNP\n",
      " MWE 1000/1561: the|DT+rights|NNS+or|CC\n",
      " MWE 1200/1561: References|NNP+See|NNP+also|RB\n",
      " MWE 1400/1561: several|JJ+decades|NNS+in|IN\n",
      "Wall time: 1h 24min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "batch_dfs = {}\n",
    "\n",
    "for bb in range(batch_count):\n",
    "    print('Processing batch {} of {}'.format(bb+1,batch_count))\n",
    "    \n",
    "    # Subset DataFrame\n",
    "    batch_dfs[bb] = ngram_eval[ngram_eval.batch == bb+1].reset_index(drop=True)\n",
    "    \n",
    "    # Initialise MWETokenizer\n",
    "    batch_token_mwe = MWETokenizer(list(batch_dfs[bb].ngram) , separator='+')\n",
    "    \n",
    "    # Load model\n",
    "    print('Loading w2v model')\n",
    "\n",
    "    batch_model = Word2Vec.load(datapath+'/Models/1 w2v/Tagged/w10p_tagged_clean_batch{}.model'.format(bb+1))\n",
    "    \n",
    "    print('Gathering MWE stats')\n",
    "    \n",
    "    # For each MWE, evaluate stats. Record vectors (in case we want to calculate different metrics later).\n",
    "    statsf = pd.DataFrame(columns=['ngram', 'stopwords', 'mwe_vector', 'component_vectors', 'component_cosims', \n",
    "                                   'cosine_sim']) # , 'base_nearest', 'mwe_nearest'\n",
    "    batch_len = len(batch_dfs[bb].ngram)\n",
    "    if batch_len >= 20000: \n",
    "        printer = 5000\n",
    "    elif batch_len >= 5000: \n",
    "        printer = 1000\n",
    "    else:\n",
    "        printer = 200\n",
    "        \n",
    "    _i = 0\n",
    "    \n",
    "    for exp in batch_dfs[bb].ngram:\n",
    "        if _i % printer == 0:\n",
    "            print(' MWE '+str(_i)+'/'+str(batch_len)+': '+'+'.join(exp))\n",
    "        _i += 1\n",
    "        \n",
    "        statsf = mwe_score(exp, batch_model, statsf)\n",
    "        \n",
    "    #  Join back onto DataFrame\n",
    "    batch_dfs[bb] = batch_dfs[bb].merge(statsf, on='ngram')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending batch 1 of 10\n",
      "Appending batch 2 of 10\n",
      "Appending batch 3 of 10\n",
      "Appending batch 4 of 10\n",
      "Appending batch 5 of 10\n",
      "Appending batch 6 of 10\n",
      "Appending batch 7 of 10\n",
      "Appending batch 8 of 10\n",
      "Appending batch 9 of 10\n",
      "Appending batch 10 of 10\n"
     ]
    }
   ],
   "source": [
    "# Merge dataframes, sort by compositionality metric, export\n",
    "\n",
    "# Also want the default batches with batch no < 0\n",
    "all_batches = ngram_eval[ngram_eval.batch < 0]\n",
    "\n",
    "for d in range(batch_count):\n",
    "    print('Appending batch {} of '.format(d+1)+str(batch_count))\n",
    "    all_batches = all_batches.append(batch_dfs[d])\n",
    "    \n",
    "all_batches = all_batches.sort_values('cosine_sim')\n",
    "all_batches = all_batches.reset_index(drop=True)\n",
    "\n",
    "all_batches.to_csv(datapath+'/Models/1 w2v/Tagged/Results/w10p_tagged_clean_output_001.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>freq</th>\n",
       "      <th>poisson</th>\n",
       "      <th>len</th>\n",
       "      <th>batch</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>mwe_vector</th>\n",
       "      <th>component_vectors</th>\n",
       "      <th>component_cosims</th>\n",
       "      <th>cosine_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(However|RB, since|IN, then|RB)</td>\n",
       "      <td>20</td>\n",
       "      <td>-1501.356357</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[-0.08021507, 0.029799368, -0.11063751, 0.0798...</td>\n",
       "      <td>[[0.44135073, -0.1859463, 2.1679575, -1.754787...</td>\n",
       "      <td>[-0.22124107, -0.1947155, -0.2786541]</td>\n",
       "      <td>-0.231537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(has|VBZ, been|VBN, following|VBG)</td>\n",
       "      <td>20</td>\n",
       "      <td>-1563.921228</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>[1, 1, 0]</td>\n",
       "      <td>[-0.06269902, -0.0087266695, -0.061697353, 0.0...</td>\n",
       "      <td>[[0.8249299, -1.3578229, 0.97652656, -0.036999...</td>\n",
       "      <td>[nan, nan, -0.22919384]</td>\n",
       "      <td>-0.229194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(both|CC, times|NNS, by|IN)</td>\n",
       "      <td>21</td>\n",
       "      <td>-1608.202878</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[-0.07510896, 0.04154765, -0.007869523, 0.1447...</td>\n",
       "      <td>[[1.2414573, -0.1210257, 0.77684075, -1.404658...</td>\n",
       "      <td>[-0.26926857, -0.18902278, nan]</td>\n",
       "      <td>-0.229146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(after|IN, both|CC, the|DT)</td>\n",
       "      <td>20</td>\n",
       "      <td>-1643.568467</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[1, 0, 1]</td>\n",
       "      <td>[-0.033339113, -0.044894636, 0.00069739716, -0...</td>\n",
       "      <td>[[0.95313185, -0.647143, 0.3539722, -3.1936626...</td>\n",
       "      <td>[nan, -0.22798495, nan]</td>\n",
       "      <td>-0.227985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(However|RB, even|RB, after|IN)</td>\n",
       "      <td>20</td>\n",
       "      <td>-1499.074445</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[-0.058937408, 0.0068662553, -0.00825334, 0.13...</td>\n",
       "      <td>[[-0.098684065, 0.9381516, 0.47127044, -1.7793...</td>\n",
       "      <td>[-0.17959411, -0.27630407, nan]</td>\n",
       "      <td>-0.227949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499995</th>\n",
       "      <td>(:|:, Paleogene|NNP, from|IN)</td>\n",
       "      <td>24</td>\n",
       "      <td>-1669.762522</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>[-2]</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499996</th>\n",
       "      <td>(of|IN, $|$, 3,000|CD)</td>\n",
       "      <td>22</td>\n",
       "      <td>-1681.886235</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>[-2]</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499997</th>\n",
       "      <td>(la|NNP, la|NNP, la|NNP)</td>\n",
       "      <td>25</td>\n",
       "      <td>-1687.517191</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>[-2]</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499998</th>\n",
       "      <td>(2015|CD, -2016|CD, school|NN)</td>\n",
       "      <td>25</td>\n",
       "      <td>-1696.555611</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>[-2]</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499999</th>\n",
       "      <td>(High|NNP, School|NNP, $|$)</td>\n",
       "      <td>23</td>\n",
       "      <td>-1705.340836</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>[-2]</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500000 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     ngram  freq      poisson  len  batch  \\\n",
       "0          (However|RB, since|IN, then|RB)    20 -1501.356357    3      4   \n",
       "1       (has|VBZ, been|VBN, following|VBG)    20 -1563.921228    3      4   \n",
       "2              (both|CC, times|NNS, by|IN)    21 -1608.202878    3      8   \n",
       "3              (after|IN, both|CC, the|DT)    20 -1643.568467    3      3   \n",
       "4          (However|RB, even|RB, after|IN)    20 -1499.074445    3      2   \n",
       "...                                    ...   ...          ...  ...    ...   \n",
       "499995       (:|:, Paleogene|NNP, from|IN)    24 -1669.762522    3     10   \n",
       "499996              (of|IN, $|$, 3,000|CD)    22 -1681.886235    3     10   \n",
       "499997            (la|NNP, la|NNP, la|NNP)    25 -1687.517191    3     10   \n",
       "499998      (2015|CD, -2016|CD, school|NN)    25 -1696.555611    3     10   \n",
       "499999         (High|NNP, School|NNP, $|$)    23 -1705.340836    3     10   \n",
       "\n",
       "        stopwords                                         mwe_vector  \\\n",
       "0       [0, 0, 0]  [-0.08021507, 0.029799368, -0.11063751, 0.0798...   \n",
       "1       [1, 1, 0]  [-0.06269902, -0.0087266695, -0.061697353, 0.0...   \n",
       "2       [0, 0, 1]  [-0.07510896, 0.04154765, -0.007869523, 0.1447...   \n",
       "3       [1, 0, 1]  [-0.033339113, -0.044894636, 0.00069739716, -0...   \n",
       "4       [0, 0, 1]  [-0.058937408, 0.0068662553, -0.00825334, 0.13...   \n",
       "...           ...                                                ...   \n",
       "499995       [-2]  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "499996       [-2]  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "499997       [-2]  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "499998       [-2]  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "499999       [-2]  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "\n",
       "                                        component_vectors  \\\n",
       "0       [[0.44135073, -0.1859463, 2.1679575, -1.754787...   \n",
       "1       [[0.8249299, -1.3578229, 0.97652656, -0.036999...   \n",
       "2       [[1.2414573, -0.1210257, 0.77684075, -1.404658...   \n",
       "3       [[0.95313185, -0.647143, 0.3539722, -3.1936626...   \n",
       "4       [[-0.098684065, 0.9381516, 0.47127044, -1.7793...   \n",
       "...                                                   ...   \n",
       "499995                                                 []   \n",
       "499996                                                 []   \n",
       "499997                                                 []   \n",
       "499998                                                 []   \n",
       "499999                                                 []   \n",
       "\n",
       "                             component_cosims  cosine_sim  \n",
       "0       [-0.22124107, -0.1947155, -0.2786541]   -0.231537  \n",
       "1                     [nan, nan, -0.22919384]   -0.229194  \n",
       "2             [-0.26926857, -0.18902278, nan]   -0.229146  \n",
       "3                     [nan, -0.22798495, nan]   -0.227985  \n",
       "4             [-0.17959411, -0.27630407, nan]   -0.227949  \n",
       "...                                       ...         ...  \n",
       "499995                                     []         NaN  \n",
       "499996                                     []         NaN  \n",
       "499997                                     []         NaN  \n",
       "499998                                     []         NaN  \n",
       "499999                                     []         NaN  \n",
       "\n",
       "[500000 rows x 10 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(all_batches.stopwords[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RuntimeWarning: Mean of empty slice\n",
    "#  Appear to be taking the np.nanmean() of a list of NaNs\n",
    "\n",
    "def inval(inlist,val=0):\n",
    "    if type(inlist) != list:\n",
    "        return False\n",
    "    return val in inlist\n",
    "\n",
    "#nozero = all_batches[~all_batches.stopwords.apply(inval)]\n",
    "\n",
    "#minone = nozero[nozero.stopwords.apply(inval,val=-1)]\n",
    "\n",
    "#minone[minone.stopwords.apply(inval,val=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "w10p_res_light = all_batches.drop(columns=['mwe_vector', 'component_vectors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "w10p_res_light.to_csv(datapath+'/Models/1 w2v/Tagged/Results/w10p_tagged_clean_light_001.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
