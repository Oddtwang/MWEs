{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\User\\\\Google Drive\\\\University\\\\Dissertation\\\\Code'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = 'C:/Users/'+os.getlogin()+'/Google Drive/University/Dissertation'\n",
    "#datapath = 'C:/Users/'+os.getlogin()+'/Dissertation Data'\n",
    "datapath = 'E:/Dissertation Data'\n",
    "\n",
    "os.chdir(path+'/Code')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import MWETokenizer\n",
    "\n",
    "from glove import Corpus, Glove\n",
    "\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autism|NN is|VBZ a|DT developmental|JJ disorder|NN characterized|VBN by|IN difficulties|NNS with|IN social|JJ interaction|NN and|CC communication|NN and|CC by|IN restricted|JJ and|CC repetitive|JJ behavior|NN \n",
      "\n",
      "Parents|NNS often|RB notice|VBP signs|NNS during|IN the|DT first|JJ three|CD years|NNS of|IN their|PRP$ child|NN 's|POS life|NN \n",
      "\n",
      "These|DT signs|NNS often|RB develop|VBP gradually|RB though|IN some|DT children|NNS with|IN autism|NN experience|NN worsening|VBG in|IN their|PRP$ communication|NN and|CC social|JJ skills|NNS after|IN reaching|VBG developmental|JJ milestones|NNS at|IN a|DT normal|JJ pace|NN \n",
      "\n",
      "Autism|NN is|VBZ associated|VBN with|IN a|DT combination|NN of|IN genetic|JJ and|CC environmental|JJ factors|NNS \n",
      "\n",
      "Risk|NN factors|NNS during|IN pregnancy|NN include|VBP certain|JJ infections|NNS such|JJ as|IN rubella|NN toxins|NNS including|VBG valproic|JJ acid|NN alcohol|NN cocaine|NN pesticides|NNS lead|VBP and|CC air|NN pollution|NN fetal|JJ growth|NN restriction|NN and|CC autoimmune|JJ diseases|NNS \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# On 10% English wiki, POS tagged\n",
    "\n",
    "sf = open(datapath+'/Corpora/wiki/enwiki_20200520/Tagged/enwiki_20200520_10pc_tagged.txt', 'r', encoding='utf-8')\n",
    "\n",
    "for lines in range(5):\n",
    "    print(sf.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus.reader.plaintext import PlaintextCorpusReader\n",
    "\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "\n",
    "from nltk.corpus.reader.util import read_line_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "w10p_t = PlaintextCorpusReader(datapath+'/Corpora/wiki/enwiki_20200520/Tagged','enwiki_20200520_10pc_tagged.txt',\n",
    "                            word_tokenizer = WhitespaceTokenizer(),\n",
    "                            para_block_reader=read_line_block\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import word and sentence generators\n",
    "\n",
    "from generators import sent_gen, word_gen, Sent_Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collate n-grams\n",
    "\n",
    "from nltk.collocations import BigramCollocationFinder, TrigramCollocationFinder\n",
    "\n",
    "from nltk.metrics import (\n",
    "    BigramAssocMeasures,\n",
    "    TrigramAssocMeasures,\n",
    "    NgramAssocMeasures,\n",
    ")\n",
    "\n",
    "from nltk.metrics.spearman import (\n",
    "    spearman_correlation,\n",
    "    ranks_from_scores,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopwords from corpus - 50 most frequent\n",
    "\n",
    "with open(datapath+'/Corpora/wiki/enwiki_20200520/Tagged/stop.pkl', 'rb') as pfile:\n",
    "    stop = pickle.load(pfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'%|NN',\n",
       " '0|CD',\n",
       " '1|CD',\n",
       " '2|CD',\n",
       " '3|CD',\n",
       " 'He|PRP',\n",
       " 'In|IN',\n",
       " 'It|PRP',\n",
       " 'The|DT',\n",
       " 'also|RB',\n",
       " 'and|CC',\n",
       " 'an|DT',\n",
       " 'are|VBP',\n",
       " 'as|IN',\n",
       " 'at|IN',\n",
       " 'a|DT',\n",
       " 'be|VB',\n",
       " 'but|CC',\n",
       " 'by|IN',\n",
       " 'first|JJ',\n",
       " 'for|IN',\n",
       " 'from|IN',\n",
       " 'had|VBD',\n",
       " 'has|VBZ',\n",
       " 'he|PRP',\n",
       " 'his|PRP$',\n",
       " 'in|IN',\n",
       " 'is|VBZ',\n",
       " 'its|PRP$',\n",
       " 'it|PRP',\n",
       " 'not|RB',\n",
       " 'of|IN',\n",
       " 'one|CD',\n",
       " 'on|IN',\n",
       " 'or|CC',\n",
       " 's|POS',\n",
       " 'that|IN',\n",
       " 'that|WDT',\n",
       " 'their|PRP$',\n",
       " 'the|DT',\n",
       " 'to|IN',\n",
       " 'to|TO',\n",
       " 'two|CD',\n",
       " 'was|VBD',\n",
       " 'were|VBD',\n",
       " 'which|WDT',\n",
       " 'who|WP',\n",
       " 'with|IN',\n",
       " '|HYPH',\n",
       " '–|SYM'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_freq = 20\n",
    "eval_count = 500000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>freq</th>\n",
       "      <th>poisson</th>\n",
       "      <th>len</th>\n",
       "      <th>batch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(311.22|CD, 500.86|CD)</td>\n",
       "      <td>20</td>\n",
       "      <td>-667.084219</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Makhaya|NNP, Ntini|NNP)</td>\n",
       "      <td>20</td>\n",
       "      <td>-667.084219</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(resting_place_coordinates|NNS, burial_place|VBP)</td>\n",
       "      <td>20</td>\n",
       "      <td>-667.084219</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Dechawat|NNP, Poomjaeng|NNP)</td>\n",
       "      <td>20</td>\n",
       "      <td>-667.084219</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(MSC1|NN, MSC2|NN)</td>\n",
       "      <td>20</td>\n",
       "      <td>-667.084219</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499995</th>\n",
       "      <td>(US|NNP, Steel|NNP)</td>\n",
       "      <td>32</td>\n",
       "      <td>-1679.033919</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499996</th>\n",
       "      <td>(Harry|NNP, Wilson|NNP)</td>\n",
       "      <td>32</td>\n",
       "      <td>-1679.034986</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499997</th>\n",
       "      <td>(a|DT, solo|JJ, piano|NN)</td>\n",
       "      <td>23</td>\n",
       "      <td>-1679.035464</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499998</th>\n",
       "      <td>(1962|CD, album|NN)</td>\n",
       "      <td>30</td>\n",
       "      <td>-1679.036008</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499999</th>\n",
       "      <td>(he|PRP, is|VBZ, set|VBN)</td>\n",
       "      <td>21</td>\n",
       "      <td>-1679.038189</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    ngram  freq      poisson  \\\n",
       "0                                  (311.22|CD, 500.86|CD)    20  -667.084219   \n",
       "1                                (Makhaya|NNP, Ntini|NNP)    20  -667.084219   \n",
       "2       (resting_place_coordinates|NNS, burial_place|VBP)    20  -667.084219   \n",
       "3                           (Dechawat|NNP, Poomjaeng|NNP)    20  -667.084219   \n",
       "4                                      (MSC1|NN, MSC2|NN)    20  -667.084219   \n",
       "...                                                   ...   ...          ...   \n",
       "499995                                (US|NNP, Steel|NNP)    32 -1679.033919   \n",
       "499996                            (Harry|NNP, Wilson|NNP)    32 -1679.034986   \n",
       "499997                          (a|DT, solo|JJ, piano|NN)    23 -1679.035464   \n",
       "499998                                (1962|CD, album|NN)    30 -1679.036008   \n",
       "499999                          (he|PRP, is|VBZ, set|VBN)    21 -1679.038189   \n",
       "\n",
       "        len  batch  \n",
       "0         2      1  \n",
       "1         2      1  \n",
       "2         2      1  \n",
       "3         2      1  \n",
       "4         2      1  \n",
       "...     ...    ...  \n",
       "499995    2      3  \n",
       "499996    2      3  \n",
       "499997    3      2  \n",
       "499998    2      6  \n",
       "499999    3      3  \n",
       "\n",
       "[500000 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_eval = pd.read_pickle(datapath+'/Corpora/wiki/enwiki_20200520/Tagged/ngram_eval.pkl')\n",
    "\n",
    "ngram_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_count = max(ngram_eval.batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1     170225\n",
       " 2     129780\n",
       " 3      77191\n",
       " 4      53152\n",
       " 5      30841\n",
       " 6      17798\n",
       " 7       9470\n",
       " 8       5725\n",
       " 9       2410\n",
       "-1       1723\n",
       " 10      1561\n",
       "-2        124\n",
       "Name: batch, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_eval.batch.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import MWETokenizer\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Flatten down to a single number\n",
    "def cosim(x,y):\n",
    "    return cosine_similarity(x.reshape(1,-1), y.reshape(1,-1))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Autism|NN', 'is|VBZ', 'a|DT', 'developmental|JJ', 'disorder|NN', 'characterized|VBN', 'by|IN', 'difficulties|NNS', 'with|IN', 'social|JJ', 'interaction|NN', 'and|CC', 'communication|NN', 'and|CC', 'by|IN', 'restricted|JJ', 'and|CC', 'repetitive|JJ', 'behavior|NN']\n"
     ]
    }
   ],
   "source": [
    "for s in Sent_Seq(w10p_t, remchars = \"[`¬@^\\\"]\"):\n",
    "    print(s)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1 of 10\n",
      "Building word2vec model\n",
      " Training model\n",
      " Saving model\n",
      "Processing batch 2 of 10\n",
      "Building word2vec model\n",
      " Training model\n",
      " Saving model\n",
      "Processing batch 3 of 10\n",
      "Building word2vec model\n",
      " Training model\n",
      " Saving model\n",
      "Processing batch 4 of 10\n",
      "Building word2vec model\n",
      " Training model\n",
      " Saving model\n",
      "Processing batch 5 of 10\n",
      "Building word2vec model\n",
      " Training model\n",
      " Saving model\n",
      "Processing batch 6 of 10\n",
      "Building word2vec model\n",
      " Training model\n",
      " Saving model\n",
      "Processing batch 7 of 10\n",
      "Building word2vec model\n",
      " Training model\n",
      " Saving model\n",
      "Processing batch 8 of 10\n",
      "Building word2vec model\n",
      " Training model\n",
      " Saving model\n",
      "Processing batch 9 of 10\n",
      "Building word2vec model\n",
      " Training model\n",
      " Saving model\n",
      "Processing batch 10 of 10\n",
      "Building word2vec model\n",
      " Training model\n",
      " Saving model\n",
      "Wall time: 2d 4h 19min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "batch_dfs = {}\n",
    "\n",
    "for bb in range(batch_count):\n",
    "    print('Processing batch {} of {}'.format(bb+1,batch_count))\n",
    "    \n",
    "    # Subset DataFrame\n",
    "    batch_dfs[bb] = ngram_eval[ngram_eval.batch == bb+1].reset_index(drop=True)\n",
    "    \n",
    "    # Initialise MWETokenizer\n",
    "    batch_token_mwe = MWETokenizer(list(batch_dfs[bb].ngram) , separator='+')\n",
    "    \n",
    "    # Build model\n",
    "    print('Building word2vec model')\n",
    "    sents_mwe = Sent_Seq(w10p_t, tokenizer = batch_token_mwe, remchars = \"[`¬@^\\\"]\")\n",
    "    \n",
    "    print(' Training model')\n",
    "    batch_model = Word2Vec(sents_mwe,\n",
    "                             min_count = 20,  # 20 matches R&E on EN Wiki\n",
    "                             size = 400,\n",
    "                             workers = 8,\n",
    "                             window = 5,\n",
    "                             sg = 0,         # CBOW\n",
    "                             sample = 10e-5, # Subsampling\n",
    "                             negative = 10\n",
    "                            )\n",
    "\n",
    "    # Save model\n",
    "    print(' Saving model')\n",
    "    batch_model.save(datapath+'/Models/1 w2v/Tagged/w10p_tagged_batch{}.model'.format(bb+1))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
